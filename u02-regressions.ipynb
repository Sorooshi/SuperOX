{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load\n",
    "from Soroosh_utilities import *\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: GPU device not found.\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
    "    print('WARNING: GPU device not found.')\n",
    "else:\n",
    "    print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of the study:\n",
    "\n",
    "- We intent to predict the critical current, determine the important features, and visual them.\n",
    "\n",
    "- Previously, it has been done for the real-world data. In this study, not only, we will repeat those experiments, but also we use the synthetically generated data to increase our test samples. To this end, we persui the following framework.\n",
    "\n",
    "    - 1) Train regressors on only real-world data;\n",
    "    - 2) Train regressors on only synthetic data;\n",
    "    - 3) Train regressors on combination of both (50%-50%).\n",
    "\n",
    "\n",
    "- To this end we use, three regression algorithms: a)RF, b) GBR-LS, c) DNNR.\n",
    "\n",
    "- Note: For more see the notion page below\n",
    "\n",
    "https://www.notion.so/SuperOx-936b1b2ce7b14f20bd76578c82305e2b\n",
    "\n",
    "\n",
    "Note: we studied and tunned the parameters in previous jupyter notebook. Thus we will use them as the default, and given here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializatin for comparison of methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE MRAE RMSE R^2-Score\n",
       "RF       NaN  NaN  NaN       NaN\n",
       "GBR-Ls   NaN  NaN  NaN       NaN\n",
       "DNN-Reg  NaN  NaN  NaN       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_algs = ['RF', 'GBR-Ls', 'DNN-Reg',]  # Regression algorithms ('Bayes_Reg')\n",
    "reg_results = ['MAE', 'MRAE', 'RMSE', 'R^2-Score',]  # 'Predictions', 'Ground Truth'\n",
    "df_reg_real = pd.DataFrame(index=reg_algs, columns=reg_results) \n",
    "df_reg_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE MRAE RMSE R^2-Score\n",
       "RF       NaN  NaN  NaN       NaN\n",
       "GBR-Ls   NaN  NaN  NaN       NaN\n",
       "DNN-Reg  NaN  NaN  NaN       NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_algs = ['RF', 'GBR-Ls', 'DNN-Reg', ]  # Regression algorithms\n",
    "reg_results = ['MAE', 'MRAE', 'RMSE', 'R^2-Score',]  # 'Predictions', 'Ground Truth'\n",
    "df_reg_synthetic = pd.DataFrame(index=reg_algs, columns=reg_results) \n",
    "df_reg_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE MRAE RMSE R^2-Score\n",
       "RF       NaN  NaN  NaN       NaN\n",
       "GBR-Ls   NaN  NaN  NaN       NaN\n",
       "DNN-Reg  NaN  NaN  NaN       NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_algs = ['RF', 'GBR-Ls', 'DNN-Reg',]  # Regression algorithms\n",
    "reg_results = ['MAE', 'MRAE', 'RMSE','R^2-Score',]  # 'Predictions', 'Ground Truth'\n",
    "df_reg_combined = pd.DataFrame(index=reg_algs, columns=reg_results) \n",
    "df_reg_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pld_complete = catalog.load('pld_complete').dropna().sort_values('pos', ascending=True)\n",
    "# pld_complete_zscore = pd.read_csv(\"/home/soroosh/SearchOX/data/pld_complete_zscore.csv\", index_col=False)\n",
    "\n",
    "\n",
    "pld_complete_range = pd.read_csv(\"/home/soroosh/Desktop/SearchOX/data/pld_complete_range.csv\",\n",
    "                                 index_col=False)\n",
    "\n",
    "pld_complete_range_synthetic = np.loadtxt(\"/home/soroosh/Desktop/SearchOX/data/x_r_synthetic.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_Voltage_HSR_V_1025</th>\n",
       "      <th>median_Voltage_HSR_V_1027</th>\n",
       "      <th>median_Voltage_HSR_V_1030</th>\n",
       "      <th>median_Voltage_HSL_V_1025</th>\n",
       "      <th>median_Voltage_HSL_V_1027</th>\n",
       "      <th>median_Voltage_HSL_V_1030</th>\n",
       "      <th>median_Voltage_HF_V_1025</th>\n",
       "      <th>median_Voltage_HF_V_1027</th>\n",
       "      <th>median_Voltage_HF_V_1030</th>\n",
       "      <th>median_Voltage_HC_V_1025</th>\n",
       "      <th>...</th>\n",
       "      <th>std_Sigma_1030</th>\n",
       "      <th>pos</th>\n",
       "      <th>Speed</th>\n",
       "      <th>X FWHM</th>\n",
       "      <th>Y FWHM</th>\n",
       "      <th>R FWHM</th>\n",
       "      <th>Coolness</th>\n",
       "      <th>Coolness_neg</th>\n",
       "      <th>Ic</th>\n",
       "      <th>Ic_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129479</td>\n",
       "      <td>0.177414</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.69562</td>\n",
       "      <td>-0.256257</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>-0.072807</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.057123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.501695</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.039589</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>-0.086369</td>\n",
       "      <td>496.2</td>\n",
       "      <td>1.767913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.110059</td>\n",
       "      <td>0.340245</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.69562</td>\n",
       "      <td>-0.321465</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>-0.173901</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.501652</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.039589</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>-0.086369</td>\n",
       "      <td>494.7</td>\n",
       "      <td>1.762568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119769</td>\n",
       "      <td>0.340245</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.69562</td>\n",
       "      <td>-0.321465</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.007363</td>\n",
       "      <td>-0.173901</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.057123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.501646</td>\n",
       "      <td>-0.007197</td>\n",
       "      <td>0.039589</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>-0.086369</td>\n",
       "      <td>494.2</td>\n",
       "      <td>1.760787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.110059</td>\n",
       "      <td>0.348139</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.69562</td>\n",
       "      <td>-0.322354</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>-0.218270</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.057123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.501635</td>\n",
       "      <td>-0.010946</td>\n",
       "      <td>0.039589</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>-0.086369</td>\n",
       "      <td>495.5</td>\n",
       "      <td>1.765419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110059</td>\n",
       "      <td>0.264593</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.69562</td>\n",
       "      <td>-0.305820</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>-0.129533</td>\n",
       "      <td>-0.021102</td>\n",
       "      <td>0.057123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.501619</td>\n",
       "      <td>-0.017147</td>\n",
       "      <td>0.042682</td>\n",
       "      <td>0.069442</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.051965</td>\n",
       "      <td>-0.084836</td>\n",
       "      <td>497.9</td>\n",
       "      <td>1.773168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   median_Voltage_HSR_V_1025  median_Voltage_HSR_V_1027  \\\n",
       "0                   0.129479                   0.177414   \n",
       "1                   0.110059                   0.340245   \n",
       "2                   0.119769                   0.340245   \n",
       "3                   0.110059                   0.348139   \n",
       "4                   0.110059                   0.264593   \n",
       "\n",
       "   median_Voltage_HSR_V_1030  median_Voltage_HSL_V_1025  \\\n",
       "0                   0.005142                    0.69562   \n",
       "1                   0.005142                    0.69562   \n",
       "2                   0.005142                    0.69562   \n",
       "3                   0.005142                    0.69562   \n",
       "4                   0.005142                    0.69562   \n",
       "\n",
       "   median_Voltage_HSL_V_1027  median_Voltage_HSL_V_1030  \\\n",
       "0                  -0.256257                  -0.015406   \n",
       "1                  -0.321465                  -0.015406   \n",
       "2                  -0.321465                  -0.015406   \n",
       "3                  -0.322354                  -0.015406   \n",
       "4                  -0.305820                  -0.015406   \n",
       "\n",
       "   median_Voltage_HF_V_1025  median_Voltage_HF_V_1027  \\\n",
       "0                 -0.009215                 -0.072807   \n",
       "1                 -0.009215                 -0.173901   \n",
       "2                 -0.007363                 -0.173901   \n",
       "3                 -0.009215                 -0.218270   \n",
       "4                 -0.009215                 -0.129533   \n",
       "\n",
       "   median_Voltage_HF_V_1030  median_Voltage_HC_V_1025  ...  std_Sigma_1030  \\\n",
       "0                 -0.021102                  0.057123  ...       -0.390667   \n",
       "1                 -0.021102                  0.050178  ...       -0.390667   \n",
       "2                 -0.021102                  0.057123  ...       -0.390667   \n",
       "3                 -0.021102                  0.057123  ...       -0.390667   \n",
       "4                 -0.021102                  0.057123  ...       -0.390667   \n",
       "\n",
       "        pos     Speed    X FWHM    Y FWHM    R FWHM  Coolness  Coolness_neg  \\\n",
       "0 -0.501695  0.009841  0.039589  0.067470  0.015697  0.053006     -0.086369   \n",
       "1 -0.501652 -0.005266  0.039589  0.067470  0.015697  0.053006     -0.086369   \n",
       "2 -0.501646 -0.007197  0.039589  0.067470  0.015697  0.053006     -0.086369   \n",
       "3 -0.501635 -0.010946  0.039589  0.067470  0.015697  0.053006     -0.086369   \n",
       "4 -0.501619 -0.017147  0.042682  0.069442  0.017956  0.051965     -0.084836   \n",
       "\n",
       "      Ic   Ic_norm  \n",
       "0  496.2  1.767913  \n",
       "1  494.7  1.762568  \n",
       "2  494.2  1.760787  \n",
       "3  495.5  1.765419  \n",
       "4  497.9  1.773168  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pld_complete_range.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18561, 376), (18561,), (18561,), (18561,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_real = pld_complete_range.loc[:,~pld_complete_range.columns.isin(['Ic', 'Ic_norm', 'pos'])].to_numpy()\n",
    "\n",
    "y_ic_real = pld_complete_range['Ic'].to_numpy()\n",
    "y_ic_norm_real = pld_complete_range['Ic_norm'].to_numpy()\n",
    "pos_real = pld_complete_range['pos'].to_numpy()\n",
    "\n",
    "x_r_real.shape, y_ic_real.shape, y_ic_norm_real.shape, pos_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 377, 378)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx = pld_complete_range.columns.get_loc(\"pos\")\n",
    "ic_idx = pld_complete_range.columns.get_loc(\"Ic\")\n",
    "ic_norm_idx = pld_complete_range.columns.get_loc(\"Ic_norm\")\n",
    "pos_idx, ic_idx, ic_norm_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18561, 370), (18561, 6), (18561, 376))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_synthetic_1 = pld_complete_range_synthetic[:, : pos_idx]\n",
    "x_r_synthetic_2 = pld_complete_range_synthetic[:, pos_idx+1:ic_idx]\n",
    "\n",
    "\n",
    "x_r_synthetic = np.concatenate([x_r_synthetic_1, x_r_synthetic_2], axis=1)\n",
    "x_r_synthetic_1.shape, x_r_synthetic_2.shape, x_r_synthetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18561, 376), (18561,), (18561,), (18561,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ic_synthetic = pld_complete_range_synthetic[:, ic_idx]\n",
    "y_ic_norm_synthetic = pld_complete_range_synthetic[:, ic_norm_idx] \n",
    "pos_synthetic = pld_complete_range_synthetic[:, pos_idx]\n",
    "\n",
    "x_r_synthetic.shape, y_ic_synthetic.shape, y_ic_norm_synthetic.shape, pos_synthetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37122, 376), (37122,), (37122,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_combined = np.concatenate([x_r_real, x_r_synthetic], axis=0)\n",
    "y_ic_combined = np.concatenate([y_ic_real, y_ic_synthetic], axis=0)\n",
    "y_ic_norm_combined = np.concatenate([y_ic_norm_real, y_ic_norm_synthetic], axis=0)\n",
    "\n",
    "x_r_combined.shape, y_ic_combined.shape, y_ic_norm_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(x_r_real))\n",
    "assert not x_r_real.shape != x_r_synthetic.shape\n",
    "assert not x_r_combined.shape[0] != int(2*x_r_synthetic.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the data\n",
    "\n",
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11136, 376), (3713, 376), (3712, 376), (11136,), (3713,), (3712,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_train_real, x_r_test_real, \\\n",
    "y_train_real, y_test_real = train_test_split(x_r_real,\n",
    "                                             y_ic_norm_real,\n",
    "                                             test_size=0.40,\n",
    "                                             random_state=43,)\n",
    "\n",
    "x_r_val_real, x_r_test_real, \\\n",
    "y_val_real, y_test_real = train_test_split(x_r_test_real,\n",
    "                                           y_test_real,\n",
    "                                           test_size=0.5,\n",
    "                                           random_state=43,)\n",
    "\n",
    "\n",
    "x_r_train_real.shape, x_r_test_real.shape, \\\n",
    "x_r_val_real.shape, y_train_real.shape, \\\n",
    "y_test_real.shape, y_val_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11136, 376), (3713, 376), (3712, 376), (11136,), (3713,), (3712,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_train_synthetic, x_r_test_synthetic,\\\n",
    "y_train_synthetic, y_test_synthetic = train_test_split(x_r_synthetic,\n",
    "                                                       y_ic_norm_synthetic,\n",
    "                                                       test_size=0.40,\n",
    "                                                       random_state=43,)\n",
    "\n",
    "x_r_val_synthetic, x_r_test_synthetic,\\\n",
    "y_val_synthetic, y_test_synthetic = train_test_split(x_r_test_synthetic,\n",
    "                                                     y_test_synthetic,\n",
    "                                                     test_size=0.5,\n",
    "                                                     random_state=43,)\n",
    "\n",
    "\n",
    "x_r_train_synthetic.shape, x_r_test_synthetic.shape, \\\n",
    "x_r_val_synthetic.shape, y_train_synthetic.shape,  y_test_synthetic.shape, y_val_synthetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22273, 376), (7425, 376), (7424, 376), (22273,), (7425,), (7424,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r_train_combined, x_r_test_combined, \\\n",
    "y_train_combined, y_test_combined = train_test_split(x_r_combined,\n",
    "                                                     y_ic_norm_combined,\n",
    "                                                     test_size=0.40,\n",
    "                                                     random_state=43,)\n",
    "\n",
    "x_r_val_combined, x_r_test_combined, \\\n",
    "y_val_combined, y_test_combined = train_test_split(x_r_test_combined,\n",
    "                                                   y_test_combined,\n",
    "                                                   test_size=0.5,\n",
    "                                                   random_state=43,)\n",
    "\n",
    "\n",
    "x_r_train_combined.shape, x_r_test_combined.shape, \\\n",
    "x_r_val_combined.shape, y_train_combined.shape, y_test_combined.shape, y_val_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RF\n",
    "\n",
    "- For more about tuning the parameters see the u01-*.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_rf(x_train, y_train, x_test, y_test, name):\n",
    "    \n",
    "    rf_reg = RandomForestRegressor(n_estimators=100, \n",
    "                                   n_jobs = -2, \n",
    "                                   criterion='mse', \n",
    "                                   min_samples_leaf=1,\n",
    "                                   verbose=1)\n",
    "    \n",
    "    rf_reg.fit(x_train, y_train)\n",
    "    \n",
    "    y_preds_rf = rf_reg.predict(x_test)\n",
    "\n",
    "    filename = \"rf_reg-\" + name +  \"-.joblib\"\n",
    "    dump(rf_reg, \"saved_model/\"+ filename )\n",
    "    \n",
    "    return y_preds_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Gradient Boosting Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_gbr(x_train, y_train, x_test, y_test, name):\n",
    "    \n",
    "    gbr_ls = GradientBoostingRegressor(loss='ls', verbose=1,)\n",
    "    gbr_ls.fit(x_train, y_train)\n",
    "    y_preds_gbr_ls = gbr_ls.predict(x_test)\n",
    "    \n",
    "    filename = \"gbr_ls-\" + name +  \"-.joblib\"\n",
    "    dump(gbr_ls, \"saved_model/\"+ filename )\n",
    "    \n",
    "    return y_preds_gbr_ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN-Regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnnReg(tfk.Model):\n",
    "    \n",
    "    def __init__(self, n_units, n_features, name='dnn_reg', **kwargs):\n",
    "        super(DnnReg, self).__init__(name=name, **kwargs)\n",
    "        self.n_units = n_units\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.input_layer = tfkl.InputLayer(input_shape=self.n_features)\n",
    "        self.cast_layer = tfkl.Lambda(lambda x: tf.cast(x, tf.float32))\n",
    "        self.dense_1 = tfkl.Dense(units=int(.5*self.n_units), activation=tf.nn.leaky_relu)\n",
    "        self.dense_2 = tfkl.Dense(units=self.n_units, activation=tf.nn.leaky_relu)\n",
    "        self.dense_3 = tfkl.Dense(units=2*self.n_units, activation=tf.nn.leaky_relu,)\n",
    "        self.regressor = tfkl.Dense(units=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.input_layer(inputs)\n",
    "        x = self.cast_layer(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        regression = self.regressor(x)\n",
    "        return regression\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000  # previously, it was 500\n",
    "learning_rate = 1e-5  # [1e-2, 1e-3, 1e-5] \n",
    "batch_size = 64  # [32, 64, 256]\n",
    "n_units = 128\n",
    "\n",
    "input_shape = (x_r_real.shape[1])  \n",
    "n_units = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_dnn_reg(dnn_reg, x_train, y_train, x_val, y_val, x_test, y_test, name):\n",
    "\n",
    "    callback = tfk.callbacks.EarlyStopping(monitor='loss', patience=5)  # for early-stop\n",
    "\n",
    "    dnn_reg.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "                    loss='mse',\n",
    "                   )\n",
    "\n",
    "    history_dnn_ref = dnn_reg.fit(x=x_train, y=y_train,\n",
    "               epochs=n_epochs, batch_size=batch_size,\n",
    "               validation_data=(x_val, y_val),\n",
    "    #            callbacks=[callback],\n",
    "               )\n",
    "\n",
    "\n",
    "#     plot_loss(history=history_dnn_ref, name='DNN-Reg('+ \n",
    "#               str(batch_size)+ \", \" + str(learning_rate)+ ')')\n",
    "\n",
    "    # Saving the trained weights for future applications\n",
    "    # !mkdir -p saved_model\n",
    "    filename = \"dnn-reg-\" + name +  \"-.joblib\"\n",
    "    dnn_reg.save_weights('saved_model/' + filename + '.h5')\n",
    "\n",
    "    y_preds_dnn_reg = dnn_reg.predict(x_test)\n",
    "\n",
    "    print(\"y_preds_dnn_reg:\", y_preds_dnn_reg.shape)\n",
    "    \n",
    "    return y_preds_dnn_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-only data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "174/174 [==============================] - 1s 3ms/step - loss: 2.5517 - val_loss: 1.9579\n",
      "Epoch 2/1000\n",
      "174/174 [==============================] - 0s 921us/step - loss: 1.7466 - val_loss: 1.1533\n",
      "Epoch 3/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.9641 - val_loss: 0.4940\n",
      "Epoch 4/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 0.3876 - val_loss: 0.1790\n",
      "Epoch 5/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 0.1450 - val_loss: 0.0991\n",
      "Epoch 6/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 0.0890 - val_loss: 0.0749\n",
      "Epoch 7/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0609\n",
      "Epoch 8/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0511\n",
      "Epoch 9/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 0.0480 - val_loss: 0.0435\n",
      "Epoch 10/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 0.0407 - val_loss: 0.0374\n",
      "Epoch 11/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 0.0355 - val_loss: 0.0324\n",
      "Epoch 12/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 0.0305 - val_loss: 0.0280\n",
      "Epoch 13/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0259 - val_loss: 0.0245\n",
      "Epoch 14/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0214\n",
      "Epoch 15/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 0.0201 - val_loss: 0.0189\n",
      "Epoch 16/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 0.0173 - val_loss: 0.0168\n",
      "Epoch 17/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 18/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0145 - val_loss: 0.0137\n",
      "Epoch 19/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 20/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 21/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 22/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 23/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 24/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 25/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 26/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 27/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 28/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 29/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 30/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 31/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 32/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 33/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 34/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 35/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 36/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 37/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 38/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 39/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 40/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 41/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 42/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 43/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 44/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 45/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 46/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 47/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 48/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 49/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 50/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 51/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 52/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 53/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 54/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 55/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 56/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 57/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 58/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 59/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 60/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 61/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 62/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 63/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 64/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 65/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 66/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 67/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 68/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 69/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 70/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 71/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 73/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 74/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 75/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 76/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 77/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 78/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 79/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 80/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 81/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 82/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 85/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 86/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 87/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 88/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 89/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 90/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 91/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 92/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 9.9956e-04 - val_loss: 0.0013\n",
      "Epoch 93/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.7816e-04 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 9.8913e-04 - val_loss: 0.0012\n",
      "Epoch 96/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 9.5702e-04 - val_loss: 0.0012\n",
      "Epoch 97/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.2965e-04 - val_loss: 0.0012\n",
      "Epoch 98/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 9.4160e-04 - val_loss: 0.0012\n",
      "Epoch 99/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 9.2691e-04 - val_loss: 0.0012\n",
      "Epoch 100/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.3102e-04 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.9913e-04 - val_loss: 0.0011\n",
      "Epoch 102/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 8.8918e-04 - val_loss: 0.0011\n",
      "Epoch 103/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 9.0162e-04 - val_loss: 0.0011\n",
      "Epoch 104/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.8719e-04 - val_loss: 0.0011\n",
      "Epoch 105/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.5404e-04 - val_loss: 0.0011\n",
      "Epoch 106/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 8.6631e-04 - val_loss: 0.0011\n",
      "Epoch 107/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 8.1996e-04 - val_loss: 0.0011\n",
      "Epoch 108/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.4405e-04 - val_loss: 0.0011\n",
      "Epoch 109/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.3501e-04 - val_loss: 0.0010\n",
      "Epoch 110/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 8.6649e-04 - val_loss: 0.0011\n",
      "Epoch 111/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.0284e-04 - val_loss: 0.0010\n",
      "Epoch 112/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 8.2047e-04 - val_loss: 0.0010\n",
      "Epoch 113/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.3026e-04 - val_loss: 0.0010\n",
      "Epoch 114/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.9015e-04 - val_loss: 0.0010\n",
      "Epoch 115/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 7.8719e-04 - val_loss: 0.0010\n",
      "Epoch 116/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.7783e-04 - val_loss: 0.0010\n",
      "Epoch 117/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.4612e-04 - val_loss: 9.7761e-04\n",
      "Epoch 118/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.7175e-04 - val_loss: 9.7517e-04\n",
      "Epoch 119/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.6521e-04 - val_loss: 9.5915e-04\n",
      "Epoch 120/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.1968e-04 - val_loss: 9.6326e-04\n",
      "Epoch 121/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 7.3073e-04 - val_loss: 9.5544e-04\n",
      "Epoch 122/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.4481e-04 - val_loss: 9.4717e-04\n",
      "Epoch 123/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.3994e-04 - val_loss: 9.3534e-04\n",
      "Epoch 124/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 6.8615e-04 - val_loss: 9.2233e-04\n",
      "Epoch 125/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 6.9101e-04 - val_loss: 9.2891e-04\n",
      "Epoch 126/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 6.8115e-04 - val_loss: 9.3096e-04\n",
      "Epoch 127/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 6.9196e-04 - val_loss: 9.0622e-04\n",
      "Epoch 128/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 7.1459e-04 - val_loss: 9.0536e-04\n",
      "Epoch 129/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.8726e-04 - val_loss: 9.1494e-04\n",
      "Epoch 130/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.9416e-04 - val_loss: 8.9582e-04\n",
      "Epoch 131/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.8663e-04 - val_loss: 8.8641e-04\n",
      "Epoch 132/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 6.7208e-04 - val_loss: 8.8593e-04\n",
      "Epoch 133/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 6.7189e-04 - val_loss: 9.0435e-04\n",
      "Epoch 134/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 6.7766e-04 - val_loss: 8.7052e-04\n",
      "Epoch 135/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.4556e-04 - val_loss: 8.6197e-04\n",
      "Epoch 136/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.6537e-04 - val_loss: 8.7024e-04\n",
      "Epoch 137/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.3297e-04 - val_loss: 8.5305e-04\n",
      "Epoch 138/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 6.4365e-04 - val_loss: 8.5228e-04\n",
      "Epoch 139/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2014e-04 - val_loss: 8.5977e-04\n",
      "Epoch 140/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 6.2660e-04 - val_loss: 8.6320e-04\n",
      "Epoch 141/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.4541e-04 - val_loss: 8.3466e-04\n",
      "Epoch 142/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.1853e-04 - val_loss: 8.3780e-04\n",
      "Epoch 143/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.1120e-04 - val_loss: 8.3081e-04\n",
      "Epoch 144/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 6.1535e-04 - val_loss: 8.3360e-04\n",
      "Epoch 145/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 6.2975e-04 - val_loss: 8.1489e-04\n",
      "Epoch 146/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.0739e-04 - val_loss: 8.1435e-04\n",
      "Epoch 147/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 6.1865e-04 - val_loss: 8.0898e-04\n",
      "Epoch 148/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 6.0056e-04 - val_loss: 8.2479e-04\n",
      "Epoch 149/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.0273e-04 - val_loss: 8.1058e-04\n",
      "Epoch 150/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 5.8810e-04 - val_loss: 8.0402e-04\n",
      "Epoch 151/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.9406e-04 - val_loss: 7.9878e-04\n",
      "Epoch 152/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 6.0212e-04 - val_loss: 7.9849e-04\n",
      "Epoch 153/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 5.8648e-04 - val_loss: 7.9966e-04\n",
      "Epoch 154/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 5.6943e-04 - val_loss: 8.0946e-04\n",
      "Epoch 155/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.7282e-04 - val_loss: 7.8291e-04\n",
      "Epoch 156/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.6814e-04 - val_loss: 7.7650e-04\n",
      "Epoch 157/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8628e-04 - val_loss: 7.7858e-04\n",
      "Epoch 158/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.6803e-04 - val_loss: 7.7841e-04\n",
      "Epoch 159/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.7021e-04 - val_loss: 7.6805e-04\n",
      "Epoch 160/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 5.7328e-04 - val_loss: 7.6880e-04\n",
      "Epoch 161/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 5.4303e-04 - val_loss: 7.5910e-04\n",
      "Epoch 162/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 5.8103e-04 - val_loss: 7.6439e-04\n",
      "Epoch 163/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 5.5460e-04 - val_loss: 7.8299e-04\n",
      "Epoch 164/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.4888e-04 - val_loss: 7.5966e-04\n",
      "Epoch 165/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 5.6047e-04 - val_loss: 7.5212e-04\n",
      "Epoch 166/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 5.4449e-04 - val_loss: 7.5402e-04\n",
      "Epoch 167/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.2897e-04 - val_loss: 7.4572e-04\n",
      "Epoch 168/1000\n",
      "174/174 [==============================] - 0s 965us/step - loss: 5.5587e-04 - val_loss: 7.4241e-04\n",
      "Epoch 169/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 5.2249e-04 - val_loss: 7.4433e-04\n",
      "Epoch 170/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 5.3642e-04 - val_loss: 7.3502e-04\n",
      "Epoch 171/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 5.3241e-04 - val_loss: 7.3671e-04\n",
      "Epoch 172/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.2502e-04 - val_loss: 7.3096e-04\n",
      "Epoch 173/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.3013e-04 - val_loss: 7.4146e-04\n",
      "Epoch 174/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 5.3691e-04 - val_loss: 7.2426e-04\n",
      "Epoch 175/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 5.0726e-04 - val_loss: 7.3352e-04\n",
      "Epoch 176/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 5.0785e-04 - val_loss: 7.2378e-04\n",
      "Epoch 177/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 5.3349e-04 - val_loss: 7.2716e-04\n",
      "Epoch 178/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 5.0912e-04 - val_loss: 7.1871e-04\n",
      "Epoch 179/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 5.2202e-04 - val_loss: 7.1438e-04\n",
      "Epoch 180/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9924e-04 - val_loss: 7.2542e-04\n",
      "Epoch 181/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.1606e-04 - val_loss: 7.1104e-04\n",
      "Epoch 182/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8312e-04 - val_loss: 7.1531e-04\n",
      "Epoch 183/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 4.7812e-04 - val_loss: 7.1091e-04\n",
      "Epoch 184/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 5.1020e-04 - val_loss: 7.0465e-04\n",
      "Epoch 185/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8974e-04 - val_loss: 7.0931e-04\n",
      "Epoch 186/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8259e-04 - val_loss: 7.0529e-04\n",
      "Epoch 187/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8228e-04 - val_loss: 7.0815e-04\n",
      "Epoch 188/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 5.0836e-04 - val_loss: 6.9958e-04\n",
      "Epoch 189/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 4.7650e-04 - val_loss: 6.9802e-04\n",
      "Epoch 190/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 4.7485e-04 - val_loss: 6.8988e-04\n",
      "Epoch 191/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 4.5589e-04 - val_loss: 6.8595e-04\n",
      "Epoch 192/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 4.9943e-04 - val_loss: 7.0437e-04\n",
      "Epoch 193/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 4.8554e-04 - val_loss: 6.9940e-04\n",
      "Epoch 194/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 4.6901e-04 - val_loss: 6.8815e-04\n",
      "Epoch 195/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9434e-04 - val_loss: 6.9456e-04\n",
      "Epoch 196/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.7960e-04 - val_loss: 6.8323e-04\n",
      "Epoch 197/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5026e-04 - val_loss: 6.7623e-04\n",
      "Epoch 198/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8002e-04 - val_loss: 6.8255e-04\n",
      "Epoch 199/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6415e-04 - val_loss: 6.7532e-04\n",
      "Epoch 200/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 4.6294e-04 - val_loss: 6.8284e-04\n",
      "Epoch 201/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.7121e-04 - val_loss: 6.7153e-04\n",
      "Epoch 202/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 4.4873e-04 - val_loss: 6.7109e-04\n",
      "Epoch 203/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4611e-04 - val_loss: 6.7565e-04\n",
      "Epoch 204/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.7388e-04 - val_loss: 7.0135e-04\n",
      "Epoch 205/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6828e-04 - val_loss: 6.7317e-04\n",
      "Epoch 206/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 4.5375e-04 - val_loss: 6.6193e-04\n",
      "Epoch 207/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5284e-04 - val_loss: 6.7285e-04\n",
      "Epoch 208/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6605e-04 - val_loss: 6.6443e-04\n",
      "Epoch 209/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5321e-04 - val_loss: 6.8066e-04\n",
      "Epoch 210/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8101e-04 - val_loss: 6.7365e-04\n",
      "Epoch 211/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 4.5663e-04 - val_loss: 6.6350e-04\n",
      "Epoch 212/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5192e-04 - val_loss: 6.6007e-04\n",
      "Epoch 213/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 4.4250e-04 - val_loss: 6.5671e-04\n",
      "Epoch 214/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 4.5317e-04 - val_loss: 6.5550e-04\n",
      "Epoch 215/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 4.4064e-04 - val_loss: 6.5618e-04\n",
      "Epoch 216/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4018e-04 - val_loss: 6.5095e-04\n",
      "Epoch 217/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4090e-04 - val_loss: 6.4738e-04\n",
      "Epoch 218/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3683e-04 - val_loss: 6.5578e-04\n",
      "Epoch 219/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3849e-04 - val_loss: 6.4291e-04\n",
      "Epoch 220/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.1729e-04 - val_loss: 6.4550e-04\n",
      "Epoch 221/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 4.3003e-04 - val_loss: 6.5227e-04\n",
      "Epoch 222/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 4.2267e-04 - val_loss: 6.6338e-04\n",
      "Epoch 223/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 4.5585e-04 - val_loss: 6.3737e-04\n",
      "Epoch 224/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2962e-04 - val_loss: 6.3921e-04\n",
      "Epoch 225/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 4.4446e-04 - val_loss: 6.3911e-04\n",
      "Epoch 226/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1715e-04 - val_loss: 6.3814e-04\n",
      "Epoch 227/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 4.2537e-04 - val_loss: 6.3449e-04\n",
      "Epoch 228/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 4.3249e-04 - val_loss: 6.3136e-04\n",
      "Epoch 229/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0767e-04 - val_loss: 6.3188e-04\n",
      "Epoch 230/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1317e-04 - val_loss: 6.3265e-04\n",
      "Epoch 231/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 4.1778e-04 - val_loss: 6.3704e-04\n",
      "Epoch 232/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1950e-04 - val_loss: 6.3223e-04\n",
      "Epoch 233/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0896e-04 - val_loss: 6.3665e-04\n",
      "Epoch 234/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 4.3721e-04 - val_loss: 6.3353e-04\n",
      "Epoch 235/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2374e-04 - val_loss: 6.2544e-04\n",
      "Epoch 236/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1196e-04 - val_loss: 6.3931e-04\n",
      "Epoch 237/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 4.1133e-04 - val_loss: 6.2696e-04\n",
      "Epoch 238/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2621e-04 - val_loss: 6.2040e-04\n",
      "Epoch 239/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1731e-04 - val_loss: 6.2879e-04\n",
      "Epoch 240/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1044e-04 - val_loss: 6.2075e-04\n",
      "Epoch 241/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0469e-04 - val_loss: 6.2307e-04\n",
      "Epoch 242/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9582e-04 - val_loss: 6.2310e-04\n",
      "Epoch 243/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.9792e-04 - val_loss: 6.1633e-04\n",
      "Epoch 244/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1660e-04 - val_loss: 6.3055e-04\n",
      "Epoch 245/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 4.2155e-04 - val_loss: 6.1477e-04\n",
      "Epoch 246/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 4.0260e-04 - val_loss: 6.1451e-04\n",
      "Epoch 247/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9045e-04 - val_loss: 6.1567e-04\n",
      "Epoch 248/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7634e-04 - val_loss: 6.1328e-04\n",
      "Epoch 249/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 3.9548e-04 - val_loss: 6.3451e-04\n",
      "Epoch 250/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 3.9282e-04 - val_loss: 6.0585e-04\n",
      "Epoch 251/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 4.0045e-04 - val_loss: 6.0691e-04\n",
      "Epoch 252/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2091e-04 - val_loss: 6.1221e-04\n",
      "Epoch 253/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9721e-04 - val_loss: 6.0956e-04\n",
      "Epoch 254/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 3.9560e-04 - val_loss: 6.1333e-04\n",
      "Epoch 255/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0634e-04 - val_loss: 6.0860e-04\n",
      "Epoch 256/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 3.9239e-04 - val_loss: 6.0666e-04\n",
      "Epoch 257/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7750e-04 - val_loss: 6.0632e-04\n",
      "Epoch 258/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.8450e-04 - val_loss: 6.0202e-04\n",
      "Epoch 259/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 4.0621e-04 - val_loss: 6.0543e-04\n",
      "Epoch 260/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.8762e-04 - val_loss: 6.0212e-04\n",
      "Epoch 261/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 3.7272e-04 - val_loss: 6.1475e-04\n",
      "Epoch 262/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.8930e-04 - val_loss: 6.0290e-04\n",
      "Epoch 263/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.7027e-04 - val_loss: 5.9581e-04\n",
      "Epoch 264/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 3.7374e-04 - val_loss: 6.0176e-04\n",
      "Epoch 265/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7862e-04 - val_loss: 5.9852e-04\n",
      "Epoch 266/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7966e-04 - val_loss: 5.9436e-04\n",
      "Epoch 267/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 3.8032e-04 - val_loss: 5.9631e-04\n",
      "Epoch 268/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8105e-04 - val_loss: 5.9657e-04\n",
      "Epoch 269/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8537e-04 - val_loss: 6.0517e-04\n",
      "Epoch 270/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7629e-04 - val_loss: 5.9529e-04\n",
      "Epoch 271/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.7509e-04 - val_loss: 5.9444e-04\n",
      "Epoch 272/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 3.7451e-04 - val_loss: 5.8931e-04\n",
      "Epoch 273/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8739e-04 - val_loss: 5.9123e-04\n",
      "Epoch 274/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8881e-04 - val_loss: 5.9260e-04\n",
      "Epoch 275/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8244e-04 - val_loss: 5.9759e-04\n",
      "Epoch 276/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 3.7488e-04 - val_loss: 5.8541e-04\n",
      "Epoch 277/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.6069e-04 - val_loss: 5.8339e-04\n",
      "Epoch 278/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 3.8348e-04 - val_loss: 5.8657e-04\n",
      "Epoch 279/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.7156e-04 - val_loss: 5.9007e-04\n",
      "Epoch 280/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 3.8631e-04 - val_loss: 5.8362e-04\n",
      "Epoch 281/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6604e-04 - val_loss: 5.8286e-04\n",
      "Epoch 282/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 3.6804e-04 - val_loss: 5.8734e-04\n",
      "Epoch 283/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7766e-04 - val_loss: 5.8700e-04\n",
      "Epoch 284/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6291e-04 - val_loss: 5.8718e-04\n",
      "Epoch 285/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6052e-04 - val_loss: 5.8190e-04\n",
      "Epoch 286/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.7598e-04 - val_loss: 5.9284e-04\n",
      "Epoch 287/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5018e-04 - val_loss: 5.8289e-04\n",
      "Epoch 288/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5836e-04 - val_loss: 5.7570e-04\n",
      "Epoch 289/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 3.5852e-04 - val_loss: 5.8816e-04\n",
      "Epoch 290/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6597e-04 - val_loss: 5.8414e-04\n",
      "Epoch 291/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.5216e-04 - val_loss: 5.7634e-04\n",
      "Epoch 292/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.5940e-04 - val_loss: 5.7468e-04\n",
      "Epoch 293/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 3.6173e-04 - val_loss: 5.8235e-04\n",
      "Epoch 294/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.5648e-04 - val_loss: 5.7549e-04\n",
      "Epoch 295/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 3.5652e-04 - val_loss: 5.7053e-04\n",
      "Epoch 296/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6706e-04 - val_loss: 5.8264e-04\n",
      "Epoch 297/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6295e-04 - val_loss: 5.7685e-04\n",
      "Epoch 298/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4247e-04 - val_loss: 5.7964e-04\n",
      "Epoch 299/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5925e-04 - val_loss: 5.7272e-04\n",
      "Epoch 300/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5493e-04 - val_loss: 5.6816e-04\n",
      "Epoch 301/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.5646e-04 - val_loss: 5.6757e-04\n",
      "Epoch 302/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.5161e-04 - val_loss: 5.7064e-04\n",
      "Epoch 303/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5365e-04 - val_loss: 5.6860e-04\n",
      "Epoch 304/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 3.4229e-04 - val_loss: 5.6430e-04\n",
      "Epoch 305/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4786e-04 - val_loss: 5.7416e-04\n",
      "Epoch 306/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4453e-04 - val_loss: 5.7099e-04\n",
      "Epoch 307/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.3283e-04 - val_loss: 5.6728e-04\n",
      "Epoch 308/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.5410e-04 - val_loss: 5.6958e-04\n",
      "Epoch 309/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.5731e-04 - val_loss: 5.7388e-04\n",
      "Epoch 310/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.5077e-04 - val_loss: 5.8074e-04\n",
      "Epoch 311/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 3.3173e-04 - val_loss: 5.6225e-04\n",
      "Epoch 312/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 3.3935e-04 - val_loss: 5.6517e-04\n",
      "Epoch 313/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 3.4439e-04 - val_loss: 5.6245e-04\n",
      "Epoch 314/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.4783e-04 - val_loss: 5.6406e-04\n",
      "Epoch 315/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.3513e-04 - val_loss: 5.6040e-04\n",
      "Epoch 316/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2957e-04 - val_loss: 5.5670e-04\n",
      "Epoch 317/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5421e-04 - val_loss: 5.6726e-04\n",
      "Epoch 318/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.3543e-04 - val_loss: 5.6083e-04\n",
      "Epoch 319/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2607e-04 - val_loss: 5.6256e-04\n",
      "Epoch 320/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2766e-04 - val_loss: 5.5625e-04\n",
      "Epoch 321/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 3.2781e-04 - val_loss: 5.5970e-04\n",
      "Epoch 322/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3165e-04 - val_loss: 5.5457e-04\n",
      "Epoch 323/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.5207e-04 - val_loss: 5.6796e-04\n",
      "Epoch 324/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2891e-04 - val_loss: 5.7205e-04\n",
      "Epoch 325/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3858e-04 - val_loss: 5.5981e-04\n",
      "Epoch 326/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.3805e-04 - val_loss: 5.6037e-04\n",
      "Epoch 327/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.3134e-04 - val_loss: 5.6939e-04\n",
      "Epoch 328/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 3.3231e-04 - val_loss: 5.6625e-04\n",
      "Epoch 329/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4119e-04 - val_loss: 5.5090e-04\n",
      "Epoch 330/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2598e-04 - val_loss: 5.6721e-04\n",
      "Epoch 331/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2525e-04 - val_loss: 5.4977e-04\n",
      "Epoch 332/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.3725e-04 - val_loss: 5.5763e-04\n",
      "Epoch 333/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 3.2497e-04 - val_loss: 5.5311e-04\n",
      "Epoch 334/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 3.3974e-04 - val_loss: 5.5020e-04\n",
      "Epoch 335/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2884e-04 - val_loss: 5.7316e-04\n",
      "Epoch 336/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3090e-04 - val_loss: 5.5296e-04\n",
      "Epoch 337/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.1014e-04 - val_loss: 5.4869e-04\n",
      "Epoch 338/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 3.3704e-04 - val_loss: 5.5034e-04\n",
      "Epoch 339/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.3696e-04 - val_loss: 5.5546e-04\n",
      "Epoch 340/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.3584e-04 - val_loss: 5.4534e-04\n",
      "Epoch 341/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2115e-04 - val_loss: 5.6222e-04\n",
      "Epoch 342/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2333e-04 - val_loss: 5.5599e-04\n",
      "Epoch 343/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0679e-04 - val_loss: 5.6084e-04\n",
      "Epoch 344/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2458e-04 - val_loss: 5.6126e-04\n",
      "Epoch 345/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3975e-04 - val_loss: 5.4672e-04\n",
      "Epoch 346/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4034e-04 - val_loss: 5.5265e-04\n",
      "Epoch 347/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0789e-04 - val_loss: 5.5150e-04\n",
      "Epoch 348/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.1710e-04 - val_loss: 5.4361e-04\n",
      "Epoch 349/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.1965e-04 - val_loss: 5.5739e-04\n",
      "Epoch 350/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 3.1518e-04 - val_loss: 5.4911e-04\n",
      "Epoch 351/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.2040e-04 - val_loss: 5.5301e-04\n",
      "Epoch 352/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2381e-04 - val_loss: 5.4896e-04\n",
      "Epoch 353/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.2120e-04 - val_loss: 5.4291e-04\n",
      "Epoch 354/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.3053e-04 - val_loss: 5.4404e-04\n",
      "Epoch 355/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9545e-04 - val_loss: 5.4081e-04\n",
      "Epoch 356/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1598e-04 - val_loss: 5.4725e-04\n",
      "Epoch 357/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.0291e-04 - val_loss: 5.4182e-04\n",
      "Epoch 358/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9624e-04 - val_loss: 5.4080e-04\n",
      "Epoch 359/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1525e-04 - val_loss: 5.3578e-04\n",
      "Epoch 360/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2225e-04 - val_loss: 5.3958e-04\n",
      "Epoch 361/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1314e-04 - val_loss: 5.4775e-04\n",
      "Epoch 362/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 3.0612e-04 - val_loss: 5.3967e-04\n",
      "Epoch 363/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.9784e-04 - val_loss: 5.4092e-04\n",
      "Epoch 364/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1753e-04 - val_loss: 5.5353e-04\n",
      "Epoch 365/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 3.2230e-04 - val_loss: 5.3659e-04\n",
      "Epoch 366/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.1179e-04 - val_loss: 5.3420e-04\n",
      "Epoch 367/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1302e-04 - val_loss: 5.3833e-04\n",
      "Epoch 368/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.0962e-04 - val_loss: 5.3826e-04\n",
      "Epoch 369/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 3.1060e-04 - val_loss: 5.4320e-04\n",
      "Epoch 370/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.1448e-04 - val_loss: 5.3749e-04\n",
      "Epoch 371/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.0184e-04 - val_loss: 5.3205e-04\n",
      "Epoch 372/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.9785e-04 - val_loss: 5.3166e-04\n",
      "Epoch 373/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2156e-04 - val_loss: 5.3147e-04\n",
      "Epoch 374/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0760e-04 - val_loss: 5.4727e-04\n",
      "Epoch 375/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.9792e-04 - val_loss: 5.4241e-04\n",
      "Epoch 376/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 3.0777e-04 - val_loss: 5.4331e-04\n",
      "Epoch 377/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 3.0113e-04 - val_loss: 5.3078e-04\n",
      "Epoch 378/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.9711e-04 - val_loss: 5.4791e-04\n",
      "Epoch 379/1000\n",
      "174/174 [==============================] - 0s 966us/step - loss: 2.9656e-04 - val_loss: 5.4676e-04\n",
      "Epoch 380/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.9229e-04 - val_loss: 5.3594e-04\n",
      "Epoch 381/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9268e-04 - val_loss: 5.4253e-04\n",
      "Epoch 382/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1529e-04 - val_loss: 5.3906e-04\n",
      "Epoch 383/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.9789e-04 - val_loss: 5.2909e-04\n",
      "Epoch 384/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.0703e-04 - val_loss: 5.2926e-04\n",
      "Epoch 385/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.9854e-04 - val_loss: 5.3787e-04\n",
      "Epoch 386/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.8658e-04 - val_loss: 5.2660e-04\n",
      "Epoch 387/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9355e-04 - val_loss: 5.2820e-04\n",
      "Epoch 388/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.9466e-04 - val_loss: 5.3369e-04\n",
      "Epoch 389/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.9687e-04 - val_loss: 5.2709e-04\n",
      "Epoch 390/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.1089e-04 - val_loss: 5.3104e-04\n",
      "Epoch 391/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.9489e-04 - val_loss: 5.3313e-04\n",
      "Epoch 392/1000\n",
      "174/174 [==============================] - 0s 968us/step - loss: 2.9580e-04 - val_loss: 5.2659e-04\n",
      "Epoch 393/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.7899e-04 - val_loss: 5.2525e-04\n",
      "Epoch 394/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8633e-04 - val_loss: 5.3735e-04\n",
      "Epoch 395/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0021e-04 - val_loss: 5.3120e-04\n",
      "Epoch 396/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9712e-04 - val_loss: 5.3810e-04\n",
      "Epoch 397/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9629e-04 - val_loss: 5.3287e-04\n",
      "Epoch 398/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8677e-04 - val_loss: 5.2810e-04\n",
      "Epoch 399/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9076e-04 - val_loss: 5.2267e-04\n",
      "Epoch 400/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.8148e-04 - val_loss: 5.2867e-04\n",
      "Epoch 401/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.8355e-04 - val_loss: 5.4149e-04\n",
      "Epoch 402/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8090e-04 - val_loss: 5.2691e-04\n",
      "Epoch 403/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9390e-04 - val_loss: 5.2839e-04\n",
      "Epoch 404/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 2.7551e-04 - val_loss: 5.2399e-04\n",
      "Epoch 405/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.9350e-04 - val_loss: 5.2460e-04\n",
      "Epoch 406/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.7360e-04 - val_loss: 5.2477e-04\n",
      "Epoch 407/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8746e-04 - val_loss: 5.2362e-04\n",
      "Epoch 408/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.9586e-04 - val_loss: 5.1984e-04\n",
      "Epoch 409/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8597e-04 - val_loss: 5.2065e-04\n",
      "Epoch 410/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8596e-04 - val_loss: 5.2125e-04\n",
      "Epoch 411/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9255e-04 - val_loss: 5.2359e-04\n",
      "Epoch 412/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.7013e-04 - val_loss: 5.2780e-04\n",
      "Epoch 413/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9503e-04 - val_loss: 5.2127e-04\n",
      "Epoch 414/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8696e-04 - val_loss: 5.2495e-04\n",
      "Epoch 415/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.7962e-04 - val_loss: 5.1790e-04\n",
      "Epoch 416/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7062e-04 - val_loss: 5.2456e-04\n",
      "Epoch 417/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7706e-04 - val_loss: 5.1734e-04\n",
      "Epoch 418/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.6143e-04 - val_loss: 5.2430e-04\n",
      "Epoch 419/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.8909e-04 - val_loss: 5.1650e-04\n",
      "Epoch 420/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.9346e-04 - val_loss: 5.1789e-04\n",
      "Epoch 421/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.7740e-04 - val_loss: 5.2356e-04\n",
      "Epoch 422/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.7974e-04 - val_loss: 5.1863e-04\n",
      "Epoch 423/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7118e-04 - val_loss: 5.1913e-04\n",
      "Epoch 424/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.8953e-04 - val_loss: 5.2046e-04\n",
      "Epoch 425/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7550e-04 - val_loss: 5.2116e-04\n",
      "Epoch 426/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8529e-04 - val_loss: 5.1618e-04\n",
      "Epoch 427/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7641e-04 - val_loss: 5.1647e-04\n",
      "Epoch 428/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8281e-04 - val_loss: 5.1379e-04\n",
      "Epoch 429/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7476e-04 - val_loss: 5.2291e-04\n",
      "Epoch 430/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6915e-04 - val_loss: 5.2112e-04\n",
      "Epoch 431/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6870e-04 - val_loss: 5.1496e-04\n",
      "Epoch 432/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6119e-04 - val_loss: 5.1698e-04\n",
      "Epoch 433/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.7168e-04 - val_loss: 5.1679e-04\n",
      "Epoch 434/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.7937e-04 - val_loss: 5.2631e-04\n",
      "Epoch 435/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 2.7976e-04 - val_loss: 5.2503e-04\n",
      "Epoch 436/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6504e-04 - val_loss: 5.1408e-04\n",
      "Epoch 437/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 2.9138e-04 - val_loss: 5.1852e-04\n",
      "Epoch 438/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 2.6537e-04 - val_loss: 5.2221e-04\n",
      "Epoch 439/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7283e-04 - val_loss: 5.1372e-04\n",
      "Epoch 440/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7589e-04 - val_loss: 5.2232e-04\n",
      "Epoch 441/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.6178e-04 - val_loss: 5.1631e-04\n",
      "Epoch 442/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6303e-04 - val_loss: 5.1166e-04\n",
      "Epoch 443/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6339e-04 - val_loss: 5.1373e-04\n",
      "Epoch 444/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7320e-04 - val_loss: 5.1704e-04\n",
      "Epoch 445/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5397e-04 - val_loss: 5.1530e-04\n",
      "Epoch 446/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7045e-04 - val_loss: 5.1068e-04\n",
      "Epoch 447/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.7266e-04 - val_loss: 5.1220e-04\n",
      "Epoch 448/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.7359e-04 - val_loss: 5.0983e-04\n",
      "Epoch 449/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.6181e-04 - val_loss: 5.1777e-04\n",
      "Epoch 450/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.7457e-04 - val_loss: 5.1094e-04\n",
      "Epoch 451/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.5589e-04 - val_loss: 5.1918e-04\n",
      "Epoch 452/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6638e-04 - val_loss: 5.0603e-04\n",
      "Epoch 453/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7220e-04 - val_loss: 5.0907e-04\n",
      "Epoch 454/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5210e-04 - val_loss: 5.0812e-04\n",
      "Epoch 455/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.6918e-04 - val_loss: 5.1308e-04\n",
      "Epoch 456/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.7439e-04 - val_loss: 5.1035e-04\n",
      "Epoch 457/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.6377e-04 - val_loss: 5.0496e-04\n",
      "Epoch 458/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 2.6815e-04 - val_loss: 5.2070e-04\n",
      "Epoch 459/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8274e-04 - val_loss: 5.1073e-04\n",
      "Epoch 460/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6552e-04 - val_loss: 5.0547e-04\n",
      "Epoch 461/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.6769e-04 - val_loss: 5.0638e-04\n",
      "Epoch 462/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.6419e-04 - val_loss: 5.0773e-04\n",
      "Epoch 463/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.4157e-04 - val_loss: 5.1879e-04\n",
      "Epoch 464/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.5804e-04 - val_loss: 5.0903e-04\n",
      "Epoch 465/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5872e-04 - val_loss: 5.0828e-04\n",
      "Epoch 466/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.5818e-04 - val_loss: 5.0720e-04\n",
      "Epoch 467/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.6004e-04 - val_loss: 5.1170e-04\n",
      "Epoch 468/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5596e-04 - val_loss: 5.0548e-04\n",
      "Epoch 469/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.5311e-04 - val_loss: 5.0844e-04\n",
      "Epoch 470/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5997e-04 - val_loss: 5.0615e-04\n",
      "Epoch 471/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5672e-04 - val_loss: 5.0601e-04\n",
      "Epoch 472/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.6957e-04 - val_loss: 5.0674e-04\n",
      "Epoch 473/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4988e-04 - val_loss: 5.0741e-04\n",
      "Epoch 474/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6469e-04 - val_loss: 5.1818e-04\n",
      "Epoch 475/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.4886e-04 - val_loss: 5.1700e-04\n",
      "Epoch 476/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.6443e-04 - val_loss: 5.0268e-04\n",
      "Epoch 477/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.5652e-04 - val_loss: 5.0631e-04\n",
      "Epoch 478/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4099e-04 - val_loss: 5.0734e-04\n",
      "Epoch 479/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5316e-04 - val_loss: 5.0745e-04\n",
      "Epoch 480/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7179e-04 - val_loss: 5.0540e-04\n",
      "Epoch 481/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.5394e-04 - val_loss: 5.1374e-04\n",
      "Epoch 482/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3864e-04 - val_loss: 5.0380e-04\n",
      "Epoch 483/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6101e-04 - val_loss: 5.0519e-04\n",
      "Epoch 484/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4777e-04 - val_loss: 5.0066e-04\n",
      "Epoch 485/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5475e-04 - val_loss: 5.0265e-04\n",
      "Epoch 486/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4593e-04 - val_loss: 5.0036e-04\n",
      "Epoch 487/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4364e-04 - val_loss: 5.0897e-04\n",
      "Epoch 488/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5068e-04 - val_loss: 5.0286e-04\n",
      "Epoch 489/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4489e-04 - val_loss: 5.0646e-04\n",
      "Epoch 490/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 2.4350e-04 - val_loss: 5.0614e-04\n",
      "Epoch 491/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.4681e-04 - val_loss: 5.0233e-04\n",
      "Epoch 492/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.5298e-04 - val_loss: 5.0177e-04\n",
      "Epoch 493/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.4031e-04 - val_loss: 5.0831e-04\n",
      "Epoch 494/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.5172e-04 - val_loss: 5.0716e-04\n",
      "Epoch 495/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.5229e-04 - val_loss: 5.0301e-04\n",
      "Epoch 496/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.4069e-04 - val_loss: 4.9883e-04\n",
      "Epoch 497/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.3040e-04 - val_loss: 4.9950e-04\n",
      "Epoch 498/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.5737e-04 - val_loss: 5.0111e-04\n",
      "Epoch 499/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4726e-04 - val_loss: 5.0687e-04\n",
      "Epoch 500/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.4909e-04 - val_loss: 5.0365e-04\n",
      "Epoch 501/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3461e-04 - val_loss: 5.0113e-04\n",
      "Epoch 502/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4922e-04 - val_loss: 5.0388e-04\n",
      "Epoch 503/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.4801e-04 - val_loss: 4.9654e-04\n",
      "Epoch 504/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.5537e-04 - val_loss: 4.9844e-04\n",
      "Epoch 505/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5265e-04 - val_loss: 5.0066e-04\n",
      "Epoch 506/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4970e-04 - val_loss: 5.0300e-04\n",
      "Epoch 507/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6162e-04 - val_loss: 5.0086e-04\n",
      "Epoch 508/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5117e-04 - val_loss: 5.0159e-04\n",
      "Epoch 509/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4675e-04 - val_loss: 5.1648e-04\n",
      "Epoch 510/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5082e-04 - val_loss: 5.0150e-04\n",
      "Epoch 511/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.4565e-04 - val_loss: 4.9791e-04\n",
      "Epoch 512/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.4094e-04 - val_loss: 4.9902e-04\n",
      "Epoch 513/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3645e-04 - val_loss: 5.0968e-04\n",
      "Epoch 514/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.4224e-04 - val_loss: 5.0409e-04\n",
      "Epoch 515/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.3851e-04 - val_loss: 5.0809e-04\n",
      "Epoch 516/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.6101e-04 - val_loss: 5.0596e-04\n",
      "Epoch 517/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3312e-04 - val_loss: 5.0016e-04\n",
      "Epoch 518/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4174e-04 - val_loss: 4.9533e-04\n",
      "Epoch 519/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3791e-04 - val_loss: 4.9613e-04\n",
      "Epoch 520/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5191e-04 - val_loss: 4.9346e-04\n",
      "Epoch 521/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3849e-04 - val_loss: 4.9768e-04\n",
      "Epoch 522/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4238e-04 - val_loss: 4.9810e-04\n",
      "Epoch 523/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3781e-04 - val_loss: 4.9565e-04\n",
      "Epoch 524/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5126e-04 - val_loss: 4.9482e-04\n",
      "Epoch 525/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3528e-04 - val_loss: 5.0645e-04\n",
      "Epoch 526/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4480e-04 - val_loss: 4.9422e-04\n",
      "Epoch 527/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3833e-04 - val_loss: 5.0773e-04\n",
      "Epoch 528/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4194e-04 - val_loss: 4.9308e-04\n",
      "Epoch 529/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2470e-04 - val_loss: 5.0394e-04\n",
      "Epoch 530/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.2029e-04 - val_loss: 4.9598e-04\n",
      "Epoch 531/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3712e-04 - val_loss: 4.9064e-04\n",
      "Epoch 532/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4092e-04 - val_loss: 4.9380e-04\n",
      "Epoch 533/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.4032e-04 - val_loss: 4.9496e-04\n",
      "Epoch 534/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.4711e-04 - val_loss: 4.9514e-04\n",
      "Epoch 535/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2969e-04 - val_loss: 4.9365e-04\n",
      "Epoch 536/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4089e-04 - val_loss: 5.0350e-04\n",
      "Epoch 537/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.3692e-04 - val_loss: 4.9997e-04\n",
      "Epoch 538/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.3835e-04 - val_loss: 4.9648e-04\n",
      "Epoch 539/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3370e-04 - val_loss: 4.9373e-04\n",
      "Epoch 540/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3057e-04 - val_loss: 4.9358e-04\n",
      "Epoch 541/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3651e-04 - val_loss: 4.9427e-04\n",
      "Epoch 542/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2684e-04 - val_loss: 4.9498e-04\n",
      "Epoch 543/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.3379e-04 - val_loss: 5.0372e-04\n",
      "Epoch 544/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2461e-04 - val_loss: 5.0629e-04\n",
      "Epoch 545/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.3524e-04 - val_loss: 4.9848e-04\n",
      "Epoch 546/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3242e-04 - val_loss: 5.2034e-04\n",
      "Epoch 547/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.3930e-04 - val_loss: 4.9544e-04\n",
      "Epoch 548/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3814e-04 - val_loss: 4.9070e-04\n",
      "Epoch 549/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.3415e-04 - val_loss: 4.9539e-04\n",
      "Epoch 550/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 2.2520e-04 - val_loss: 4.9800e-04\n",
      "Epoch 551/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2286e-04 - val_loss: 4.9090e-04\n",
      "Epoch 552/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.2792e-04 - val_loss: 5.3427e-04\n",
      "Epoch 553/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.3493e-04 - val_loss: 4.9317e-04\n",
      "Epoch 554/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3285e-04 - val_loss: 4.9760e-04\n",
      "Epoch 555/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.2468e-04 - val_loss: 4.9172e-04\n",
      "Epoch 556/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2770e-04 - val_loss: 4.8991e-04\n",
      "Epoch 557/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2912e-04 - val_loss: 5.0334e-04\n",
      "Epoch 558/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3211e-04 - val_loss: 4.9013e-04\n",
      "Epoch 559/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3002e-04 - val_loss: 5.1157e-04\n",
      "Epoch 560/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2323e-04 - val_loss: 4.9213e-04\n",
      "Epoch 561/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2075e-04 - val_loss: 5.0666e-04\n",
      "Epoch 562/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2762e-04 - val_loss: 4.9503e-04\n",
      "Epoch 563/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3330e-04 - val_loss: 4.9078e-04\n",
      "Epoch 564/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.2004e-04 - val_loss: 5.0066e-04\n",
      "Epoch 565/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.2643e-04 - val_loss: 4.8878e-04\n",
      "Epoch 566/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.2319e-04 - val_loss: 5.0452e-04\n",
      "Epoch 567/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.2781e-04 - val_loss: 5.0024e-04\n",
      "Epoch 568/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.3397e-04 - val_loss: 4.8960e-04\n",
      "Epoch 569/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4045e-04 - val_loss: 4.9094e-04\n",
      "Epoch 570/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1447e-04 - val_loss: 4.9679e-04\n",
      "Epoch 571/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2554e-04 - val_loss: 4.9076e-04\n",
      "Epoch 572/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.2458e-04 - val_loss: 4.9312e-04\n",
      "Epoch 573/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3375e-04 - val_loss: 4.9184e-04\n",
      "Epoch 574/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.2914e-04 - val_loss: 4.8901e-04\n",
      "Epoch 575/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.2343e-04 - val_loss: 4.9698e-04\n",
      "Epoch 576/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.2470e-04 - val_loss: 4.8683e-04\n",
      "Epoch 577/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2030e-04 - val_loss: 4.8469e-04\n",
      "Epoch 578/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2551e-04 - val_loss: 4.8762e-04\n",
      "Epoch 579/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2599e-04 - val_loss: 4.9328e-04\n",
      "Epoch 580/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1924e-04 - val_loss: 4.8759e-04\n",
      "Epoch 581/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.1936e-04 - val_loss: 4.8927e-04\n",
      "Epoch 582/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.1889e-04 - val_loss: 5.0353e-04\n",
      "Epoch 583/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2340e-04 - val_loss: 4.8834e-04\n",
      "Epoch 584/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1231e-04 - val_loss: 4.8995e-04\n",
      "Epoch 585/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.1437e-04 - val_loss: 4.8849e-04\n",
      "Epoch 586/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1785e-04 - val_loss: 4.9056e-04\n",
      "Epoch 587/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.1766e-04 - val_loss: 4.9534e-04\n",
      "Epoch 588/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.1619e-04 - val_loss: 4.9063e-04\n",
      "Epoch 589/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.2495e-04 - val_loss: 4.9396e-04\n",
      "Epoch 590/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1713e-04 - val_loss: 4.8678e-04\n",
      "Epoch 591/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.2539e-04 - val_loss: 4.8512e-04\n",
      "Epoch 592/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.2043e-04 - val_loss: 4.9897e-04\n",
      "Epoch 593/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.1143e-04 - val_loss: 5.0369e-04\n",
      "Epoch 594/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1845e-04 - val_loss: 4.8460e-04\n",
      "Epoch 595/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.0832e-04 - val_loss: 4.9997e-04\n",
      "Epoch 596/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.0859e-04 - val_loss: 4.8636e-04\n",
      "Epoch 597/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2194e-04 - val_loss: 4.8373e-04\n",
      "Epoch 598/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.1439e-04 - val_loss: 4.8580e-04\n",
      "Epoch 599/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2319e-04 - val_loss: 4.8955e-04\n",
      "Epoch 600/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1358e-04 - val_loss: 4.8541e-04\n",
      "Epoch 601/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1001e-04 - val_loss: 4.8604e-04\n",
      "Epoch 602/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.1851e-04 - val_loss: 4.8391e-04\n",
      "Epoch 603/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.1240e-04 - val_loss: 4.9746e-04\n",
      "Epoch 604/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.1270e-04 - val_loss: 4.8575e-04\n",
      "Epoch 605/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.1387e-04 - val_loss: 4.8334e-04\n",
      "Epoch 606/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.0482e-04 - val_loss: 4.8863e-04\n",
      "Epoch 607/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.1164e-04 - val_loss: 4.8876e-04\n",
      "Epoch 608/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0929e-04 - val_loss: 4.8582e-04\n",
      "Epoch 609/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.2123e-04 - val_loss: 4.8618e-04\n",
      "Epoch 610/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0944e-04 - val_loss: 4.8596e-04\n",
      "Epoch 611/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2137e-04 - val_loss: 4.8376e-04\n",
      "Epoch 612/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.1929e-04 - val_loss: 4.8848e-04\n",
      "Epoch 613/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0808e-04 - val_loss: 4.8416e-04\n",
      "Epoch 614/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1005e-04 - val_loss: 4.8170e-04\n",
      "Epoch 615/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 2.2130e-04 - val_loss: 4.8830e-04\n",
      "Epoch 616/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1372e-04 - val_loss: 4.8470e-04\n",
      "Epoch 617/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0176e-04 - val_loss: 4.9295e-04\n",
      "Epoch 618/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 2.0994e-04 - val_loss: 4.8030e-04\n",
      "Epoch 619/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 2.0847e-04 - val_loss: 4.9782e-04\n",
      "Epoch 620/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 2.1354e-04 - val_loss: 4.8283e-04\n",
      "Epoch 621/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0398e-04 - val_loss: 4.8702e-04\n",
      "Epoch 622/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2228e-04 - val_loss: 4.8406e-04\n",
      "Epoch 623/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1047e-04 - val_loss: 4.8491e-04\n",
      "Epoch 624/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.9811e-04 - val_loss: 4.8259e-04\n",
      "Epoch 625/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0142e-04 - val_loss: 4.8233e-04\n",
      "Epoch 626/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0864e-04 - val_loss: 4.8265e-04\n",
      "Epoch 627/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 2.0865e-04 - val_loss: 4.8339e-04\n",
      "Epoch 628/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.0388e-04 - val_loss: 4.8650e-04\n",
      "Epoch 629/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 2.2500e-04 - val_loss: 4.8780e-04\n",
      "Epoch 630/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 2.1093e-04 - val_loss: 4.8037e-04\n",
      "Epoch 631/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0588e-04 - val_loss: 4.8490e-04\n",
      "Epoch 632/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0061e-04 - val_loss: 4.8630e-04\n",
      "Epoch 633/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0196e-04 - val_loss: 4.7847e-04\n",
      "Epoch 634/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.9859e-04 - val_loss: 4.8234e-04\n",
      "Epoch 635/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0746e-04 - val_loss: 4.8070e-04\n",
      "Epoch 636/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0683e-04 - val_loss: 4.8323e-04\n",
      "Epoch 637/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0935e-04 - val_loss: 4.8384e-04\n",
      "Epoch 638/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1028e-04 - val_loss: 4.8182e-04\n",
      "Epoch 639/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.1013e-04 - val_loss: 4.8218e-04\n",
      "Epoch 640/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.1027e-04 - val_loss: 4.8147e-04\n",
      "Epoch 641/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.9934e-04 - val_loss: 4.8675e-04\n",
      "Epoch 642/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.1452e-04 - val_loss: 4.7946e-04\n",
      "Epoch 643/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0040e-04 - val_loss: 4.8452e-04\n",
      "Epoch 644/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.9267e-04 - val_loss: 4.8831e-04\n",
      "Epoch 645/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 2.1535e-04 - val_loss: 4.8678e-04\n",
      "Epoch 646/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.9970e-04 - val_loss: 4.7955e-04\n",
      "Epoch 647/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0023e-04 - val_loss: 4.7746e-04\n",
      "Epoch 648/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.9862e-04 - val_loss: 4.8450e-04\n",
      "Epoch 649/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.0716e-04 - val_loss: 4.8820e-04\n",
      "Epoch 650/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.0398e-04 - val_loss: 4.8072e-04\n",
      "Epoch 651/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9531e-04 - val_loss: 4.8053e-04\n",
      "Epoch 652/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.0171e-04 - val_loss: 4.8502e-04\n",
      "Epoch 653/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9690e-04 - val_loss: 4.8564e-04\n",
      "Epoch 654/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0190e-04 - val_loss: 4.8716e-04\n",
      "Epoch 655/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.9509e-04 - val_loss: 4.8659e-04\n",
      "Epoch 656/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.0357e-04 - val_loss: 5.0003e-04\n",
      "Epoch 657/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.9483e-04 - val_loss: 4.8419e-04\n",
      "Epoch 658/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.9980e-04 - val_loss: 4.7732e-04\n",
      "Epoch 659/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9736e-04 - val_loss: 4.8841e-04\n",
      "Epoch 660/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9607e-04 - val_loss: 4.7764e-04\n",
      "Epoch 661/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9651e-04 - val_loss: 4.8012e-04\n",
      "Epoch 662/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.9100e-04 - val_loss: 4.8819e-04\n",
      "Epoch 663/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9959e-04 - val_loss: 4.7703e-04\n",
      "Epoch 664/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9719e-04 - val_loss: 4.7770e-04\n",
      "Epoch 665/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.9576e-04 - val_loss: 4.7725e-04\n",
      "Epoch 666/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0364e-04 - val_loss: 4.7726e-04\n",
      "Epoch 667/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.9177e-04 - val_loss: 4.7709e-04\n",
      "Epoch 668/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.0103e-04 - val_loss: 4.8621e-04\n",
      "Epoch 669/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9848e-04 - val_loss: 4.8009e-04\n",
      "Epoch 670/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9543e-04 - val_loss: 4.8743e-04\n",
      "Epoch 671/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.0144e-04 - val_loss: 4.7934e-04\n",
      "Epoch 672/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.9360e-04 - val_loss: 4.8146e-04\n",
      "Epoch 673/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.0182e-04 - val_loss: 4.8123e-04\n",
      "Epoch 674/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.8724e-04 - val_loss: 4.7734e-04\n",
      "Epoch 675/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9506e-04 - val_loss: 4.7956e-04\n",
      "Epoch 676/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.8980e-04 - val_loss: 4.7735e-04\n",
      "Epoch 677/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9315e-04 - val_loss: 4.7918e-04\n",
      "Epoch 678/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.8989e-04 - val_loss: 4.7717e-04\n",
      "Epoch 679/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.0608e-04 - val_loss: 4.8307e-04\n",
      "Epoch 680/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.9218e-04 - val_loss: 4.8450e-04\n",
      "Epoch 681/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.8546e-04 - val_loss: 4.8059e-04\n",
      "Epoch 682/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9906e-04 - val_loss: 4.7953e-04\n",
      "Epoch 683/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8802e-04 - val_loss: 4.8007e-04\n",
      "Epoch 684/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.8948e-04 - val_loss: 4.7802e-04\n",
      "Epoch 685/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.9783e-04 - val_loss: 4.7777e-04\n",
      "Epoch 686/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.8847e-04 - val_loss: 4.7900e-04\n",
      "Epoch 687/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.9527e-04 - val_loss: 4.7998e-04\n",
      "Epoch 688/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.8072e-04 - val_loss: 4.8581e-04\n",
      "Epoch 689/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9417e-04 - val_loss: 4.8129e-04\n",
      "Epoch 690/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9380e-04 - val_loss: 4.8074e-04\n",
      "Epoch 691/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8992e-04 - val_loss: 4.7514e-04\n",
      "Epoch 692/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9455e-04 - val_loss: 4.8103e-04\n",
      "Epoch 693/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8627e-04 - val_loss: 4.8031e-04\n",
      "Epoch 694/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8747e-04 - val_loss: 4.7437e-04\n",
      "Epoch 695/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8228e-04 - val_loss: 4.8748e-04\n",
      "Epoch 696/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8897e-04 - val_loss: 4.7743e-04\n",
      "Epoch 697/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9327e-04 - val_loss: 4.7873e-04\n",
      "Epoch 698/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8791e-04 - val_loss: 4.7460e-04\n",
      "Epoch 699/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8402e-04 - val_loss: 4.8380e-04\n",
      "Epoch 700/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8189e-04 - val_loss: 4.7470e-04\n",
      "Epoch 701/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9253e-04 - val_loss: 4.8158e-04\n",
      "Epoch 702/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8771e-04 - val_loss: 4.7463e-04\n",
      "Epoch 703/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9327e-04 - val_loss: 4.7581e-04\n",
      "Epoch 704/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7790e-04 - val_loss: 4.7638e-04\n",
      "Epoch 705/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.8551e-04 - val_loss: 4.8929e-04\n",
      "Epoch 706/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 1.9428e-04 - val_loss: 4.7551e-04\n",
      "Epoch 707/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8905e-04 - val_loss: 4.7517e-04\n",
      "Epoch 708/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.9229e-04 - val_loss: 4.8048e-04\n",
      "Epoch 709/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9495e-04 - val_loss: 4.7591e-04\n",
      "Epoch 710/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8416e-04 - val_loss: 4.9692e-04\n",
      "Epoch 711/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.9892e-04 - val_loss: 4.7373e-04\n",
      "Epoch 712/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9650e-04 - val_loss: 4.7552e-04\n",
      "Epoch 713/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8944e-04 - val_loss: 4.7699e-04\n",
      "Epoch 714/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8432e-04 - val_loss: 4.7763e-04\n",
      "Epoch 715/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9143e-04 - val_loss: 4.8332e-04\n",
      "Epoch 716/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.9130e-04 - val_loss: 4.7856e-04\n",
      "Epoch 717/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8235e-04 - val_loss: 4.7957e-04\n",
      "Epoch 718/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8604e-04 - val_loss: 4.8092e-04\n",
      "Epoch 719/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8863e-04 - val_loss: 4.7972e-04\n",
      "Epoch 720/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9327e-04 - val_loss: 4.7939e-04\n",
      "Epoch 721/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8936e-04 - val_loss: 4.7305e-04\n",
      "Epoch 722/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8144e-04 - val_loss: 4.8364e-04\n",
      "Epoch 723/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8480e-04 - val_loss: 4.8089e-04\n",
      "Epoch 724/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.8159e-04 - val_loss: 4.7213e-04\n",
      "Epoch 725/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8007e-04 - val_loss: 4.7608e-04\n",
      "Epoch 726/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8202e-04 - val_loss: 4.7455e-04\n",
      "Epoch 727/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8473e-04 - val_loss: 4.7362e-04\n",
      "Epoch 728/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8242e-04 - val_loss: 4.8763e-04\n",
      "Epoch 729/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7533e-04 - val_loss: 4.8400e-04\n",
      "Epoch 730/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8721e-04 - val_loss: 4.7948e-04\n",
      "Epoch 731/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.8787e-04 - val_loss: 4.7148e-04\n",
      "Epoch 732/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7991e-04 - val_loss: 4.7739e-04\n",
      "Epoch 733/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.9196e-04 - val_loss: 4.7527e-04\n",
      "Epoch 734/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.8285e-04 - val_loss: 4.7302e-04\n",
      "Epoch 735/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8239e-04 - val_loss: 4.7523e-04\n",
      "Epoch 736/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.8295e-04 - val_loss: 4.7713e-04\n",
      "Epoch 737/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7403e-04 - val_loss: 4.7118e-04\n",
      "Epoch 738/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8332e-04 - val_loss: 4.7307e-04\n",
      "Epoch 739/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.8088e-04 - val_loss: 4.7614e-04\n",
      "Epoch 740/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.7671e-04 - val_loss: 4.7698e-04\n",
      "Epoch 741/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8188e-04 - val_loss: 4.8172e-04\n",
      "Epoch 742/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.7883e-04 - val_loss: 4.7814e-04\n",
      "Epoch 743/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8529e-04 - val_loss: 4.7660e-04\n",
      "Epoch 744/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8621e-04 - val_loss: 4.7754e-04\n",
      "Epoch 745/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.8041e-04 - val_loss: 4.7353e-04\n",
      "Epoch 746/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7825e-04 - val_loss: 4.7325e-04\n",
      "Epoch 747/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7876e-04 - val_loss: 4.7485e-04\n",
      "Epoch 748/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8226e-04 - val_loss: 4.7317e-04\n",
      "Epoch 749/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.7684e-04 - val_loss: 4.7199e-04\n",
      "Epoch 750/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7554e-04 - val_loss: 4.7621e-04\n",
      "Epoch 751/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7905e-04 - val_loss: 4.7964e-04\n",
      "Epoch 752/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.7352e-04 - val_loss: 4.7327e-04\n",
      "Epoch 753/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7533e-04 - val_loss: 4.7506e-04\n",
      "Epoch 754/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.7411e-04 - val_loss: 4.7425e-04\n",
      "Epoch 755/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7060e-04 - val_loss: 4.7422e-04\n",
      "Epoch 756/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.6945e-04 - val_loss: 4.7964e-04\n",
      "Epoch 757/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.8088e-04 - val_loss: 4.8099e-04\n",
      "Epoch 758/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.7937e-04 - val_loss: 4.7009e-04\n",
      "Epoch 759/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.8197e-04 - val_loss: 4.7613e-04\n",
      "Epoch 760/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.7927e-04 - val_loss: 4.7510e-04\n",
      "Epoch 761/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7724e-04 - val_loss: 4.7828e-04\n",
      "Epoch 762/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.7190e-04 - val_loss: 4.7449e-04\n",
      "Epoch 763/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.8276e-04 - val_loss: 4.8930e-04\n",
      "Epoch 764/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8061e-04 - val_loss: 4.7418e-04\n",
      "Epoch 765/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7461e-04 - val_loss: 4.7962e-04\n",
      "Epoch 766/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.8489e-04 - val_loss: 4.7616e-04\n",
      "Epoch 767/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.7299e-04 - val_loss: 4.7741e-04\n",
      "Epoch 768/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7427e-04 - val_loss: 4.7216e-04\n",
      "Epoch 769/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.7574e-04 - val_loss: 4.7470e-04\n",
      "Epoch 770/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7793e-04 - val_loss: 4.8709e-04\n",
      "Epoch 771/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.7954e-04 - val_loss: 4.7147e-04\n",
      "Epoch 772/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7366e-04 - val_loss: 4.7007e-04\n",
      "Epoch 773/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7319e-04 - val_loss: 4.7004e-04\n",
      "Epoch 774/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6991e-04 - val_loss: 4.7038e-04\n",
      "Epoch 775/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.7528e-04 - val_loss: 4.7056e-04\n",
      "Epoch 776/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7262e-04 - val_loss: 4.7247e-04\n",
      "Epoch 777/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.7037e-04 - val_loss: 4.7507e-04\n",
      "Epoch 778/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.8145e-04 - val_loss: 4.7242e-04\n",
      "Epoch 779/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.7170e-04 - val_loss: 4.7385e-04\n",
      "Epoch 780/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.7486e-04 - val_loss: 4.7333e-04\n",
      "Epoch 781/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7816e-04 - val_loss: 4.8265e-04\n",
      "Epoch 782/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.6992e-04 - val_loss: 4.8017e-04\n",
      "Epoch 783/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.7438e-04 - val_loss: 4.7422e-04\n",
      "Epoch 784/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.6713e-04 - val_loss: 4.6898e-04\n",
      "Epoch 785/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7037e-04 - val_loss: 4.7342e-04\n",
      "Epoch 786/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7204e-04 - val_loss: 4.7096e-04\n",
      "Epoch 787/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.6466e-04 - val_loss: 4.7499e-04\n",
      "Epoch 788/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.6522e-04 - val_loss: 4.7302e-04\n",
      "Epoch 789/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8043e-04 - val_loss: 4.7153e-04\n",
      "Epoch 790/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.7434e-04 - val_loss: 4.7118e-04\n",
      "Epoch 791/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6919e-04 - val_loss: 4.7029e-04\n",
      "Epoch 792/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8328e-04 - val_loss: 4.7244e-04\n",
      "Epoch 793/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.7287e-04 - val_loss: 4.7365e-04\n",
      "Epoch 794/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7074e-04 - val_loss: 4.7071e-04\n",
      "Epoch 795/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6880e-04 - val_loss: 4.7364e-04\n",
      "Epoch 796/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6645e-04 - val_loss: 4.6907e-04\n",
      "Epoch 797/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6636e-04 - val_loss: 4.6984e-04\n",
      "Epoch 798/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.6275e-04 - val_loss: 4.8108e-04\n",
      "Epoch 799/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6455e-04 - val_loss: 4.6683e-04\n",
      "Epoch 800/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6503e-04 - val_loss: 4.6924e-04\n",
      "Epoch 801/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.6807e-04 - val_loss: 4.7239e-04\n",
      "Epoch 802/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6792e-04 - val_loss: 4.7109e-04\n",
      "Epoch 803/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6422e-04 - val_loss: 4.7196e-04\n",
      "Epoch 804/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.7879e-04 - val_loss: 4.7166e-04\n",
      "Epoch 805/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.6560e-04 - val_loss: 4.7578e-04\n",
      "Epoch 806/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.7434e-04 - val_loss: 4.8657e-04\n",
      "Epoch 807/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6476e-04 - val_loss: 4.6897e-04\n",
      "Epoch 808/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7141e-04 - val_loss: 4.6846e-04\n",
      "Epoch 809/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.6691e-04 - val_loss: 4.6888e-04\n",
      "Epoch 810/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7391e-04 - val_loss: 4.7603e-04\n",
      "Epoch 811/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6936e-04 - val_loss: 4.7255e-04\n",
      "Epoch 812/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6474e-04 - val_loss: 4.7557e-04\n",
      "Epoch 813/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 1.6992e-04 - val_loss: 4.6722e-04\n",
      "Epoch 814/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.5758e-04 - val_loss: 4.7227e-04\n",
      "Epoch 815/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.6515e-04 - val_loss: 4.9263e-04\n",
      "Epoch 816/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.5492e-04 - val_loss: 4.6807e-04\n",
      "Epoch 817/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.6276e-04 - val_loss: 4.6716e-04\n",
      "Epoch 818/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.6659e-04 - val_loss: 4.7102e-04\n",
      "Epoch 819/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.6994e-04 - val_loss: 4.7501e-04\n",
      "Epoch 820/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 1.7336e-04 - val_loss: 4.7084e-04\n",
      "Epoch 821/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.6123e-04 - val_loss: 4.7179e-04\n",
      "Epoch 822/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.7070e-04 - val_loss: 4.6924e-04\n",
      "Epoch 823/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.6613e-04 - val_loss: 4.7006e-04\n",
      "Epoch 824/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6228e-04 - val_loss: 4.6828e-04\n",
      "Epoch 825/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.6555e-04 - val_loss: 4.6627e-04\n",
      "Epoch 826/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6237e-04 - val_loss: 4.9120e-04\n",
      "Epoch 827/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6813e-04 - val_loss: 4.6591e-04\n",
      "Epoch 828/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.6221e-04 - val_loss: 4.7450e-04\n",
      "Epoch 829/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.6902e-04 - val_loss: 4.7623e-04\n",
      "Epoch 830/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.6465e-04 - val_loss: 4.6637e-04\n",
      "Epoch 831/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6590e-04 - val_loss: 4.6891e-04\n",
      "Epoch 832/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.5893e-04 - val_loss: 4.6797e-04\n",
      "Epoch 833/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.7021e-04 - val_loss: 4.7148e-04\n",
      "Epoch 834/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.6255e-04 - val_loss: 4.7318e-04\n",
      "Epoch 835/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.7629e-04 - val_loss: 4.7600e-04\n",
      "Epoch 836/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 1.6911e-04 - val_loss: 4.6741e-04\n",
      "Epoch 837/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.6035e-04 - val_loss: 4.6918e-04\n",
      "Epoch 838/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5951e-04 - val_loss: 4.7321e-04\n",
      "Epoch 839/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.6255e-04 - val_loss: 4.6602e-04\n",
      "Epoch 840/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6112e-04 - val_loss: 4.8538e-04\n",
      "Epoch 841/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.5981e-04 - val_loss: 4.6766e-04\n",
      "Epoch 842/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6155e-04 - val_loss: 4.7104e-04\n",
      "Epoch 843/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5787e-04 - val_loss: 4.6888e-04\n",
      "Epoch 844/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.6900e-04 - val_loss: 4.6795e-04\n",
      "Epoch 845/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.5309e-04 - val_loss: 4.6756e-04\n",
      "Epoch 846/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6123e-04 - val_loss: 4.6712e-04\n",
      "Epoch 847/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5028e-04 - val_loss: 4.6700e-04\n",
      "Epoch 848/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 1.5452e-04 - val_loss: 4.7509e-04\n",
      "Epoch 849/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.6328e-04 - val_loss: 4.7075e-04\n",
      "Epoch 850/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.6178e-04 - val_loss: 4.6756e-04\n",
      "Epoch 851/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.5708e-04 - val_loss: 4.6722e-04\n",
      "Epoch 852/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5761e-04 - val_loss: 4.6709e-04\n",
      "Epoch 853/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.6336e-04 - val_loss: 4.7705e-04\n",
      "Epoch 854/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.6378e-04 - val_loss: 4.6621e-04\n",
      "Epoch 855/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.5581e-04 - val_loss: 4.6685e-04\n",
      "Epoch 856/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.5814e-04 - val_loss: 4.7691e-04\n",
      "Epoch 857/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6259e-04 - val_loss: 4.6571e-04\n",
      "Epoch 858/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5714e-04 - val_loss: 4.6653e-04\n",
      "Epoch 859/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.5612e-04 - val_loss: 4.6886e-04\n",
      "Epoch 860/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.5468e-04 - val_loss: 4.8082e-04\n",
      "Epoch 861/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6490e-04 - val_loss: 4.6812e-04\n",
      "Epoch 862/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.5887e-04 - val_loss: 4.6713e-04\n",
      "Epoch 863/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5410e-04 - val_loss: 4.7358e-04\n",
      "Epoch 864/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6107e-04 - val_loss: 4.6710e-04\n",
      "Epoch 865/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.5198e-04 - val_loss: 4.7344e-04\n",
      "Epoch 866/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.5272e-04 - val_loss: 4.6917e-04\n",
      "Epoch 867/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.5529e-04 - val_loss: 4.6958e-04\n",
      "Epoch 868/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5818e-04 - val_loss: 4.7214e-04\n",
      "Epoch 869/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 1.5447e-04 - val_loss: 4.6989e-04\n",
      "Epoch 870/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.5688e-04 - val_loss: 4.7245e-04\n",
      "Epoch 871/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 1.5999e-04 - val_loss: 4.6613e-04\n",
      "Epoch 872/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.5512e-04 - val_loss: 4.7002e-04\n",
      "Epoch 873/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.5282e-04 - val_loss: 4.6861e-04\n",
      "Epoch 874/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5437e-04 - val_loss: 4.6802e-04\n",
      "Epoch 875/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5526e-04 - val_loss: 4.7879e-04\n",
      "Epoch 876/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.5441e-04 - val_loss: 4.6710e-04\n",
      "Epoch 877/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.5205e-04 - val_loss: 4.7336e-04\n",
      "Epoch 878/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5733e-04 - val_loss: 4.6505e-04\n",
      "Epoch 879/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.5636e-04 - val_loss: 4.7431e-04\n",
      "Epoch 880/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6413e-04 - val_loss: 4.6875e-04\n",
      "Epoch 881/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5692e-04 - val_loss: 4.7016e-04\n",
      "Epoch 882/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5214e-04 - val_loss: 4.6612e-04\n",
      "Epoch 883/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6245e-04 - val_loss: 4.7860e-04\n",
      "Epoch 884/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.5697e-04 - val_loss: 4.7283e-04\n",
      "Epoch 885/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4988e-04 - val_loss: 4.7032e-04\n",
      "Epoch 886/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.5040e-04 - val_loss: 4.6640e-04\n",
      "Epoch 887/1000\n",
      "174/174 [==============================] - 0s 959us/step - loss: 1.5542e-04 - val_loss: 4.6710e-04\n",
      "Epoch 888/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.5031e-04 - val_loss: 4.6774e-04\n",
      "Epoch 889/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.5241e-04 - val_loss: 4.6707e-04\n",
      "Epoch 890/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.5430e-04 - val_loss: 4.7047e-04\n",
      "Epoch 891/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5287e-04 - val_loss: 4.7951e-04\n",
      "Epoch 892/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5546e-04 - val_loss: 4.6569e-04\n",
      "Epoch 893/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5586e-04 - val_loss: 4.6708e-04\n",
      "Epoch 894/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4464e-04 - val_loss: 4.6884e-04\n",
      "Epoch 895/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.5385e-04 - val_loss: 4.7007e-04\n",
      "Epoch 896/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.4880e-04 - val_loss: 4.7421e-04\n",
      "Epoch 897/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.5150e-04 - val_loss: 4.6788e-04\n",
      "Epoch 898/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5347e-04 - val_loss: 4.7080e-04\n",
      "Epoch 899/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.5053e-04 - val_loss: 4.6544e-04\n",
      "Epoch 900/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4412e-04 - val_loss: 4.6385e-04\n",
      "Epoch 901/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5351e-04 - val_loss: 4.7018e-04\n",
      "Epoch 902/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.5526e-04 - val_loss: 4.6642e-04\n",
      "Epoch 903/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5169e-04 - val_loss: 4.6976e-04\n",
      "Epoch 904/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4744e-04 - val_loss: 4.6817e-04\n",
      "Epoch 905/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5142e-04 - val_loss: 4.6831e-04\n",
      "Epoch 906/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.4624e-04 - val_loss: 4.6428e-04\n",
      "Epoch 907/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 1.5007e-04 - val_loss: 4.6901e-04\n",
      "Epoch 908/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.5138e-04 - val_loss: 4.6525e-04\n",
      "Epoch 909/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4887e-04 - val_loss: 4.6519e-04\n",
      "Epoch 910/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5181e-04 - val_loss: 4.6519e-04\n",
      "Epoch 911/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.4506e-04 - val_loss: 4.7319e-04\n",
      "Epoch 912/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.4842e-04 - val_loss: 4.6666e-04\n",
      "Epoch 913/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5420e-04 - val_loss: 4.6906e-04\n",
      "Epoch 914/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5385e-04 - val_loss: 4.6763e-04\n",
      "Epoch 915/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4862e-04 - val_loss: 4.6621e-04\n",
      "Epoch 916/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5323e-04 - val_loss: 4.6827e-04\n",
      "Epoch 917/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.4469e-04 - val_loss: 4.6634e-04\n",
      "Epoch 918/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4874e-04 - val_loss: 4.7842e-04\n",
      "Epoch 919/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.4807e-04 - val_loss: 4.7634e-04\n",
      "Epoch 920/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.5515e-04 - val_loss: 4.6981e-04\n",
      "Epoch 921/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.5016e-04 - val_loss: 4.6873e-04\n",
      "Epoch 922/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.4831e-04 - val_loss: 4.7288e-04\n",
      "Epoch 923/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.5619e-04 - val_loss: 4.6722e-04\n",
      "Epoch 924/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4644e-04 - val_loss: 4.7016e-04\n",
      "Epoch 925/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4594e-04 - val_loss: 4.6689e-04\n",
      "Epoch 926/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.5105e-04 - val_loss: 4.6811e-04\n",
      "Epoch 927/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4664e-04 - val_loss: 4.6551e-04\n",
      "Epoch 928/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.4971e-04 - val_loss: 4.6946e-04\n",
      "Epoch 929/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4375e-04 - val_loss: 4.6523e-04\n",
      "Epoch 930/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.4386e-04 - val_loss: 4.7208e-04\n",
      "Epoch 931/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4892e-04 - val_loss: 4.7184e-04\n",
      "Epoch 932/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5360e-04 - val_loss: 4.6379e-04\n",
      "Epoch 933/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5662e-04 - val_loss: 4.6574e-04\n",
      "Epoch 934/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5298e-04 - val_loss: 4.6565e-04\n",
      "Epoch 935/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.5413e-04 - val_loss: 4.6564e-04\n",
      "Epoch 936/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4433e-04 - val_loss: 4.6775e-04\n",
      "Epoch 937/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.4480e-04 - val_loss: 4.6626e-04\n",
      "Epoch 938/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.4436e-04 - val_loss: 4.6753e-04\n",
      "Epoch 939/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4585e-04 - val_loss: 4.6791e-04\n",
      "Epoch 940/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4030e-04 - val_loss: 4.6637e-04\n",
      "Epoch 941/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5225e-04 - val_loss: 4.6745e-04\n",
      "Epoch 942/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.4389e-04 - val_loss: 4.6758e-04\n",
      "Epoch 943/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.4669e-04 - val_loss: 4.6574e-04\n",
      "Epoch 944/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.4437e-04 - val_loss: 4.6727e-04\n",
      "Epoch 945/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4042e-04 - val_loss: 4.6983e-04\n",
      "Epoch 946/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4963e-04 - val_loss: 4.6498e-04\n",
      "Epoch 947/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.4377e-04 - val_loss: 4.6567e-04\n",
      "Epoch 948/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3972e-04 - val_loss: 4.6566e-04\n",
      "Epoch 949/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 1.4941e-04 - val_loss: 4.6344e-04\n",
      "Epoch 950/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.5139e-04 - val_loss: 4.6429e-04\n",
      "Epoch 951/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.3843e-04 - val_loss: 4.6917e-04\n",
      "Epoch 952/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.5049e-04 - val_loss: 4.6969e-04\n",
      "Epoch 953/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.4320e-04 - val_loss: 4.6712e-04\n",
      "Epoch 954/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.4856e-04 - val_loss: 4.6622e-04\n",
      "Epoch 955/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4327e-04 - val_loss: 4.6929e-04\n",
      "Epoch 956/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.4332e-04 - val_loss: 4.6713e-04\n",
      "Epoch 957/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.3920e-04 - val_loss: 4.6833e-04\n",
      "Epoch 958/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4745e-04 - val_loss: 4.6796e-04\n",
      "Epoch 959/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3912e-04 - val_loss: 4.7252e-04\n",
      "Epoch 960/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.4140e-04 - val_loss: 4.6475e-04\n",
      "Epoch 961/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.4349e-04 - val_loss: 4.6986e-04\n",
      "Epoch 962/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.3851e-04 - val_loss: 4.6957e-04\n",
      "Epoch 963/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.4496e-04 - val_loss: 4.7708e-04\n",
      "Epoch 964/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4161e-04 - val_loss: 4.6765e-04\n",
      "Epoch 965/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.4078e-04 - val_loss: 4.6402e-04\n",
      "Epoch 966/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.4247e-04 - val_loss: 4.6447e-04\n",
      "Epoch 967/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.4105e-04 - val_loss: 4.6535e-04\n",
      "Epoch 968/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3913e-04 - val_loss: 4.6632e-04\n",
      "Epoch 969/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4242e-04 - val_loss: 4.6605e-04\n",
      "Epoch 970/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4139e-04 - val_loss: 4.6391e-04\n",
      "Epoch 971/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.4499e-04 - val_loss: 4.6759e-04\n",
      "Epoch 972/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3781e-04 - val_loss: 4.6743e-04\n",
      "Epoch 973/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.4567e-04 - val_loss: 4.6683e-04\n",
      "Epoch 974/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.3519e-04 - val_loss: 4.6617e-04\n",
      "Epoch 975/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.3756e-04 - val_loss: 4.6266e-04\n",
      "Epoch 976/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.3940e-04 - val_loss: 4.9362e-04\n",
      "Epoch 977/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.4263e-04 - val_loss: 4.6847e-04\n",
      "Epoch 978/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4119e-04 - val_loss: 4.6774e-04\n",
      "Epoch 979/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4126e-04 - val_loss: 4.6931e-04\n",
      "Epoch 980/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4720e-04 - val_loss: 4.6601e-04\n",
      "Epoch 981/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.3158e-04 - val_loss: 4.6345e-04\n",
      "Epoch 982/1000\n",
      "174/174 [==============================] - 0s 965us/step - loss: 1.4148e-04 - val_loss: 4.6396e-04\n",
      "Epoch 983/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.4203e-04 - val_loss: 4.6444e-04\n",
      "Epoch 984/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.3786e-04 - val_loss: 4.6457e-04\n",
      "Epoch 985/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3973e-04 - val_loss: 4.6495e-04\n",
      "Epoch 986/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.3797e-04 - val_loss: 4.6775e-04\n",
      "Epoch 987/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.3714e-04 - val_loss: 4.7222e-04\n",
      "Epoch 988/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3795e-04 - val_loss: 4.6556e-04\n",
      "Epoch 989/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3917e-04 - val_loss: 4.6674e-04\n",
      "Epoch 990/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3640e-04 - val_loss: 4.6571e-04\n",
      "Epoch 991/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4300e-04 - val_loss: 4.6632e-04\n",
      "Epoch 992/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.3844e-04 - val_loss: 4.6999e-04\n",
      "Epoch 993/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3471e-04 - val_loss: 4.6591e-04\n",
      "Epoch 994/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3316e-04 - val_loss: 4.7003e-04\n",
      "Epoch 995/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.4796e-04 - val_loss: 4.6528e-04\n",
      "Epoch 996/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3781e-04 - val_loss: 4.6404e-04\n",
      "Epoch 997/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3740e-04 - val_loss: 4.6329e-04\n",
      "Epoch 998/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3884e-04 - val_loss: 4.6631e-04\n",
      "Epoch 999/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.4311e-04 - val_loss: 4.6900e-04\n",
      "Epoch 1000/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.3496e-04 - val_loss: 4.6553e-04\n",
      "y_preds_dnn_reg: (3713, 1)\n",
      "CPU times: user 6min 21s, sys: 57.6 s, total: 7min 19s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dnn_reg_real = DnnReg(n_units=n_units, n_features=input_shape)\n",
    "\n",
    "y_preds_dnn_reg_real = train_eval_dnn_reg(dnn_reg=dnn_reg_real,\n",
    "                                          x_train=x_r_train_real,\n",
    "                                          y_train=y_train_real, \n",
    "                                          x_val=x_r_val_real, \n",
    "                                          y_val=y_val_real,\n",
    "                                          x_test=x_r_test_real,\n",
    "                                          y_test=y_test_real,\n",
    "                                          name='real',\n",
    "                                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0372209</td>\n",
       "      <td>0.0217353</td>\n",
       "      <td>0.0474404</td>\n",
       "      <td>0.570674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE       MRAE       RMSE R^2-Score\n",
       "RF             NaN        NaN        NaN       NaN\n",
       "GBR-Ls         NaN        NaN        NaN       NaN\n",
       "DNN-Reg  0.0372209  0.0217353  0.0474404  0.570674"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_reg_real = add_to_regression_comparison(df_reg_real,\n",
    "                                           y_preds=y_preds_dnn_reg_real,\n",
    "                                           y_trues=y_test_real, \n",
    "                                           name='DNN-Reg',\n",
    "                                           data_name='real')\n",
    "df_reg_real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  20 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   27.4s finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 42s, sys: 4.02 ms, total: 5min 42s\n",
      "Wall time: 27.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.00628533</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>0.747494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0372209</td>\n",
       "      <td>0.0217353</td>\n",
       "      <td>0.0474404</td>\n",
       "      <td>0.570674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF        0.010694  0.00628533   0.017858  0.747494\n",
       "GBR-Ls         NaN         NaN        NaN       NaN\n",
       "DNN-Reg  0.0372209   0.0217353  0.0474404  0.570674"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_preds_rf_real = train_eval_rf(x_train=x_r_train_real,\n",
    "                                y_train=y_train_real, \n",
    "                                x_test=x_r_test_real,\n",
    "                                y_test=y_test_real,\n",
    "                                name='real'\n",
    "                               )\n",
    "\n",
    "\n",
    "df_reg_real = add_to_regression_comparison(df_reg_real,\n",
    "                                           y_preds=y_preds_rf_real,\n",
    "                                           y_trues=y_test_real, \n",
    "                                           name='RF',\n",
    "                                           data_name='real'\n",
    "                                          )\n",
    "df_reg_real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0011            1.10m\n",
      "         2           0.0010            1.08m\n",
      "         3           0.0009            1.07m\n",
      "         4           0.0008            1.06m\n",
      "         5           0.0007            1.05m\n",
      "         6           0.0007            1.04m\n",
      "         7           0.0007            1.03m\n",
      "         8           0.0006            1.02m\n",
      "         9           0.0006            1.01m\n",
      "        10           0.0006           59.96s\n",
      "        20           0.0005           53.38s\n",
      "        30           0.0004           47.06s\n",
      "        40           0.0004           40.82s\n",
      "        50           0.0004           34.21s\n",
      "        60           0.0004           27.46s\n",
      "        70           0.0004           20.66s\n",
      "        80           0.0003           13.78s\n",
      "        90           0.0003            6.90s\n",
      "       100           0.0003            0.00s\n",
      "CPU times: user 1min 9s, sys: 0 ns, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.00628533</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>0.747494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>0.0141234</td>\n",
       "      <td>0.00829238</td>\n",
       "      <td>0.0211861</td>\n",
       "      <td>0.644608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0372209</td>\n",
       "      <td>0.0217353</td>\n",
       "      <td>0.0474404</td>\n",
       "      <td>0.570674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF        0.010694  0.00628533   0.017858  0.747494\n",
       "GBR-Ls   0.0141234  0.00829238  0.0211861  0.644608\n",
       "DNN-Reg  0.0372209   0.0217353  0.0474404  0.570674"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_gbr_real = train_eval_gbr(x_train=x_r_train_real,\n",
    "                              y_train=y_train_real, \n",
    "                              x_test=x_r_test_real,\n",
    "                              y_test=y_test_real,\n",
    "                              name='real',\n",
    "                             )\n",
    "\n",
    "\n",
    "df_reg_real = add_to_regression_comparison(df_reg_real,\n",
    "                                           y_preds=y_preds_gbr_real,\n",
    "                                           y_trues=y_test_real, \n",
    "                                           name='GBR-Ls',\n",
    "                                           data_name='real'\n",
    "                                          )\n",
    "df_reg_real\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion over real-only data:\n",
    "\n",
    "- All three algorithms obtained acceptable results w.r.t MAE, MRAE, RMSE.\n",
    "\n",
    "- Although all of these three also obtain acceptable r^2 score, however, RF is the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic-only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5782 - val_loss: 2.0135\n",
      "Epoch 2/1000\n",
      "174/174 [==============================] - 0s 925us/step - loss: 1.8074 - val_loss: 1.2427\n",
      "Epoch 3/1000\n",
      "174/174 [==============================] - 0s 944us/step - loss: 1.0506 - val_loss: 0.5983\n",
      "Epoch 4/1000\n",
      "174/174 [==============================] - 0s 940us/step - loss: 0.4656 - val_loss: 0.2122\n",
      "Epoch 5/1000\n",
      "174/174 [==============================] - 0s 962us/step - loss: 0.1604 - val_loss: 0.0822\n",
      "Epoch 6/1000\n",
      "174/174 [==============================] - 0s 963us/step - loss: 0.0712 - val_loss: 0.0488\n",
      "Epoch 7/1000\n",
      "174/174 [==============================] - 0s 960us/step - loss: 0.0452 - val_loss: 0.0372\n",
      "Epoch 8/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 0.0356 - val_loss: 0.0310\n",
      "Epoch 9/1000\n",
      "174/174 [==============================] - 0s 964us/step - loss: 0.0307 - val_loss: 0.0264\n",
      "Epoch 10/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 0.0246 - val_loss: 0.0226\n",
      "Epoch 11/1000\n",
      "174/174 [==============================] - 0s 957us/step - loss: 0.0214 - val_loss: 0.0194\n",
      "Epoch 12/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 0.0185 - val_loss: 0.0168\n",
      "Epoch 13/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 0.0158 - val_loss: 0.0145\n",
      "Epoch 14/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0127\n",
      "Epoch 15/1000\n",
      "174/174 [==============================] - 0s 960us/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 16/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 17/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 18/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 19/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 20/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 21/1000\n",
      "174/174 [==============================] - 0s 964us/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 22/1000\n",
      "174/174 [==============================] - 0s 966us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 23/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 24/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 25/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 26/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 27/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 28/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 29/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 30/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 31/1000\n",
      "174/174 [==============================] - 0s 955us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 32/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 33/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 34/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 35/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 36/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 37/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 38/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 39/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 40/1000\n",
      "174/174 [==============================] - 0s 960us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 41/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 42/1000\n",
      "174/174 [==============================] - 0s 961us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 43/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 44/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 45/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 46/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 47/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 48/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 49/1000\n",
      "174/174 [==============================] - 0s 966us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 50/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 51/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 52/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 53/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 54/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 55/1000\n",
      "174/174 [==============================] - 0s 968us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 56/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 57/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 58/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 59/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 60/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 61/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 62/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 63/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 64/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 65/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 66/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 67/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 68/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 69/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 70/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 71/1000\n",
      "174/174 [==============================] - 0s 954us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 72/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 73/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 74/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 75/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 76/1000\n",
      "174/174 [==============================] - 0s 962us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "174/174 [==============================] - 0s 965us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 79/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 9.7735e-04 - val_loss: 0.0011\n",
      "Epoch 80/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 9.4671e-04 - val_loss: 0.0011\n",
      "Epoch 81/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 9.1559e-04 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 9.5408e-04 - val_loss: 0.0010\n",
      "Epoch 83/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 9.0588e-04 - val_loss: 0.0010\n",
      "Epoch 84/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 9.2993e-04 - val_loss: 0.0010\n",
      "Epoch 85/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 8.7718e-04 - val_loss: 0.0010\n",
      "Epoch 86/1000\n",
      "174/174 [==============================] - 0s 966us/step - loss: 8.6573e-04 - val_loss: 9.9032e-04\n",
      "Epoch 87/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 8.7892e-04 - val_loss: 9.7573e-04\n",
      "Epoch 88/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.2390e-04 - val_loss: 9.6890e-04\n",
      "Epoch 89/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 8.6436e-04 - val_loss: 9.5069e-04\n",
      "Epoch 90/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 8.0400e-04 - val_loss: 9.3015e-04\n",
      "Epoch 91/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 8.0379e-04 - val_loss: 9.2917e-04\n",
      "Epoch 92/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 7.9064e-04 - val_loss: 9.0727e-04\n",
      "Epoch 93/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.9690e-04 - val_loss: 8.9784e-04\n",
      "Epoch 94/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 7.4078e-04 - val_loss: 8.8569e-04\n",
      "Epoch 95/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 7.8009e-04 - val_loss: 8.8041e-04\n",
      "Epoch 96/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 7.7195e-04 - val_loss: 8.8541e-04\n",
      "Epoch 97/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 7.5391e-04 - val_loss: 8.8012e-04\n",
      "Epoch 98/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 7.2069e-04 - val_loss: 8.4029e-04\n",
      "Epoch 99/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 7.4676e-04 - val_loss: 8.4717e-04\n",
      "Epoch 100/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 7.0951e-04 - val_loss: 8.2881e-04\n",
      "Epoch 101/1000\n",
      "174/174 [==============================] - 0s 964us/step - loss: 7.0854e-04 - val_loss: 8.2155e-04\n",
      "Epoch 102/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 6.8494e-04 - val_loss: 8.0465e-04\n",
      "Epoch 103/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 6.9682e-04 - val_loss: 8.1972e-04\n",
      "Epoch 104/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.7497e-04 - val_loss: 7.8679e-04\n",
      "Epoch 105/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 6.7918e-04 - val_loss: 7.9069e-04\n",
      "Epoch 106/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 6.7090e-04 - val_loss: 7.8305e-04\n",
      "Epoch 107/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 6.5794e-04 - val_loss: 7.6714e-04\n",
      "Epoch 108/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.5189e-04 - val_loss: 7.6587e-04\n",
      "Epoch 109/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 6.4566e-04 - val_loss: 7.5627e-04\n",
      "Epoch 110/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 6.5676e-04 - val_loss: 7.4986e-04\n",
      "Epoch 111/1000\n",
      "174/174 [==============================] - 0s 962us/step - loss: 6.1164e-04 - val_loss: 7.3565e-04\n",
      "Epoch 112/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 6.3030e-04 - val_loss: 7.4471e-04\n",
      "Epoch 113/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 6.3096e-04 - val_loss: 7.2296e-04\n",
      "Epoch 114/1000\n",
      "174/174 [==============================] - 0s 964us/step - loss: 6.4184e-04 - val_loss: 7.1683e-04\n",
      "Epoch 115/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.0600e-04 - val_loss: 7.0542e-04\n",
      "Epoch 116/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 5.8311e-04 - val_loss: 7.0744e-04\n",
      "Epoch 117/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 5.6922e-04 - val_loss: 6.9420e-04\n",
      "Epoch 118/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 5.8418e-04 - val_loss: 6.9593e-04\n",
      "Epoch 119/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.7195e-04 - val_loss: 6.8563e-04\n",
      "Epoch 120/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 5.7533e-04 - val_loss: 6.7815e-04\n",
      "Epoch 121/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 5.6427e-04 - val_loss: 6.7388e-04\n",
      "Epoch 122/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 5.7960e-04 - val_loss: 6.5998e-04\n",
      "Epoch 123/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 5.4921e-04 - val_loss: 6.6304e-04\n",
      "Epoch 124/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.6607e-04 - val_loss: 6.6308e-04\n",
      "Epoch 125/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.2518e-04 - val_loss: 6.6009e-04\n",
      "Epoch 126/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.2895e-04 - val_loss: 6.4704e-04\n",
      "Epoch 127/1000\n",
      "174/174 [==============================] - 0s 956us/step - loss: 5.3322e-04 - val_loss: 6.4045e-04\n",
      "Epoch 128/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.4625e-04 - val_loss: 6.3392e-04\n",
      "Epoch 129/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 5.1026e-04 - val_loss: 6.5397e-04\n",
      "Epoch 130/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 5.1939e-04 - val_loss: 6.4167e-04\n",
      "Epoch 131/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 5.3101e-04 - val_loss: 6.1057e-04\n",
      "Epoch 132/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 5.0688e-04 - val_loss: 6.1962e-04\n",
      "Epoch 133/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 5.0470e-04 - val_loss: 6.1665e-04\n",
      "Epoch 134/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 4.9059e-04 - val_loss: 6.0145e-04\n",
      "Epoch 135/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 4.9917e-04 - val_loss: 5.9461e-04\n",
      "Epoch 136/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 5.0521e-04 - val_loss: 6.0458e-04\n",
      "Epoch 137/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8907e-04 - val_loss: 5.8404e-04\n",
      "Epoch 138/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.9072e-04 - val_loss: 5.9147e-04\n",
      "Epoch 139/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 4.8010e-04 - val_loss: 5.8248e-04\n",
      "Epoch 140/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 4.8155e-04 - val_loss: 5.7315e-04\n",
      "Epoch 141/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 4.7492e-04 - val_loss: 5.6518e-04\n",
      "Epoch 142/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 4.8990e-04 - val_loss: 5.6781e-04\n",
      "Epoch 143/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 4.7201e-04 - val_loss: 5.6091e-04\n",
      "Epoch 144/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5991e-04 - val_loss: 5.5813e-04\n",
      "Epoch 145/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5557e-04 - val_loss: 5.5152e-04\n",
      "Epoch 146/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 4.5389e-04 - val_loss: 5.4450e-04\n",
      "Epoch 147/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 4.4600e-04 - val_loss: 5.4253e-04\n",
      "Epoch 148/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 4.5887e-04 - val_loss: 5.3820e-04\n",
      "Epoch 149/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3139e-04 - val_loss: 5.4745e-04\n",
      "Epoch 150/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3638e-04 - val_loss: 5.3792e-04\n",
      "Epoch 151/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.2150e-04 - val_loss: 5.2499e-04\n",
      "Epoch 152/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 4.3719e-04 - val_loss: 5.2878e-04\n",
      "Epoch 153/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 4.2169e-04 - val_loss: 5.2394e-04\n",
      "Epoch 154/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 4.2311e-04 - val_loss: 5.2183e-04\n",
      "Epoch 155/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 4.3307e-04 - val_loss: 5.2262e-04\n",
      "Epoch 156/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 4.1471e-04 - val_loss: 5.2473e-04\n",
      "Epoch 157/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 4.1037e-04 - val_loss: 5.0379e-04\n",
      "Epoch 158/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 4.1184e-04 - val_loss: 5.0012e-04\n",
      "Epoch 159/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 4.1968e-04 - val_loss: 4.9570e-04\n",
      "Epoch 160/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.8972e-04 - val_loss: 5.0310e-04\n",
      "Epoch 161/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 4.0167e-04 - val_loss: 5.0243e-04\n",
      "Epoch 162/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 3.9497e-04 - val_loss: 4.9980e-04\n",
      "Epoch 163/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9548e-04 - val_loss: 4.8841e-04\n",
      "Epoch 164/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9346e-04 - val_loss: 4.7724e-04\n",
      "Epoch 165/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 4.0812e-04 - val_loss: 4.8895e-04\n",
      "Epoch 166/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9051e-04 - val_loss: 4.6976e-04\n",
      "Epoch 167/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8093e-04 - val_loss: 4.9074e-04\n",
      "Epoch 168/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9074e-04 - val_loss: 4.7719e-04\n",
      "Epoch 169/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.7357e-04 - val_loss: 4.6806e-04\n",
      "Epoch 170/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.8139e-04 - val_loss: 4.5898e-04\n",
      "Epoch 171/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 3.8324e-04 - val_loss: 4.5622e-04\n",
      "Epoch 172/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6019e-04 - val_loss: 4.5639e-04\n",
      "Epoch 173/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.6816e-04 - val_loss: 4.5549e-04\n",
      "Epoch 174/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.6413e-04 - val_loss: 4.4693e-04\n",
      "Epoch 175/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 3.4076e-04 - val_loss: 4.5633e-04\n",
      "Epoch 176/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5207e-04 - val_loss: 4.4850e-04\n",
      "Epoch 177/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 3.5810e-04 - val_loss: 4.4232e-04\n",
      "Epoch 178/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4764e-04 - val_loss: 4.4613e-04\n",
      "Epoch 179/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.3709e-04 - val_loss: 4.3671e-04\n",
      "Epoch 180/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4805e-04 - val_loss: 4.3053e-04\n",
      "Epoch 181/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.5261e-04 - val_loss: 4.3122e-04\n",
      "Epoch 182/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 3.3915e-04 - val_loss: 4.2243e-04\n",
      "Epoch 183/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.4511e-04 - val_loss: 4.2816e-04\n",
      "Epoch 184/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3538e-04 - val_loss: 4.1951e-04\n",
      "Epoch 185/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 3.3807e-04 - val_loss: 4.1612e-04\n",
      "Epoch 186/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 3.3694e-04 - val_loss: 4.1972e-04\n",
      "Epoch 187/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 3.4017e-04 - val_loss: 4.1182e-04\n",
      "Epoch 188/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 3.3244e-04 - val_loss: 4.1573e-04\n",
      "Epoch 189/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.1653e-04 - val_loss: 4.0702e-04\n",
      "Epoch 190/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 3.2577e-04 - val_loss: 4.1097e-04\n",
      "Epoch 191/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.1586e-04 - val_loss: 4.0528e-04\n",
      "Epoch 192/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 3.1988e-04 - val_loss: 4.0891e-04\n",
      "Epoch 193/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1282e-04 - val_loss: 3.9844e-04\n",
      "Epoch 194/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1387e-04 - val_loss: 4.1015e-04\n",
      "Epoch 195/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0808e-04 - val_loss: 3.9439e-04\n",
      "Epoch 196/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0774e-04 - val_loss: 3.9182e-04\n",
      "Epoch 197/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 3.1146e-04 - val_loss: 3.8999e-04\n",
      "Epoch 198/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1103e-04 - val_loss: 4.0426e-04\n",
      "Epoch 199/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.9740e-04 - val_loss: 3.9182e-04\n",
      "Epoch 200/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 3.0226e-04 - val_loss: 3.8267e-04\n",
      "Epoch 201/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.9645e-04 - val_loss: 3.7955e-04\n",
      "Epoch 202/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.9331e-04 - val_loss: 3.8305e-04\n",
      "Epoch 203/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0265e-04 - val_loss: 3.7572e-04\n",
      "Epoch 204/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8095e-04 - val_loss: 3.7264e-04\n",
      "Epoch 205/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.9046e-04 - val_loss: 3.7145e-04\n",
      "Epoch 206/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8922e-04 - val_loss: 3.7679e-04\n",
      "Epoch 207/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.8714e-04 - val_loss: 3.7266e-04\n",
      "Epoch 208/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 2.8463e-04 - val_loss: 3.7505e-04\n",
      "Epoch 209/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8643e-04 - val_loss: 3.6870e-04\n",
      "Epoch 210/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.8358e-04 - val_loss: 3.6522e-04\n",
      "Epoch 211/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8172e-04 - val_loss: 3.5546e-04\n",
      "Epoch 212/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7177e-04 - val_loss: 3.5605e-04\n",
      "Epoch 213/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8905e-04 - val_loss: 3.5617e-04\n",
      "Epoch 214/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7948e-04 - val_loss: 3.6185e-04\n",
      "Epoch 215/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6053e-04 - val_loss: 3.5056e-04\n",
      "Epoch 216/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.6302e-04 - val_loss: 3.4849e-04\n",
      "Epoch 217/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.6860e-04 - val_loss: 3.4429e-04\n",
      "Epoch 218/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5821e-04 - val_loss: 3.3973e-04\n",
      "Epoch 219/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.6314e-04 - val_loss: 3.5691e-04\n",
      "Epoch 220/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.6376e-04 - val_loss: 3.3724e-04\n",
      "Epoch 221/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 2.6903e-04 - val_loss: 3.3604e-04\n",
      "Epoch 222/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.5696e-04 - val_loss: 3.3803e-04\n",
      "Epoch 223/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.5628e-04 - val_loss: 3.3272e-04\n",
      "Epoch 224/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.5773e-04 - val_loss: 3.3226e-04\n",
      "Epoch 225/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6045e-04 - val_loss: 3.3235e-04\n",
      "Epoch 226/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.5172e-04 - val_loss: 3.3923e-04\n",
      "Epoch 227/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.5445e-04 - val_loss: 3.4025e-04\n",
      "Epoch 228/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4714e-04 - val_loss: 3.3040e-04\n",
      "Epoch 229/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.4497e-04 - val_loss: 3.3261e-04\n",
      "Epoch 230/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.4574e-04 - val_loss: 3.2346e-04\n",
      "Epoch 231/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.4700e-04 - val_loss: 3.3183e-04\n",
      "Epoch 232/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.4859e-04 - val_loss: 3.1822e-04\n",
      "Epoch 233/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 2.4633e-04 - val_loss: 3.1414e-04\n",
      "Epoch 234/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.3157e-04 - val_loss: 3.1213e-04\n",
      "Epoch 235/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4051e-04 - val_loss: 3.1886e-04\n",
      "Epoch 236/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2998e-04 - val_loss: 3.1583e-04\n",
      "Epoch 237/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.4114e-04 - val_loss: 3.0843e-04\n",
      "Epoch 238/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.3136e-04 - val_loss: 3.0934e-04\n",
      "Epoch 239/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3567e-04 - val_loss: 3.0466e-04\n",
      "Epoch 240/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.2865e-04 - val_loss: 3.0528e-04\n",
      "Epoch 241/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.3482e-04 - val_loss: 3.0876e-04\n",
      "Epoch 242/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.1816e-04 - val_loss: 3.0414e-04\n",
      "Epoch 243/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.3393e-04 - val_loss: 3.0112e-04\n",
      "Epoch 244/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.1328e-04 - val_loss: 3.0070e-04\n",
      "Epoch 245/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3189e-04 - val_loss: 2.9798e-04\n",
      "Epoch 246/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 2.1653e-04 - val_loss: 2.9595e-04\n",
      "Epoch 247/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.1693e-04 - val_loss: 2.9359e-04\n",
      "Epoch 248/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.1547e-04 - val_loss: 2.9079e-04\n",
      "Epoch 249/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.1888e-04 - val_loss: 2.8923e-04\n",
      "Epoch 250/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.0890e-04 - val_loss: 2.8650e-04\n",
      "Epoch 251/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0649e-04 - val_loss: 2.8594e-04\n",
      "Epoch 252/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0583e-04 - val_loss: 2.9538e-04\n",
      "Epoch 253/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0599e-04 - val_loss: 2.8388e-04\n",
      "Epoch 254/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 2.1311e-04 - val_loss: 2.9894e-04\n",
      "Epoch 255/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0636e-04 - val_loss: 2.8017e-04\n",
      "Epoch 256/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 2.0920e-04 - val_loss: 2.8888e-04\n",
      "Epoch 257/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0969e-04 - val_loss: 2.8862e-04\n",
      "Epoch 258/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.0099e-04 - val_loss: 2.9044e-04\n",
      "Epoch 259/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.9898e-04 - val_loss: 2.7465e-04\n",
      "Epoch 260/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.0008e-04 - val_loss: 2.7137e-04\n",
      "Epoch 261/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.0420e-04 - val_loss: 2.7649e-04\n",
      "Epoch 262/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.9644e-04 - val_loss: 2.7873e-04\n",
      "Epoch 263/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9140e-04 - val_loss: 2.6792e-04\n",
      "Epoch 264/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9442e-04 - val_loss: 2.7269e-04\n",
      "Epoch 265/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.8943e-04 - val_loss: 2.6682e-04\n",
      "Epoch 266/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.8914e-04 - val_loss: 2.6785e-04\n",
      "Epoch 267/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 1.8806e-04 - val_loss: 2.6079e-04\n",
      "Epoch 268/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.9104e-04 - val_loss: 2.6803e-04\n",
      "Epoch 269/1000\n",
      "174/174 [==============================] - 0s 963us/step - loss: 1.9106e-04 - val_loss: 2.6334e-04\n",
      "Epoch 270/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.9446e-04 - val_loss: 2.7404e-04\n",
      "Epoch 271/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9075e-04 - val_loss: 2.5744e-04\n",
      "Epoch 272/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7891e-04 - val_loss: 2.5488e-04\n",
      "Epoch 273/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.7852e-04 - val_loss: 2.7203e-04\n",
      "Epoch 274/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.8942e-04 - val_loss: 2.6343e-04\n",
      "Epoch 275/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.8525e-04 - val_loss: 2.5312e-04\n",
      "Epoch 276/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.8423e-04 - val_loss: 2.5619e-04\n",
      "Epoch 277/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 1.7564e-04 - val_loss: 2.5284e-04\n",
      "Epoch 278/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.7620e-04 - val_loss: 2.5496e-04\n",
      "Epoch 279/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8741e-04 - val_loss: 2.5178e-04\n",
      "Epoch 280/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7279e-04 - val_loss: 2.5943e-04\n",
      "Epoch 281/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7425e-04 - val_loss: 2.4935e-04\n",
      "Epoch 282/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.7749e-04 - val_loss: 2.6858e-04\n",
      "Epoch 283/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7794e-04 - val_loss: 2.4153e-04\n",
      "Epoch 284/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.6896e-04 - val_loss: 2.4569e-04\n",
      "Epoch 285/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7218e-04 - val_loss: 2.4315e-04\n",
      "Epoch 286/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.7183e-04 - val_loss: 2.4180e-04\n",
      "Epoch 287/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.7631e-04 - val_loss: 2.3847e-04\n",
      "Epoch 288/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6071e-04 - val_loss: 2.3636e-04\n",
      "Epoch 289/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.6026e-04 - val_loss: 2.3649e-04\n",
      "Epoch 290/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6381e-04 - val_loss: 2.4311e-04\n",
      "Epoch 291/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.6320e-04 - val_loss: 2.3322e-04\n",
      "Epoch 292/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6963e-04 - val_loss: 2.4320e-04\n",
      "Epoch 293/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.6636e-04 - val_loss: 2.2973e-04\n",
      "Epoch 294/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.6696e-04 - val_loss: 2.3360e-04\n",
      "Epoch 295/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.6178e-04 - val_loss: 2.3213e-04\n",
      "Epoch 296/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.5853e-04 - val_loss: 2.2645e-04\n",
      "Epoch 297/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.5303e-04 - val_loss: 2.4143e-04\n",
      "Epoch 298/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.4737e-04 - val_loss: 2.2378e-04\n",
      "Epoch 299/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.5460e-04 - val_loss: 2.2467e-04\n",
      "Epoch 300/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 1.5954e-04 - val_loss: 2.3120e-04\n",
      "Epoch 301/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 1.5407e-04 - val_loss: 2.3476e-04\n",
      "Epoch 302/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.5540e-04 - val_loss: 2.2042e-04\n",
      "Epoch 303/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 1.5500e-04 - val_loss: 2.1938e-04\n",
      "Epoch 304/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 1.5133e-04 - val_loss: 2.1986e-04\n",
      "Epoch 305/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.5279e-04 - val_loss: 2.2184e-04\n",
      "Epoch 306/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4818e-04 - val_loss: 2.1743e-04\n",
      "Epoch 307/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4876e-04 - val_loss: 2.2290e-04\n",
      "Epoch 308/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 1.4421e-04 - val_loss: 2.2237e-04\n",
      "Epoch 309/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4577e-04 - val_loss: 2.1929e-04\n",
      "Epoch 310/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.4196e-04 - val_loss: 2.1066e-04\n",
      "Epoch 311/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.4514e-04 - val_loss: 2.1846e-04\n",
      "Epoch 312/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.4410e-04 - val_loss: 2.0896e-04\n",
      "Epoch 313/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.4119e-04 - val_loss: 2.1814e-04\n",
      "Epoch 314/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.4019e-04 - val_loss: 2.1096e-04\n",
      "Epoch 315/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 1.4002e-04 - val_loss: 2.0748e-04\n",
      "Epoch 316/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.3493e-04 - val_loss: 2.2004e-04\n",
      "Epoch 317/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 1.4303e-04 - val_loss: 2.0972e-04\n",
      "Epoch 318/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.4145e-04 - val_loss: 2.0548e-04\n",
      "Epoch 319/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4285e-04 - val_loss: 2.0487e-04\n",
      "Epoch 320/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3790e-04 - val_loss: 2.0113e-04\n",
      "Epoch 321/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.3266e-04 - val_loss: 2.0289e-04\n",
      "Epoch 322/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.3373e-04 - val_loss: 1.9893e-04\n",
      "Epoch 323/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.3152e-04 - val_loss: 2.1651e-04\n",
      "Epoch 324/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.3095e-04 - val_loss: 2.0997e-04\n",
      "Epoch 325/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2896e-04 - val_loss: 1.9751e-04\n",
      "Epoch 326/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2942e-04 - val_loss: 1.9816e-04\n",
      "Epoch 327/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 1.2553e-04 - val_loss: 1.9490e-04\n",
      "Epoch 328/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.2943e-04 - val_loss: 2.0096e-04\n",
      "Epoch 329/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.2785e-04 - val_loss: 2.0089e-04\n",
      "Epoch 330/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2524e-04 - val_loss: 1.9694e-04\n",
      "Epoch 331/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.2898e-04 - val_loss: 1.9760e-04\n",
      "Epoch 332/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.2775e-04 - val_loss: 1.9094e-04\n",
      "Epoch 333/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 1.2663e-04 - val_loss: 1.9119e-04\n",
      "Epoch 334/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.2263e-04 - val_loss: 1.9000e-04\n",
      "Epoch 335/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.3176e-04 - val_loss: 1.8915e-04\n",
      "Epoch 336/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.2286e-04 - val_loss: 1.8794e-04\n",
      "Epoch 337/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.2634e-04 - val_loss: 1.9315e-04\n",
      "Epoch 338/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2474e-04 - val_loss: 1.8664e-04\n",
      "Epoch 339/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.2190e-04 - val_loss: 1.9311e-04\n",
      "Epoch 340/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.1860e-04 - val_loss: 1.8566e-04\n",
      "Epoch 341/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.1976e-04 - val_loss: 1.8291e-04\n",
      "Epoch 342/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 1.1797e-04 - val_loss: 1.8216e-04\n",
      "Epoch 343/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 1.1615e-04 - val_loss: 1.8382e-04\n",
      "Epoch 344/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1790e-04 - val_loss: 1.7972e-04\n",
      "Epoch 345/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.1647e-04 - val_loss: 1.9572e-04\n",
      "Epoch 346/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.1815e-04 - val_loss: 1.8311e-04\n",
      "Epoch 347/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.1611e-04 - val_loss: 1.8102e-04\n",
      "Epoch 348/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1650e-04 - val_loss: 1.8936e-04\n",
      "Epoch 349/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.1063e-04 - val_loss: 1.8254e-04\n",
      "Epoch 350/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.1338e-04 - val_loss: 1.7965e-04\n",
      "Epoch 351/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.0919e-04 - val_loss: 1.7919e-04\n",
      "Epoch 352/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.1379e-04 - val_loss: 1.7593e-04\n",
      "Epoch 353/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1005e-04 - val_loss: 1.7828e-04\n",
      "Epoch 354/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.1115e-04 - val_loss: 1.7410e-04\n",
      "Epoch 355/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.0847e-04 - val_loss: 1.7693e-04\n",
      "Epoch 356/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 1.0951e-04 - val_loss: 1.7261e-04\n",
      "Epoch 357/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.0900e-04 - val_loss: 1.7019e-04\n",
      "Epoch 358/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.0953e-04 - val_loss: 1.7220e-04\n",
      "Epoch 359/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.0920e-04 - val_loss: 1.7017e-04\n",
      "Epoch 360/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.0895e-04 - val_loss: 1.7812e-04\n",
      "Epoch 361/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.0642e-04 - val_loss: 1.6957e-04\n",
      "Epoch 362/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.0629e-04 - val_loss: 1.8110e-04\n",
      "Epoch 363/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.0397e-04 - val_loss: 1.6899e-04\n",
      "Epoch 364/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.0146e-04 - val_loss: 1.7746e-04\n",
      "Epoch 365/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.0644e-04 - val_loss: 1.6398e-04\n",
      "Epoch 366/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 9.7842e-05 - val_loss: 1.7529e-04\n",
      "Epoch 367/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 9.8387e-05 - val_loss: 1.7008e-04\n",
      "Epoch 368/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.0371e-04 - val_loss: 1.6717e-04\n",
      "Epoch 369/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.0205e-04 - val_loss: 1.6405e-04\n",
      "Epoch 370/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 9.8465e-05 - val_loss: 1.6431e-04\n",
      "Epoch 371/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 9.7506e-05 - val_loss: 1.6544e-04\n",
      "Epoch 372/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 9.6760e-05 - val_loss: 1.6066e-04\n",
      "Epoch 373/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.7837e-05 - val_loss: 1.5984e-04\n",
      "Epoch 374/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 9.5845e-05 - val_loss: 1.7185e-04\n",
      "Epoch 375/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 9.8526e-05 - val_loss: 1.7423e-04\n",
      "Epoch 376/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.0012e-04 - val_loss: 1.6293e-04\n",
      "Epoch 377/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.8978e-05 - val_loss: 1.5657e-04\n",
      "Epoch 378/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 9.7444e-05 - val_loss: 1.6698e-04\n",
      "Epoch 379/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.5532e-05 - val_loss: 1.5858e-04\n",
      "Epoch 380/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.5501e-05 - val_loss: 1.6077e-04\n",
      "Epoch 381/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.6256e-05 - val_loss: 1.6029e-04\n",
      "Epoch 382/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.5186e-05 - val_loss: 1.5343e-04\n",
      "Epoch 383/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.4252e-05 - val_loss: 1.5579e-04\n",
      "Epoch 384/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.2667e-05 - val_loss: 1.5162e-04\n",
      "Epoch 385/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.0173e-05 - val_loss: 1.5581e-04\n",
      "Epoch 386/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 8.9868e-05 - val_loss: 1.5645e-04\n",
      "Epoch 387/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.2213e-05 - val_loss: 1.4909e-04\n",
      "Epoch 388/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 8.9590e-05 - val_loss: 1.5184e-04\n",
      "Epoch 389/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.0843e-05 - val_loss: 1.5395e-04\n",
      "Epoch 390/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 9.1459e-05 - val_loss: 1.5005e-04\n",
      "Epoch 391/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.9480e-05 - val_loss: 1.4718e-04\n",
      "Epoch 392/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 8.7795e-05 - val_loss: 1.4700e-04\n",
      "Epoch 393/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.6381e-05 - val_loss: 1.4809e-04\n",
      "Epoch 394/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 8.9633e-05 - val_loss: 1.4681e-04\n",
      "Epoch 395/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 8.9839e-05 - val_loss: 1.5027e-04\n",
      "Epoch 396/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 8.8140e-05 - val_loss: 1.4743e-04\n",
      "Epoch 397/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.4015e-05 - val_loss: 1.4609e-04\n",
      "Epoch 398/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 8.2506e-05 - val_loss: 1.4260e-04\n",
      "Epoch 399/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.0060e-05 - val_loss: 1.4649e-04\n",
      "Epoch 400/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 8.6693e-05 - val_loss: 1.4319e-04\n",
      "Epoch 401/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 8.6406e-05 - val_loss: 1.5861e-04\n",
      "Epoch 402/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.6315e-05 - val_loss: 1.4349e-04\n",
      "Epoch 403/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 8.2161e-05 - val_loss: 1.4247e-04\n",
      "Epoch 404/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 8.3692e-05 - val_loss: 1.4509e-04\n",
      "Epoch 405/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 8.4809e-05 - val_loss: 1.4086e-04\n",
      "Epoch 406/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.1265e-05 - val_loss: 1.3832e-04\n",
      "Epoch 407/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 8.3056e-05 - val_loss: 1.3902e-04\n",
      "Epoch 408/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 7.8521e-05 - val_loss: 1.3778e-04\n",
      "Epoch 409/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 8.0772e-05 - val_loss: 1.3813e-04\n",
      "Epoch 410/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.2179e-05 - val_loss: 1.3860e-04\n",
      "Epoch 411/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.7529e-05 - val_loss: 1.3849e-04\n",
      "Epoch 412/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.5096e-05 - val_loss: 1.4377e-04\n",
      "Epoch 413/1000\n",
      "174/174 [==============================] - 0s 968us/step - loss: 7.7942e-05 - val_loss: 1.3994e-04\n",
      "Epoch 414/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.7466e-05 - val_loss: 1.4265e-04\n",
      "Epoch 415/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.7540e-05 - val_loss: 1.3673e-04\n",
      "Epoch 416/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 8.0044e-05 - val_loss: 1.3364e-04\n",
      "Epoch 417/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.8677e-05 - val_loss: 1.4012e-04\n",
      "Epoch 418/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.5711e-05 - val_loss: 1.3572e-04\n",
      "Epoch 419/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.3010e-05 - val_loss: 1.3229e-04\n",
      "Epoch 420/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.6756e-05 - val_loss: 1.3399e-04\n",
      "Epoch 421/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.4424e-05 - val_loss: 1.3091e-04\n",
      "Epoch 422/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.8484e-05 - val_loss: 1.3002e-04\n",
      "Epoch 423/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.3960e-05 - val_loss: 1.3193e-04\n",
      "Epoch 424/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.3184e-05 - val_loss: 1.2941e-04\n",
      "Epoch 425/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.6842e-05 - val_loss: 1.2884e-04\n",
      "Epoch 426/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 7.3184e-05 - val_loss: 1.3213e-04\n",
      "Epoch 427/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 7.2828e-05 - val_loss: 1.2970e-04\n",
      "Epoch 428/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 7.1881e-05 - val_loss: 1.2825e-04\n",
      "Epoch 429/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 7.1436e-05 - val_loss: 1.2646e-04\n",
      "Epoch 430/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 7.1061e-05 - val_loss: 1.2813e-04\n",
      "Epoch 431/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 7.3135e-05 - val_loss: 1.3621e-04\n",
      "Epoch 432/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.2357e-05 - val_loss: 1.2420e-04\n",
      "Epoch 433/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.0222e-05 - val_loss: 1.3224e-04\n",
      "Epoch 434/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 7.2635e-05 - val_loss: 1.2390e-04\n",
      "Epoch 435/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 6.9675e-05 - val_loss: 1.2675e-04\n",
      "Epoch 436/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 6.8332e-05 - val_loss: 1.2651e-04\n",
      "Epoch 437/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 7.0676e-05 - val_loss: 1.2323e-04\n",
      "Epoch 438/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 7.0686e-05 - val_loss: 1.3586e-04\n",
      "Epoch 439/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 6.6747e-05 - val_loss: 1.2537e-04\n",
      "Epoch 440/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 6.8545e-05 - val_loss: 1.2464e-04\n",
      "Epoch 441/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 6.7137e-05 - val_loss: 1.2381e-04\n",
      "Epoch 442/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.8396e-05 - val_loss: 1.2123e-04\n",
      "Epoch 443/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.8883e-05 - val_loss: 1.2402e-04\n",
      "Epoch 444/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.8196e-05 - val_loss: 1.3289e-04\n",
      "Epoch 445/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 6.6273e-05 - val_loss: 1.2237e-04\n",
      "Epoch 446/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 6.6630e-05 - val_loss: 1.2300e-04\n",
      "Epoch 447/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2704e-05 - val_loss: 1.2180e-04\n",
      "Epoch 448/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 6.6048e-05 - val_loss: 1.1797e-04\n",
      "Epoch 449/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 6.4334e-05 - val_loss: 1.2430e-04\n",
      "Epoch 450/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 6.7946e-05 - val_loss: 1.2105e-04\n",
      "Epoch 451/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2707e-05 - val_loss: 1.1847e-04\n",
      "Epoch 452/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 6.2609e-05 - val_loss: 1.2067e-04\n",
      "Epoch 453/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.3929e-05 - val_loss: 1.1774e-04\n",
      "Epoch 454/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.1601e-05 - val_loss: 1.1908e-04\n",
      "Epoch 455/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2705e-05 - val_loss: 1.1510e-04\n",
      "Epoch 456/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2820e-05 - val_loss: 1.1503e-04\n",
      "Epoch 457/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.3341e-05 - val_loss: 1.1965e-04\n",
      "Epoch 458/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.2912e-05 - val_loss: 1.1313e-04\n",
      "Epoch 459/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.1868e-05 - val_loss: 1.1959e-04\n",
      "Epoch 460/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 6.1104e-05 - val_loss: 1.1342e-04\n",
      "Epoch 461/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 5.9896e-05 - val_loss: 1.1303e-04\n",
      "Epoch 462/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 6.1295e-05 - val_loss: 1.1505e-04\n",
      "Epoch 463/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.1740e-05 - val_loss: 1.1567e-04\n",
      "Epoch 464/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 6.1483e-05 - val_loss: 1.1153e-04\n",
      "Epoch 465/1000\n",
      "174/174 [==============================] - 0s 962us/step - loss: 5.8782e-05 - val_loss: 1.1185e-04\n",
      "Epoch 466/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 6.2173e-05 - val_loss: 1.1299e-04\n",
      "Epoch 467/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 6.0263e-05 - val_loss: 1.1613e-04\n",
      "Epoch 468/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8927e-05 - val_loss: 1.1093e-04\n",
      "Epoch 469/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 5.9643e-05 - val_loss: 1.1061e-04\n",
      "Epoch 470/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8768e-05 - val_loss: 1.1157e-04\n",
      "Epoch 471/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8495e-05 - val_loss: 1.1306e-04\n",
      "Epoch 472/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 5.6712e-05 - val_loss: 1.1280e-04\n",
      "Epoch 473/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8513e-05 - val_loss: 1.0887e-04\n",
      "Epoch 474/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 5.8262e-05 - val_loss: 1.1192e-04\n",
      "Epoch 475/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.8861e-05 - val_loss: 1.0936e-04\n",
      "Epoch 476/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 5.5751e-05 - val_loss: 1.1895e-04\n",
      "Epoch 477/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 5.8088e-05 - val_loss: 1.0576e-04\n",
      "Epoch 478/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.5720e-05 - val_loss: 1.0906e-04\n",
      "Epoch 479/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.7606e-05 - val_loss: 1.0719e-04\n",
      "Epoch 480/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 5.6778e-05 - val_loss: 1.0525e-04\n",
      "Epoch 481/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 5.6059e-05 - val_loss: 1.0678e-04\n",
      "Epoch 482/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.4618e-05 - val_loss: 1.0657e-04\n",
      "Epoch 483/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 5.5439e-05 - val_loss: 1.0643e-04\n",
      "Epoch 484/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.5523e-05 - val_loss: 1.0766e-04\n",
      "Epoch 485/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 5.6978e-05 - val_loss: 1.0364e-04\n",
      "Epoch 486/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 5.5900e-05 - val_loss: 1.0331e-04\n",
      "Epoch 487/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.5147e-05 - val_loss: 1.0541e-04\n",
      "Epoch 488/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.6618e-05 - val_loss: 1.0286e-04\n",
      "Epoch 489/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.3498e-05 - val_loss: 1.0321e-04\n",
      "Epoch 490/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.3860e-05 - val_loss: 1.0129e-04\n",
      "Epoch 491/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.1626e-05 - val_loss: 1.0164e-04\n",
      "Epoch 492/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.4603e-05 - val_loss: 1.0402e-04\n",
      "Epoch 493/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.3131e-05 - val_loss: 1.0204e-04\n",
      "Epoch 494/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 5.3198e-05 - val_loss: 1.0090e-04\n",
      "Epoch 495/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 5.2161e-05 - val_loss: 9.9701e-05\n",
      "Epoch 496/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 5.4398e-05 - val_loss: 1.0631e-04\n",
      "Epoch 497/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 5.3119e-05 - val_loss: 1.0192e-04\n",
      "Epoch 498/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 5.2562e-05 - val_loss: 9.9201e-05\n",
      "Epoch 499/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 5.2756e-05 - val_loss: 1.0216e-04\n",
      "Epoch 500/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 5.3365e-05 - val_loss: 1.0129e-04\n",
      "Epoch 501/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.2305e-05 - val_loss: 9.8867e-05\n",
      "Epoch 502/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 5.0941e-05 - val_loss: 1.0174e-04\n",
      "Epoch 503/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 5.0971e-05 - val_loss: 9.9678e-05\n",
      "Epoch 504/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9999e-05 - val_loss: 1.0664e-04\n",
      "Epoch 505/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9354e-05 - val_loss: 9.6881e-05\n",
      "Epoch 506/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 5.1252e-05 - val_loss: 9.8126e-05\n",
      "Epoch 507/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 4.8273e-05 - val_loss: 9.7476e-05\n",
      "Epoch 508/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 4.9937e-05 - val_loss: 9.6802e-05\n",
      "Epoch 509/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9628e-05 - val_loss: 1.0174e-04\n",
      "Epoch 510/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 4.9162e-05 - val_loss: 9.6619e-05\n",
      "Epoch 511/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 4.8158e-05 - val_loss: 9.6489e-05\n",
      "Epoch 512/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.9120e-05 - val_loss: 9.8575e-05\n",
      "Epoch 513/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 4.7385e-05 - val_loss: 9.4111e-05\n",
      "Epoch 514/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 4.8705e-05 - val_loss: 9.7305e-05\n",
      "Epoch 515/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 4.7773e-05 - val_loss: 9.5740e-05\n",
      "Epoch 516/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8217e-05 - val_loss: 9.2719e-05\n",
      "Epoch 517/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 4.7260e-05 - val_loss: 9.4470e-05\n",
      "Epoch 518/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6768e-05 - val_loss: 9.6510e-05\n",
      "Epoch 519/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.8257e-05 - val_loss: 9.5189e-05\n",
      "Epoch 520/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8797e-05 - val_loss: 9.4014e-05\n",
      "Epoch 521/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.8720e-05 - val_loss: 9.3391e-05\n",
      "Epoch 522/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 4.8246e-05 - val_loss: 9.1960e-05\n",
      "Epoch 523/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.5222e-05 - val_loss: 9.1896e-05\n",
      "Epoch 524/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6498e-05 - val_loss: 9.2793e-05\n",
      "Epoch 525/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 4.6194e-05 - val_loss: 9.0724e-05\n",
      "Epoch 526/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 4.5926e-05 - val_loss: 9.2748e-05\n",
      "Epoch 527/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.6105e-05 - val_loss: 9.2023e-05\n",
      "Epoch 528/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 4.4581e-05 - val_loss: 9.0371e-05\n",
      "Epoch 529/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4024e-05 - val_loss: 9.1163e-05\n",
      "Epoch 530/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.4450e-05 - val_loss: 8.9750e-05\n",
      "Epoch 531/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3767e-05 - val_loss: 8.8437e-05\n",
      "Epoch 532/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 4.4550e-05 - val_loss: 8.8761e-05\n",
      "Epoch 533/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3879e-05 - val_loss: 8.8425e-05\n",
      "Epoch 534/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3697e-05 - val_loss: 8.9030e-05\n",
      "Epoch 535/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4937e-05 - val_loss: 8.8995e-05\n",
      "Epoch 536/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2719e-05 - val_loss: 8.7167e-05\n",
      "Epoch 537/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4199e-05 - val_loss: 9.0599e-05\n",
      "Epoch 538/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.4282e-05 - val_loss: 8.7778e-05\n",
      "Epoch 539/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3467e-05 - val_loss: 9.1823e-05\n",
      "Epoch 540/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3913e-05 - val_loss: 8.7240e-05\n",
      "Epoch 541/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3745e-05 - val_loss: 9.0393e-05\n",
      "Epoch 542/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0744e-05 - val_loss: 9.7173e-05\n",
      "Epoch 543/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.3884e-05 - val_loss: 8.9728e-05\n",
      "Epoch 544/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1773e-05 - val_loss: 9.1589e-05\n",
      "Epoch 545/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1275e-05 - val_loss: 8.7711e-05\n",
      "Epoch 546/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0852e-05 - val_loss: 8.5716e-05\n",
      "Epoch 547/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 4.1139e-05 - val_loss: 8.6109e-05\n",
      "Epoch 548/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 4.2659e-05 - val_loss: 8.5007e-05\n",
      "Epoch 549/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0801e-05 - val_loss: 8.5283e-05\n",
      "Epoch 550/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 4.1723e-05 - val_loss: 8.3899e-05\n",
      "Epoch 551/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 4.1130e-05 - val_loss: 8.3724e-05\n",
      "Epoch 552/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.2237e-05 - val_loss: 8.8196e-05\n",
      "Epoch 553/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1092e-05 - val_loss: 8.4855e-05\n",
      "Epoch 554/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 4.1687e-05 - val_loss: 8.4421e-05\n",
      "Epoch 555/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0460e-05 - val_loss: 8.3256e-05\n",
      "Epoch 556/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0873e-05 - val_loss: 8.3133e-05\n",
      "Epoch 557/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.1180e-05 - val_loss: 8.9715e-05\n",
      "Epoch 558/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0614e-05 - val_loss: 8.2827e-05\n",
      "Epoch 559/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 4.0833e-05 - val_loss: 8.6366e-05\n",
      "Epoch 560/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 4.0407e-05 - val_loss: 8.5119e-05\n",
      "Epoch 561/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8653e-05 - val_loss: 8.1634e-05\n",
      "Epoch 562/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.8754e-05 - val_loss: 8.0769e-05\n",
      "Epoch 563/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8811e-05 - val_loss: 8.1476e-05\n",
      "Epoch 564/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.9088e-05 - val_loss: 8.3886e-05\n",
      "Epoch 565/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 4.0175e-05 - val_loss: 8.6183e-05\n",
      "Epoch 566/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.9216e-05 - val_loss: 8.1845e-05\n",
      "Epoch 567/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 3.8755e-05 - val_loss: 8.2366e-05\n",
      "Epoch 568/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8940e-05 - val_loss: 7.9610e-05\n",
      "Epoch 569/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 4.0643e-05 - val_loss: 8.4360e-05\n",
      "Epoch 570/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 4.0531e-05 - val_loss: 8.1513e-05\n",
      "Epoch 571/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.7151e-05 - val_loss: 8.0143e-05\n",
      "Epoch 572/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7377e-05 - val_loss: 8.1207e-05\n",
      "Epoch 573/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.7305e-05 - val_loss: 8.0251e-05\n",
      "Epoch 574/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.9458e-05 - val_loss: 7.8974e-05\n",
      "Epoch 575/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6321e-05 - val_loss: 7.8654e-05\n",
      "Epoch 576/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8072e-05 - val_loss: 8.0135e-05\n",
      "Epoch 577/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.8137e-05 - val_loss: 8.0773e-05\n",
      "Epoch 578/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.7294e-05 - val_loss: 8.1417e-05\n",
      "Epoch 579/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6706e-05 - val_loss: 7.8700e-05\n",
      "Epoch 580/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 3.6197e-05 - val_loss: 7.6946e-05\n",
      "Epoch 581/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6578e-05 - val_loss: 7.9082e-05\n",
      "Epoch 582/1000\n",
      "174/174 [==============================] - 0s 962us/step - loss: 3.7132e-05 - val_loss: 7.8443e-05\n",
      "Epoch 583/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 3.8819e-05 - val_loss: 7.6617e-05\n",
      "Epoch 584/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.6918e-05 - val_loss: 7.7932e-05\n",
      "Epoch 585/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.5256e-05 - val_loss: 7.9388e-05\n",
      "Epoch 586/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.7733e-05 - val_loss: 7.6153e-05\n",
      "Epoch 587/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.5953e-05 - val_loss: 7.6797e-05\n",
      "Epoch 588/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.5690e-05 - val_loss: 7.6363e-05\n",
      "Epoch 589/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 3.6275e-05 - val_loss: 8.1107e-05\n",
      "Epoch 590/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 3.6017e-05 - val_loss: 7.4822e-05\n",
      "Epoch 591/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 3.4605e-05 - val_loss: 7.4528e-05\n",
      "Epoch 592/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.5180e-05 - val_loss: 7.4268e-05\n",
      "Epoch 593/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.6276e-05 - val_loss: 9.0156e-05\n",
      "Epoch 594/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 3.6910e-05 - val_loss: 7.5789e-05\n",
      "Epoch 595/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.4952e-05 - val_loss: 8.1708e-05\n",
      "Epoch 596/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 3.4166e-05 - val_loss: 7.6212e-05\n",
      "Epoch 597/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 3.5265e-05 - val_loss: 7.9336e-05\n",
      "Epoch 598/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.4863e-05 - val_loss: 7.4702e-05\n",
      "Epoch 599/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3383e-05 - val_loss: 7.5618e-05\n",
      "Epoch 600/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.3653e-05 - val_loss: 7.6435e-05\n",
      "Epoch 601/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.4742e-05 - val_loss: 7.5922e-05\n",
      "Epoch 602/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 3.5426e-05 - val_loss: 7.5190e-05\n",
      "Epoch 603/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 3.4182e-05 - val_loss: 7.2376e-05\n",
      "Epoch 604/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2193e-05 - val_loss: 7.4128e-05\n",
      "Epoch 605/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 3.3079e-05 - val_loss: 7.5161e-05\n",
      "Epoch 606/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 3.4737e-05 - val_loss: 7.2004e-05\n",
      "Epoch 607/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2640e-05 - val_loss: 7.2853e-05\n",
      "Epoch 608/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3063e-05 - val_loss: 7.2530e-05\n",
      "Epoch 609/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3561e-05 - val_loss: 7.3676e-05\n",
      "Epoch 610/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.3347e-05 - val_loss: 7.3066e-05\n",
      "Epoch 611/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2859e-05 - val_loss: 7.1985e-05\n",
      "Epoch 612/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2848e-05 - val_loss: 7.0838e-05\n",
      "Epoch 613/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2811e-05 - val_loss: 7.0361e-05\n",
      "Epoch 614/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2725e-05 - val_loss: 6.9955e-05\n",
      "Epoch 615/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.1648e-05 - val_loss: 7.2074e-05\n",
      "Epoch 616/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 3.2325e-05 - val_loss: 7.1475e-05\n",
      "Epoch 617/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.2712e-05 - val_loss: 6.9516e-05\n",
      "Epoch 618/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 3.0967e-05 - val_loss: 7.0252e-05\n",
      "Epoch 619/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.1555e-05 - val_loss: 7.1643e-05\n",
      "Epoch 620/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 3.3408e-05 - val_loss: 7.2385e-05\n",
      "Epoch 621/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0232e-05 - val_loss: 6.9522e-05\n",
      "Epoch 622/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0428e-05 - val_loss: 6.8595e-05\n",
      "Epoch 623/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 3.1198e-05 - val_loss: 6.8665e-05\n",
      "Epoch 624/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.9687e-05 - val_loss: 6.9542e-05\n",
      "Epoch 625/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 3.0846e-05 - val_loss: 7.7273e-05\n",
      "Epoch 626/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.2225e-05 - val_loss: 7.0100e-05\n",
      "Epoch 627/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0735e-05 - val_loss: 6.8893e-05\n",
      "Epoch 628/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 3.2118e-05 - val_loss: 6.7427e-05\n",
      "Epoch 629/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 2.9789e-05 - val_loss: 7.2309e-05\n",
      "Epoch 630/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0958e-05 - val_loss: 6.8546e-05\n",
      "Epoch 631/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 3.0478e-05 - val_loss: 7.2292e-05\n",
      "Epoch 632/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0786e-05 - val_loss: 6.6119e-05\n",
      "Epoch 633/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 3.1483e-05 - val_loss: 6.7111e-05\n",
      "Epoch 634/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.9710e-05 - val_loss: 6.9499e-05\n",
      "Epoch 635/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8923e-05 - val_loss: 7.3270e-05\n",
      "Epoch 636/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 3.0473e-05 - val_loss: 6.7046e-05\n",
      "Epoch 637/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9588e-05 - val_loss: 7.0211e-05\n",
      "Epoch 638/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.9776e-05 - val_loss: 6.6279e-05\n",
      "Epoch 639/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9072e-05 - val_loss: 6.6312e-05\n",
      "Epoch 640/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.9709e-05 - val_loss: 6.9997e-05\n",
      "Epoch 641/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9877e-05 - val_loss: 6.9160e-05\n",
      "Epoch 642/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.9266e-05 - val_loss: 6.9574e-05\n",
      "Epoch 643/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9613e-05 - val_loss: 6.9030e-05\n",
      "Epoch 644/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9597e-05 - val_loss: 6.5534e-05\n",
      "Epoch 645/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9655e-05 - val_loss: 6.4690e-05\n",
      "Epoch 646/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9269e-05 - val_loss: 6.5201e-05\n",
      "Epoch 647/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.9896e-05 - val_loss: 6.5662e-05\n",
      "Epoch 648/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8554e-05 - val_loss: 7.0021e-05\n",
      "Epoch 649/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.9217e-05 - val_loss: 6.5587e-05\n",
      "Epoch 650/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 2.9601e-05 - val_loss: 6.6140e-05\n",
      "Epoch 651/1000\n",
      "174/174 [==============================] - 0s 970us/step - loss: 2.8887e-05 - val_loss: 6.5934e-05\n",
      "Epoch 652/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 2.9021e-05 - val_loss: 7.2090e-05\n",
      "Epoch 653/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 2.8409e-05 - val_loss: 6.3511e-05\n",
      "Epoch 654/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7676e-05 - val_loss: 6.4846e-05\n",
      "Epoch 655/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.7131e-05 - val_loss: 6.5667e-05\n",
      "Epoch 656/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.8598e-05 - val_loss: 7.2140e-05\n",
      "Epoch 657/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 2.8755e-05 - val_loss: 6.5058e-05\n",
      "Epoch 658/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.7894e-05 - val_loss: 6.5226e-05\n",
      "Epoch 659/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 3.0031e-05 - val_loss: 6.3132e-05\n",
      "Epoch 660/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.7713e-05 - val_loss: 6.1669e-05\n",
      "Epoch 661/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.8165e-05 - val_loss: 6.3163e-05\n",
      "Epoch 662/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.7307e-05 - val_loss: 6.3312e-05\n",
      "Epoch 663/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.7694e-05 - val_loss: 6.4451e-05\n",
      "Epoch 664/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.6845e-05 - val_loss: 6.2767e-05\n",
      "Epoch 665/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6482e-05 - val_loss: 6.3508e-05\n",
      "Epoch 666/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.6430e-05 - val_loss: 6.1953e-05\n",
      "Epoch 667/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.7503e-05 - val_loss: 6.3177e-05\n",
      "Epoch 668/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6387e-05 - val_loss: 6.1498e-05\n",
      "Epoch 669/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 2.6535e-05 - val_loss: 6.2995e-05\n",
      "Epoch 670/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.6227e-05 - val_loss: 6.0958e-05\n",
      "Epoch 671/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.7731e-05 - val_loss: 6.5634e-05\n",
      "Epoch 672/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.7315e-05 - val_loss: 6.6069e-05\n",
      "Epoch 673/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 2.7367e-05 - val_loss: 6.3197e-05\n",
      "Epoch 674/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5901e-05 - val_loss: 6.4000e-05\n",
      "Epoch 675/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.7920e-05 - val_loss: 6.3705e-05\n",
      "Epoch 676/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.6844e-05 - val_loss: 5.9716e-05\n",
      "Epoch 677/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.6083e-05 - val_loss: 6.1968e-05\n",
      "Epoch 678/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.5491e-05 - val_loss: 6.1668e-05\n",
      "Epoch 679/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5563e-05 - val_loss: 5.9362e-05\n",
      "Epoch 680/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5501e-05 - val_loss: 6.0014e-05\n",
      "Epoch 681/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 2.5607e-05 - val_loss: 6.0896e-05\n",
      "Epoch 682/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.6555e-05 - val_loss: 5.8493e-05\n",
      "Epoch 683/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.6806e-05 - val_loss: 6.0608e-05\n",
      "Epoch 684/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.6202e-05 - val_loss: 6.2931e-05\n",
      "Epoch 685/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.6221e-05 - val_loss: 5.9886e-05\n",
      "Epoch 686/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 2.6631e-05 - val_loss: 5.8921e-05\n",
      "Epoch 687/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5689e-05 - val_loss: 6.0909e-05\n",
      "Epoch 688/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 2.6268e-05 - val_loss: 6.0361e-05\n",
      "Epoch 689/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.6573e-05 - val_loss: 6.0295e-05\n",
      "Epoch 690/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.4851e-05 - val_loss: 5.9768e-05\n",
      "Epoch 691/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 2.4600e-05 - val_loss: 5.8544e-05\n",
      "Epoch 692/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4542e-05 - val_loss: 5.8206e-05\n",
      "Epoch 693/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.3840e-05 - val_loss: 5.8722e-05\n",
      "Epoch 694/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5184e-05 - val_loss: 6.1754e-05\n",
      "Epoch 695/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.5932e-05 - val_loss: 5.8370e-05\n",
      "Epoch 696/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3914e-05 - val_loss: 5.8523e-05\n",
      "Epoch 697/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4709e-05 - val_loss: 5.7076e-05\n",
      "Epoch 698/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4978e-05 - val_loss: 6.0198e-05\n",
      "Epoch 699/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4286e-05 - val_loss: 5.6881e-05\n",
      "Epoch 700/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 2.3966e-05 - val_loss: 6.2605e-05\n",
      "Epoch 701/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.5250e-05 - val_loss: 5.8898e-05\n",
      "Epoch 702/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.3171e-05 - val_loss: 5.8601e-05\n",
      "Epoch 703/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.5002e-05 - val_loss: 5.8180e-05\n",
      "Epoch 704/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.4141e-05 - val_loss: 5.6207e-05\n",
      "Epoch 705/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 2.3297e-05 - val_loss: 5.7798e-05\n",
      "Epoch 706/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4315e-05 - val_loss: 6.0167e-05\n",
      "Epoch 707/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3836e-05 - val_loss: 5.8843e-05\n",
      "Epoch 708/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 2.4173e-05 - val_loss: 5.5671e-05\n",
      "Epoch 709/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2961e-05 - val_loss: 5.6104e-05\n",
      "Epoch 710/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3279e-05 - val_loss: 5.5890e-05\n",
      "Epoch 711/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.2890e-05 - val_loss: 5.6270e-05\n",
      "Epoch 712/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 2.3453e-05 - val_loss: 5.6453e-05\n",
      "Epoch 713/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3677e-05 - val_loss: 5.7203e-05\n",
      "Epoch 714/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.4187e-05 - val_loss: 5.7483e-05\n",
      "Epoch 715/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3556e-05 - val_loss: 5.5921e-05\n",
      "Epoch 716/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3175e-05 - val_loss: 5.5636e-05\n",
      "Epoch 717/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3355e-05 - val_loss: 5.5144e-05\n",
      "Epoch 718/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.3246e-05 - val_loss: 5.7108e-05\n",
      "Epoch 719/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.3220e-05 - val_loss: 5.5093e-05\n",
      "Epoch 720/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.1512e-05 - val_loss: 5.5502e-05\n",
      "Epoch 721/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 2.1998e-05 - val_loss: 5.6052e-05\n",
      "Epoch 722/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 2.3883e-05 - val_loss: 6.0689e-05\n",
      "Epoch 723/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.2550e-05 - val_loss: 5.4643e-05\n",
      "Epoch 724/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.3834e-05 - val_loss: 5.5025e-05\n",
      "Epoch 725/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.3581e-05 - val_loss: 5.4558e-05\n",
      "Epoch 726/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 2.2963e-05 - val_loss: 5.3926e-05\n",
      "Epoch 727/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 2.1792e-05 - val_loss: 5.3345e-05\n",
      "Epoch 728/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.3084e-05 - val_loss: 5.5110e-05\n",
      "Epoch 729/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.2130e-05 - val_loss: 5.4591e-05\n",
      "Epoch 730/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.2901e-05 - val_loss: 5.4244e-05\n",
      "Epoch 731/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.3031e-05 - val_loss: 5.5497e-05\n",
      "Epoch 732/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 2.2090e-05 - val_loss: 5.4409e-05\n",
      "Epoch 733/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 2.1836e-05 - val_loss: 5.4121e-05\n",
      "Epoch 734/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.1344e-05 - val_loss: 5.3419e-05\n",
      "Epoch 735/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1385e-05 - val_loss: 5.5104e-05\n",
      "Epoch 736/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1494e-05 - val_loss: 5.3783e-05\n",
      "Epoch 737/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1695e-05 - val_loss: 5.5689e-05\n",
      "Epoch 738/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.1076e-05 - val_loss: 5.3011e-05\n",
      "Epoch 739/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 2.2082e-05 - val_loss: 5.4768e-05\n",
      "Epoch 740/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 2.1821e-05 - val_loss: 5.5759e-05\n",
      "Epoch 741/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 2.0868e-05 - val_loss: 5.4994e-05\n",
      "Epoch 742/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1322e-05 - val_loss: 5.4331e-05\n",
      "Epoch 743/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 2.1626e-05 - val_loss: 5.4292e-05\n",
      "Epoch 744/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1400e-05 - val_loss: 5.3751e-05\n",
      "Epoch 745/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1732e-05 - val_loss: 5.2508e-05\n",
      "Epoch 746/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.0724e-05 - val_loss: 5.3079e-05\n",
      "Epoch 747/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 2.0907e-05 - val_loss: 5.1242e-05\n",
      "Epoch 748/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1007e-05 - val_loss: 5.2436e-05\n",
      "Epoch 749/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 2.1220e-05 - val_loss: 5.1562e-05\n",
      "Epoch 750/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.9831e-05 - val_loss: 6.7193e-05\n",
      "Epoch 751/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 2.3821e-05 - val_loss: 5.4415e-05\n",
      "Epoch 752/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0272e-05 - val_loss: 5.4266e-05\n",
      "Epoch 753/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.0802e-05 - val_loss: 5.2155e-05\n",
      "Epoch 754/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1219e-05 - val_loss: 5.3600e-05\n",
      "Epoch 755/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.1021e-05 - val_loss: 5.6957e-05\n",
      "Epoch 756/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 2.0624e-05 - val_loss: 5.0991e-05\n",
      "Epoch 757/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 2.0020e-05 - val_loss: 5.3110e-05\n",
      "Epoch 758/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1199e-05 - val_loss: 5.0703e-05\n",
      "Epoch 759/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0964e-05 - val_loss: 5.1897e-05\n",
      "Epoch 760/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0121e-05 - val_loss: 5.0848e-05\n",
      "Epoch 761/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9789e-05 - val_loss: 5.0381e-05\n",
      "Epoch 762/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1100e-05 - val_loss: 5.0519e-05\n",
      "Epoch 763/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0909e-05 - val_loss: 5.0704e-05\n",
      "Epoch 764/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0929e-05 - val_loss: 5.0988e-05\n",
      "Epoch 765/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.1271e-05 - val_loss: 5.7427e-05\n",
      "Epoch 766/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0213e-05 - val_loss: 4.9538e-05\n",
      "Epoch 767/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0129e-05 - val_loss: 5.5781e-05\n",
      "Epoch 768/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0592e-05 - val_loss: 5.0127e-05\n",
      "Epoch 769/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.9187e-05 - val_loss: 5.0741e-05\n",
      "Epoch 770/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 2.0181e-05 - val_loss: 4.9538e-05\n",
      "Epoch 771/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.9831e-05 - val_loss: 4.9557e-05\n",
      "Epoch 772/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 1.9528e-05 - val_loss: 4.9351e-05\n",
      "Epoch 773/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9168e-05 - val_loss: 4.9659e-05\n",
      "Epoch 774/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9326e-05 - val_loss: 5.0295e-05\n",
      "Epoch 775/1000\n",
      "174/174 [==============================] - 0s 980us/step - loss: 2.0663e-05 - val_loss: 5.3028e-05\n",
      "Epoch 776/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.9918e-05 - val_loss: 5.0641e-05\n",
      "Epoch 777/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.9191e-05 - val_loss: 4.8240e-05\n",
      "Epoch 778/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.8814e-05 - val_loss: 5.0533e-05\n",
      "Epoch 779/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 2.0788e-05 - val_loss: 5.0729e-05\n",
      "Epoch 780/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9255e-05 - val_loss: 4.8722e-05\n",
      "Epoch 781/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9510e-05 - val_loss: 5.0599e-05\n",
      "Epoch 782/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 2.0704e-05 - val_loss: 4.9283e-05\n",
      "Epoch 783/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9235e-05 - val_loss: 4.8204e-05\n",
      "Epoch 784/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.8997e-05 - val_loss: 4.8051e-05\n",
      "Epoch 785/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.9582e-05 - val_loss: 4.8840e-05\n",
      "Epoch 786/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 1.9555e-05 - val_loss: 4.7674e-05\n",
      "Epoch 787/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8683e-05 - val_loss: 4.9613e-05\n",
      "Epoch 788/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8458e-05 - val_loss: 4.7072e-05\n",
      "Epoch 789/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.8668e-05 - val_loss: 4.8171e-05\n",
      "Epoch 790/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.9258e-05 - val_loss: 4.9524e-05\n",
      "Epoch 791/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.8448e-05 - val_loss: 5.0664e-05\n",
      "Epoch 792/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.8750e-05 - val_loss: 4.8708e-05\n",
      "Epoch 793/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.9365e-05 - val_loss: 4.7472e-05\n",
      "Epoch 794/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.8842e-05 - val_loss: 4.8993e-05\n",
      "Epoch 795/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.9047e-05 - val_loss: 4.8342e-05\n",
      "Epoch 796/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8889e-05 - val_loss: 4.9257e-05\n",
      "Epoch 797/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8328e-05 - val_loss: 4.7315e-05\n",
      "Epoch 798/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8507e-05 - val_loss: 4.7006e-05\n",
      "Epoch 799/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8548e-05 - val_loss: 4.7871e-05\n",
      "Epoch 800/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7204e-05 - val_loss: 4.6401e-05\n",
      "Epoch 801/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.8382e-05 - val_loss: 4.7575e-05\n",
      "Epoch 802/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.8230e-05 - val_loss: 4.9195e-05\n",
      "Epoch 803/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.9592e-05 - val_loss: 4.6903e-05\n",
      "Epoch 804/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7861e-05 - val_loss: 5.2839e-05\n",
      "Epoch 805/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 1.9253e-05 - val_loss: 4.6202e-05\n",
      "Epoch 806/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.7496e-05 - val_loss: 4.8702e-05\n",
      "Epoch 807/1000\n",
      "174/174 [==============================] - 0s 972us/step - loss: 1.7791e-05 - val_loss: 4.8174e-05\n",
      "Epoch 808/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7466e-05 - val_loss: 4.9910e-05\n",
      "Epoch 809/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7238e-05 - val_loss: 4.5297e-05\n",
      "Epoch 810/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.8116e-05 - val_loss: 4.7187e-05\n",
      "Epoch 811/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.7767e-05 - val_loss: 4.7997e-05\n",
      "Epoch 812/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.8218e-05 - val_loss: 4.5709e-05\n",
      "Epoch 813/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.7778e-05 - val_loss: 4.5867e-05\n",
      "Epoch 814/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7396e-05 - val_loss: 4.6970e-05\n",
      "Epoch 815/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.6798e-05 - val_loss: 4.5101e-05\n",
      "Epoch 816/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.8158e-05 - val_loss: 4.6138e-05\n",
      "Epoch 817/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.8373e-05 - val_loss: 4.4357e-05\n",
      "Epoch 818/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6658e-05 - val_loss: 4.4626e-05\n",
      "Epoch 819/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.7150e-05 - val_loss: 4.5916e-05\n",
      "Epoch 820/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.6848e-05 - val_loss: 4.7844e-05\n",
      "Epoch 821/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.7686e-05 - val_loss: 4.5738e-05\n",
      "Epoch 822/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.6876e-05 - val_loss: 4.6090e-05\n",
      "Epoch 823/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.6461e-05 - val_loss: 4.6044e-05\n",
      "Epoch 824/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.6888e-05 - val_loss: 4.6323e-05\n",
      "Epoch 825/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.6389e-05 - val_loss: 4.4399e-05\n",
      "Epoch 826/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.6800e-05 - val_loss: 4.6266e-05\n",
      "Epoch 827/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.7163e-05 - val_loss: 4.3624e-05\n",
      "Epoch 828/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.6864e-05 - val_loss: 4.4210e-05\n",
      "Epoch 829/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6668e-05 - val_loss: 4.4455e-05\n",
      "Epoch 830/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6112e-05 - val_loss: 4.5115e-05\n",
      "Epoch 831/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7422e-05 - val_loss: 4.3313e-05\n",
      "Epoch 832/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.7089e-05 - val_loss: 4.4772e-05\n",
      "Epoch 833/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7000e-05 - val_loss: 4.4815e-05\n",
      "Epoch 834/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.6377e-05 - val_loss: 4.6070e-05\n",
      "Epoch 835/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.7111e-05 - val_loss: 4.3402e-05\n",
      "Epoch 836/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6333e-05 - val_loss: 4.4742e-05\n",
      "Epoch 837/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.6841e-05 - val_loss: 4.3966e-05\n",
      "Epoch 838/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.6749e-05 - val_loss: 4.5668e-05\n",
      "Epoch 839/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.6127e-05 - val_loss: 4.5754e-05\n",
      "Epoch 840/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7077e-05 - val_loss: 4.2932e-05\n",
      "Epoch 841/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6389e-05 - val_loss: 4.5935e-05\n",
      "Epoch 842/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.7251e-05 - val_loss: 4.3051e-05\n",
      "Epoch 843/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6265e-05 - val_loss: 4.3458e-05\n",
      "Epoch 844/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6304e-05 - val_loss: 4.3733e-05\n",
      "Epoch 845/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6526e-05 - val_loss: 4.2632e-05\n",
      "Epoch 846/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6323e-05 - val_loss: 4.3454e-05\n",
      "Epoch 847/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6178e-05 - val_loss: 4.3153e-05\n",
      "Epoch 848/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5996e-05 - val_loss: 4.4483e-05\n",
      "Epoch 849/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.6081e-05 - val_loss: 4.2626e-05\n",
      "Epoch 850/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5488e-05 - val_loss: 4.3426e-05\n",
      "Epoch 851/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5511e-05 - val_loss: 4.2687e-05\n",
      "Epoch 852/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5836e-05 - val_loss: 4.3562e-05\n",
      "Epoch 853/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5766e-05 - val_loss: 4.2242e-05\n",
      "Epoch 854/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5512e-05 - val_loss: 4.2191e-05\n",
      "Epoch 855/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.5091e-05 - val_loss: 4.2986e-05\n",
      "Epoch 856/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5547e-05 - val_loss: 4.2774e-05\n",
      "Epoch 857/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.5835e-05 - val_loss: 4.4761e-05\n",
      "Epoch 858/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.6804e-05 - val_loss: 4.2023e-05\n",
      "Epoch 859/1000\n",
      "174/174 [==============================] - 0s 983us/step - loss: 1.6063e-05 - val_loss: 4.2596e-05\n",
      "Epoch 860/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.5322e-05 - val_loss: 4.6923e-05\n",
      "Epoch 861/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.6845e-05 - val_loss: 4.1676e-05\n",
      "Epoch 862/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5545e-05 - val_loss: 4.1203e-05\n",
      "Epoch 863/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4473e-05 - val_loss: 4.3091e-05\n",
      "Epoch 864/1000\n",
      "174/174 [==============================] - 0s 971us/step - loss: 1.4878e-05 - val_loss: 4.3294e-05\n",
      "Epoch 865/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5020e-05 - val_loss: 4.2627e-05\n",
      "Epoch 866/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.4704e-05 - val_loss: 4.1919e-05\n",
      "Epoch 867/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.5432e-05 - val_loss: 4.0953e-05\n",
      "Epoch 868/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.5101e-05 - val_loss: 4.2418e-05\n",
      "Epoch 869/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.5152e-05 - val_loss: 4.2171e-05\n",
      "Epoch 870/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.5213e-05 - val_loss: 4.1686e-05\n",
      "Epoch 871/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5823e-05 - val_loss: 4.1299e-05\n",
      "Epoch 872/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.5167e-05 - val_loss: 4.3025e-05\n",
      "Epoch 873/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.5933e-05 - val_loss: 4.5462e-05\n",
      "Epoch 874/1000\n",
      "174/174 [==============================] - 0s 999us/step - loss: 1.5268e-05 - val_loss: 4.3337e-05\n",
      "Epoch 875/1000\n",
      "174/174 [==============================] - 0s 981us/step - loss: 1.5051e-05 - val_loss: 4.2185e-05\n",
      "Epoch 876/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4432e-05 - val_loss: 4.1868e-05\n",
      "Epoch 877/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.4718e-05 - val_loss: 4.0855e-05\n",
      "Epoch 878/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4518e-05 - val_loss: 4.1196e-05\n",
      "Epoch 879/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5713e-05 - val_loss: 4.0050e-05\n",
      "Epoch 880/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4894e-05 - val_loss: 4.0363e-05\n",
      "Epoch 881/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4756e-05 - val_loss: 4.1652e-05\n",
      "Epoch 882/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.4310e-05 - val_loss: 4.1460e-05\n",
      "Epoch 883/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.4803e-05 - val_loss: 4.1990e-05\n",
      "Epoch 884/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5152e-05 - val_loss: 4.0257e-05\n",
      "Epoch 885/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4922e-05 - val_loss: 4.0107e-05\n",
      "Epoch 886/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4724e-05 - val_loss: 4.0625e-05\n",
      "Epoch 887/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4684e-05 - val_loss: 3.9629e-05\n",
      "Epoch 888/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3611e-05 - val_loss: 4.1558e-05\n",
      "Epoch 889/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 1.4682e-05 - val_loss: 4.2700e-05\n",
      "Epoch 890/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4584e-05 - val_loss: 4.0736e-05\n",
      "Epoch 891/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4669e-05 - val_loss: 4.1064e-05\n",
      "Epoch 892/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.5096e-05 - val_loss: 3.9781e-05\n",
      "Epoch 893/1000\n",
      "174/174 [==============================] - 0s 997us/step - loss: 1.4120e-05 - val_loss: 4.0247e-05\n",
      "Epoch 894/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.4461e-05 - val_loss: 4.1720e-05\n",
      "Epoch 895/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.4433e-05 - val_loss: 3.9273e-05\n",
      "Epoch 896/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.4194e-05 - val_loss: 4.1935e-05\n",
      "Epoch 897/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3634e-05 - val_loss: 3.9998e-05\n",
      "Epoch 898/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.4467e-05 - val_loss: 4.0080e-05\n",
      "Epoch 899/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.4448e-05 - val_loss: 4.0213e-05\n",
      "Epoch 900/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4037e-05 - val_loss: 3.8724e-05\n",
      "Epoch 901/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3702e-05 - val_loss: 3.9218e-05\n",
      "Epoch 902/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3834e-05 - val_loss: 4.1152e-05\n",
      "Epoch 903/1000\n",
      "174/174 [==============================] - 0s 977us/step - loss: 1.4475e-05 - val_loss: 4.0316e-05\n",
      "Epoch 904/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.3632e-05 - val_loss: 3.9744e-05\n",
      "Epoch 905/1000\n",
      "174/174 [==============================] - 0s 974us/step - loss: 1.3842e-05 - val_loss: 3.9063e-05\n",
      "Epoch 906/1000\n",
      "174/174 [==============================] - 0s 976us/step - loss: 1.3732e-05 - val_loss: 3.9205e-05\n",
      "Epoch 907/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3674e-05 - val_loss: 3.8344e-05\n",
      "Epoch 908/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3559e-05 - val_loss: 3.8372e-05\n",
      "Epoch 909/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.4191e-05 - val_loss: 4.0828e-05\n",
      "Epoch 910/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4634e-05 - val_loss: 4.2132e-05\n",
      "Epoch 911/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4346e-05 - val_loss: 3.9344e-05\n",
      "Epoch 912/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3719e-05 - val_loss: 4.1914e-05\n",
      "Epoch 913/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.5578e-05 - val_loss: 4.1125e-05\n",
      "Epoch 914/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3748e-05 - val_loss: 3.8614e-05\n",
      "Epoch 915/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.3586e-05 - val_loss: 3.7982e-05\n",
      "Epoch 916/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.3200e-05 - val_loss: 4.0174e-05\n",
      "Epoch 917/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.3500e-05 - val_loss: 3.8324e-05\n",
      "Epoch 918/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3993e-05 - val_loss: 4.0592e-05\n",
      "Epoch 919/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3103e-05 - val_loss: 3.8341e-05\n",
      "Epoch 920/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3563e-05 - val_loss: 3.9527e-05\n",
      "Epoch 921/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3480e-05 - val_loss: 3.8403e-05\n",
      "Epoch 922/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.4035e-05 - val_loss: 3.8354e-05\n",
      "Epoch 923/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.3449e-05 - val_loss: 3.9767e-05\n",
      "Epoch 924/1000\n",
      "174/174 [==============================] - 0s 982us/step - loss: 1.3858e-05 - val_loss: 3.8278e-05\n",
      "Epoch 925/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.3299e-05 - val_loss: 3.7722e-05\n",
      "Epoch 926/1000\n",
      "174/174 [==============================] - 0s 984us/step - loss: 1.2568e-05 - val_loss: 3.8073e-05\n",
      "Epoch 927/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3747e-05 - val_loss: 4.0125e-05\n",
      "Epoch 928/1000\n",
      "174/174 [==============================] - 0s 992us/step - loss: 1.2926e-05 - val_loss: 3.8873e-05\n",
      "Epoch 929/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.3093e-05 - val_loss: 3.7157e-05\n",
      "Epoch 930/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.3521e-05 - val_loss: 3.8024e-05\n",
      "Epoch 931/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2746e-05 - val_loss: 3.7301e-05\n",
      "Epoch 932/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3242e-05 - val_loss: 3.8303e-05\n",
      "Epoch 933/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.3543e-05 - val_loss: 3.7770e-05\n",
      "Epoch 934/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.3089e-05 - val_loss: 3.6733e-05\n",
      "Epoch 935/1000\n",
      "174/174 [==============================] - 0s 969us/step - loss: 1.3027e-05 - val_loss: 3.8090e-05\n",
      "Epoch 936/1000\n",
      "174/174 [==============================] - 0s 996us/step - loss: 1.2978e-05 - val_loss: 3.8995e-05\n",
      "Epoch 937/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.3183e-05 - val_loss: 3.8976e-05\n",
      "Epoch 938/1000\n",
      "174/174 [==============================] - 0s 973us/step - loss: 1.3283e-05 - val_loss: 3.7287e-05\n",
      "Epoch 939/1000\n",
      "174/174 [==============================] - 0s 967us/step - loss: 1.3917e-05 - val_loss: 3.6908e-05\n",
      "Epoch 940/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.2135e-05 - val_loss: 3.7748e-05\n",
      "Epoch 941/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3686e-05 - val_loss: 3.6852e-05\n",
      "Epoch 942/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.3104e-05 - val_loss: 3.8097e-05\n",
      "Epoch 943/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2569e-05 - val_loss: 3.7292e-05\n",
      "Epoch 944/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.3027e-05 - val_loss: 3.7203e-05\n",
      "Epoch 945/1000\n",
      "174/174 [==============================] - 0s 989us/step - loss: 1.2968e-05 - val_loss: 3.6460e-05\n",
      "Epoch 946/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.2368e-05 - val_loss: 3.9332e-05\n",
      "Epoch 947/1000\n",
      "174/174 [==============================] - 0s 995us/step - loss: 1.3373e-05 - val_loss: 3.9411e-05\n",
      "Epoch 948/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2634e-05 - val_loss: 3.7071e-05\n",
      "Epoch 949/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.2113e-05 - val_loss: 3.8307e-05\n",
      "Epoch 950/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.2725e-05 - val_loss: 3.7458e-05\n",
      "Epoch 951/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.2593e-05 - val_loss: 3.7548e-05\n",
      "Epoch 952/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2493e-05 - val_loss: 3.9719e-05\n",
      "Epoch 953/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.3120e-05 - val_loss: 4.0466e-05\n",
      "Epoch 954/1000\n",
      "174/174 [==============================] - 0s 1000us/step - loss: 1.4390e-05 - val_loss: 3.6582e-05\n",
      "Epoch 955/1000\n",
      "174/174 [==============================] - 0s 985us/step - loss: 1.2065e-05 - val_loss: 3.6137e-05\n",
      "Epoch 956/1000\n",
      "174/174 [==============================] - 0s 994us/step - loss: 1.2054e-05 - val_loss: 3.9733e-05\n",
      "Epoch 957/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2158e-05 - val_loss: 3.6328e-05\n",
      "Epoch 958/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.2511e-05 - val_loss: 3.6913e-05\n",
      "Epoch 959/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2781e-05 - val_loss: 3.5511e-05\n",
      "Epoch 960/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2957e-05 - val_loss: 3.6418e-05\n",
      "Epoch 961/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.2731e-05 - val_loss: 3.5635e-05\n",
      "Epoch 962/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.2663e-05 - val_loss: 3.5620e-05\n",
      "Epoch 963/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.1825e-05 - val_loss: 3.6408e-05\n",
      "Epoch 964/1000\n",
      "174/174 [==============================] - 0s 975us/step - loss: 1.2299e-05 - val_loss: 3.6290e-05\n",
      "Epoch 965/1000\n",
      "174/174 [==============================] - 0s 987us/step - loss: 1.2423e-05 - val_loss: 3.5960e-05\n",
      "Epoch 966/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2142e-05 - val_loss: 3.6272e-05\n",
      "Epoch 967/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.1573e-05 - val_loss: 3.5718e-05\n",
      "Epoch 968/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.1681e-05 - val_loss: 3.5936e-05\n",
      "Epoch 969/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1909e-05 - val_loss: 3.5948e-05\n",
      "Epoch 970/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.2135e-05 - val_loss: 3.4907e-05\n",
      "Epoch 971/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2499e-05 - val_loss: 3.5256e-05\n",
      "Epoch 972/1000\n",
      "174/174 [==============================] - 0s 986us/step - loss: 1.2365e-05 - val_loss: 3.5052e-05\n",
      "Epoch 973/1000\n",
      "174/174 [==============================] - 0s 979us/step - loss: 1.1826e-05 - val_loss: 3.5029e-05\n",
      "Epoch 974/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2263e-05 - val_loss: 3.6248e-05\n",
      "Epoch 975/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2038e-05 - val_loss: 3.7255e-05\n",
      "Epoch 976/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2192e-05 - val_loss: 3.8296e-05\n",
      "Epoch 977/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1349e-05 - val_loss: 3.6165e-05\n",
      "Epoch 978/1000\n",
      "174/174 [==============================] - 0s 991us/step - loss: 1.1262e-05 - val_loss: 3.5888e-05\n",
      "Epoch 979/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.1644e-05 - val_loss: 3.4383e-05\n",
      "Epoch 980/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2127e-05 - val_loss: 3.4693e-05\n",
      "Epoch 981/1000\n",
      "174/174 [==============================] - 0s 990us/step - loss: 1.1704e-05 - val_loss: 3.5600e-05\n",
      "Epoch 982/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1180e-05 - val_loss: 3.6532e-05\n",
      "Epoch 983/1000\n",
      "174/174 [==============================] - 0s 998us/step - loss: 1.1998e-05 - val_loss: 3.5032e-05\n",
      "Epoch 984/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1935e-05 - val_loss: 3.4919e-05\n",
      "Epoch 985/1000\n",
      "174/174 [==============================] - 0s 978us/step - loss: 1.1435e-05 - val_loss: 3.6687e-05\n",
      "Epoch 986/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1716e-05 - val_loss: 3.4831e-05\n",
      "Epoch 987/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1607e-05 - val_loss: 3.5773e-05\n",
      "Epoch 988/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1485e-05 - val_loss: 3.4273e-05\n",
      "Epoch 989/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1308e-05 - val_loss: 3.4179e-05\n",
      "Epoch 990/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1518e-05 - val_loss: 3.5418e-05\n",
      "Epoch 991/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1312e-05 - val_loss: 3.4680e-05\n",
      "Epoch 992/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.2357e-05 - val_loss: 3.6043e-05\n",
      "Epoch 993/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1275e-05 - val_loss: 3.8088e-05\n",
      "Epoch 994/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1639e-05 - val_loss: 3.4813e-05\n",
      "Epoch 995/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1169e-05 - val_loss: 3.5183e-05\n",
      "Epoch 996/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1085e-05 - val_loss: 3.3958e-05\n",
      "Epoch 997/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.1273e-05 - val_loss: 3.5295e-05\n",
      "Epoch 998/1000\n",
      "174/174 [==============================] - 0s 1ms/step - loss: 1.0976e-05 - val_loss: 3.4503e-05\n",
      "Epoch 999/1000\n",
      "174/174 [==============================] - 0s 988us/step - loss: 1.1315e-05 - val_loss: 3.5518e-05\n",
      "Epoch 1000/1000\n",
      "174/174 [==============================] - 0s 993us/step - loss: 1.1386e-05 - val_loss: 3.4285e-05\n",
      "y_preds_dnn_reg: (3713, 1)\n",
      "CPU times: user 6min 22s, sys: 57.4 s, total: 7min 20s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dnn_reg_synthetic = DnnReg(n_units=n_units, n_features=input_shape)\n",
    "\n",
    "y_preds_dnn_reg_synthetic = train_eval_dnn_reg(dnn_reg=dnn_reg_synthetic,\n",
    "                                          x_train=x_r_train_synthetic,\n",
    "                                          y_train=y_train_synthetic, \n",
    "                                          x_val=x_r_val_synthetic, \n",
    "                                          y_val=y_val_synthetic,\n",
    "                                          x_test=x_r_test_synthetic,\n",
    "                                          y_test=y_test_synthetic,\n",
    "                                          name='synthetic',\n",
    "                                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0459249</td>\n",
       "      <td>0.0269077</td>\n",
       "      <td>0.0587384</td>\n",
       "      <td>0.979433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE       MRAE       RMSE R^2-Score\n",
       "RF             NaN        NaN        NaN       NaN\n",
       "GBR-Ls         NaN        NaN        NaN       NaN\n",
       "DNN-Reg  0.0459249  0.0269077  0.0587384  0.979433"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_reg_synthetic = add_to_regression_comparison(df_reg_synthetic,\n",
    "                                           y_preds=y_preds_dnn_reg_synthetic,\n",
    "                                           y_trues=y_test_synthetic, \n",
    "                                           name='DNN-Reg',\n",
    "                                           data_name='synthetic')\n",
    "df_reg_synthetic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  20 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:   30.6s finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 16s, sys: 0 ns, total: 6min 16s\n",
      "Wall time: 30.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.0152971</td>\n",
       "      <td>0.00900766</td>\n",
       "      <td>0.0229524</td>\n",
       "      <td>0.697224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0459249</td>\n",
       "      <td>0.0269077</td>\n",
       "      <td>0.0587384</td>\n",
       "      <td>0.979433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF       0.0152971  0.00900766  0.0229524  0.697224\n",
       "GBR-Ls         NaN         NaN        NaN       NaN\n",
       "DNN-Reg  0.0459249   0.0269077  0.0587384  0.979433"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_preds_rf_synthetic = train_eval_rf(x_train=x_r_train_synthetic,\n",
    "                                y_train=y_train_synthetic, \n",
    "                                x_test=x_r_test_synthetic,\n",
    "                                y_test=y_test_synthetic,\n",
    "                                name='synthetic'\n",
    "                               )\n",
    "\n",
    "\n",
    "df_reg_synthetic = add_to_regression_comparison(df_reg_synthetic,\n",
    "                                           y_preds=y_preds_rf_synthetic,\n",
    "                                           y_trues=y_test_synthetic, \n",
    "                                           name='RF',\n",
    "                                           data_name='synthetic'\n",
    "                                          )\n",
    "df_reg_synthetic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0015            1.49m\n",
      "         2           0.0014            1.48m\n",
      "         3           0.0013            1.46m\n",
      "         4           0.0012            1.45m\n",
      "         5           0.0011            1.43m\n",
      "         6           0.0011            1.42m\n",
      "         7           0.0010            1.40m\n",
      "         8           0.0010            1.39m\n",
      "         9           0.0010            1.37m\n",
      "        10           0.0009            1.36m\n",
      "        20           0.0008            1.21m\n",
      "        30           0.0007            1.06m\n",
      "        40           0.0006           54.76s\n",
      "        50           0.0006           45.73s\n",
      "        60           0.0006           36.71s\n",
      "        70           0.0005           27.57s\n",
      "        80           0.0005           18.40s\n",
      "        90           0.0005            9.22s\n",
      "       100           0.0005            0.00s\n",
      "CPU times: user 1min 32s, sys: 0 ns, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.0152971</td>\n",
       "      <td>0.00900766</td>\n",
       "      <td>0.0229524</td>\n",
       "      <td>0.697224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.0104725</td>\n",
       "      <td>0.025361</td>\n",
       "      <td>0.630344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.0459249</td>\n",
       "      <td>0.0269077</td>\n",
       "      <td>0.0587384</td>\n",
       "      <td>0.979433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF       0.0152971  0.00900766  0.0229524  0.697224\n",
       "GBR-Ls    0.017798   0.0104725   0.025361  0.630344\n",
       "DNN-Reg  0.0459249   0.0269077  0.0587384  0.979433"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_gbr_synthetic = train_eval_gbr(x_train=x_r_train_synthetic,\n",
    "                              y_train=y_train_synthetic, \n",
    "                              x_test=x_r_test_synthetic,\n",
    "                              y_test=y_test_synthetic,\n",
    "                              name='synthetic',\n",
    "                             )\n",
    "\n",
    "\n",
    "df_reg_synthetic = add_to_regression_comparison(df_reg_synthetic,\n",
    "                                           y_preds=y_preds_gbr_synthetic,\n",
    "                                           y_trues=y_test_synthetic, \n",
    "                                           name='GBR-Ls',\n",
    "                                           data_name='synthetic'\n",
    "                                          )\n",
    "df_reg_synthetic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion over synthetic-only data:\n",
    "\n",
    "- All three algorithms obtained acceptable results w.r.t MAE, MRAE, RMSE.\n",
    "\n",
    "- Although all of these three also obtain acceptable r^2 score, however, DNN-Reg is the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2.4956 - val_loss: 1.2901\n",
      "Epoch 2/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 0.9009 - val_loss: 0.1873\n",
      "Epoch 3/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 0.1334 - val_loss: 0.0724\n",
      "Epoch 4/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 0.0638 - val_loss: 0.0480\n",
      "Epoch 5/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 0.0427 - val_loss: 0.0354\n",
      "Epoch 6/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 0.0321 - val_loss: 0.0271\n",
      "Epoch 7/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 0.0245 - val_loss: 0.0212\n",
      "Epoch 8/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 0.0196 - val_loss: 0.0169\n",
      "Epoch 9/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 0.0155 - val_loss: 0.0139\n",
      "Epoch 10/1000\n",
      "349/349 [==============================] - 0s 964us/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 11/1000\n",
      "349/349 [==============================] - 0s 952us/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 12/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 13/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 14/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 15/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 16/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 17/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 18/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 19/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 20/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 21/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 22/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 23/1000\n",
      "349/349 [==============================] - 0s 940us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 24/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 25/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 26/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 27/1000\n",
      "349/349 [==============================] - 0s 945us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 28/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 29/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 30/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 31/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 32/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 33/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 34/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 35/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 36/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 37/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 38/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 39/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 40/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 41/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 42/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 43/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 44/1000\n",
      "349/349 [==============================] - 0s 965us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 45/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 46/1000\n",
      "349/349 [==============================] - 0s 968us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 47/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 48/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 49/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 51/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 52/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 53/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 54/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 55/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 56/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 57/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 58/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 59/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 60/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 61/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 62/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 63/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 64/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 9.8460e-04 - val_loss: 0.0010\n",
      "Epoch 65/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 66/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 9.6681e-04 - val_loss: 9.9946e-04\n",
      "Epoch 67/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 9.7811e-04 - val_loss: 0.0010\n",
      "Epoch 68/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 9.5723e-04 - val_loss: 9.6744e-04\n",
      "Epoch 69/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 9.3636e-04 - val_loss: 9.6518e-04\n",
      "Epoch 70/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 9.3351e-04 - val_loss: 9.4613e-04\n",
      "Epoch 71/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 9.0111e-04 - val_loss: 9.3344e-04\n",
      "Epoch 72/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 8.8466e-04 - val_loss: 9.2508e-04\n",
      "Epoch 73/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 8.7427e-04 - val_loss: 9.1353e-04\n",
      "Epoch 74/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 8.8534e-04 - val_loss: 9.0799e-04\n",
      "Epoch 75/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 8.8611e-04 - val_loss: 9.3033e-04\n",
      "Epoch 76/1000\n",
      "349/349 [==============================] - 0s 893us/step - loss: 8.7665e-04 - val_loss: 8.8656e-04\n",
      "Epoch 77/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 8.4210e-04 - val_loss: 8.8902e-04\n",
      "Epoch 78/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 8.2043e-04 - val_loss: 8.9034e-04\n",
      "Epoch 79/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 8.5753e-04 - val_loss: 8.7510e-04\n",
      "Epoch 80/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 8.5285e-04 - val_loss: 8.6357e-04\n",
      "Epoch 81/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 8.0238e-04 - val_loss: 8.4781e-04\n",
      "Epoch 82/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 8.3209e-04 - val_loss: 8.3839e-04\n",
      "Epoch 83/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 7.8341e-04 - val_loss: 8.3710e-04\n",
      "Epoch 84/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 7.8620e-04 - val_loss: 8.6229e-04\n",
      "Epoch 85/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 8.2521e-04 - val_loss: 8.1963e-04\n",
      "Epoch 86/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 7.7550e-04 - val_loss: 8.1385e-04\n",
      "Epoch 87/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 7.8509e-04 - val_loss: 8.4328e-04\n",
      "Epoch 88/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 7.6459e-04 - val_loss: 8.0930e-04\n",
      "Epoch 89/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 7.7285e-04 - val_loss: 8.2857e-04\n",
      "Epoch 90/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 7.8334e-04 - val_loss: 7.9151e-04\n",
      "Epoch 91/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 7.5340e-04 - val_loss: 7.8645e-04\n",
      "Epoch 92/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 7.4710e-04 - val_loss: 7.9623e-04\n",
      "Epoch 93/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 7.4751e-04 - val_loss: 8.0864e-04\n",
      "Epoch 94/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 7.3834e-04 - val_loss: 7.8095e-04\n",
      "Epoch 95/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 7.2966e-04 - val_loss: 7.6755e-04\n",
      "Epoch 96/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 7.2784e-04 - val_loss: 7.6060e-04\n",
      "Epoch 97/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 7.2462e-04 - val_loss: 7.6114e-04\n",
      "Epoch 98/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 7.0914e-04 - val_loss: 7.6605e-04\n",
      "Epoch 99/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 6.8674e-04 - val_loss: 7.5354e-04\n",
      "Epoch 100/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 6.9795e-04 - val_loss: 7.4415e-04\n",
      "Epoch 101/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 7.0800e-04 - val_loss: 7.4310e-04\n",
      "Epoch 102/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 6.9069e-04 - val_loss: 7.3881e-04\n",
      "Epoch 103/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 6.8767e-04 - val_loss: 7.5000e-04\n",
      "Epoch 104/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 6.8804e-04 - val_loss: 7.3280e-04\n",
      "Epoch 105/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 6.6801e-04 - val_loss: 7.2219e-04\n",
      "Epoch 106/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 6.7911e-04 - val_loss: 7.3292e-04\n",
      "Epoch 107/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 6.5447e-04 - val_loss: 7.1538e-04\n",
      "Epoch 108/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 6.5950e-04 - val_loss: 7.2107e-04\n",
      "Epoch 109/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 6.7125e-04 - val_loss: 7.2435e-04\n",
      "Epoch 110/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 6.7269e-04 - val_loss: 7.0687e-04\n",
      "Epoch 111/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 6.6214e-04 - val_loss: 7.2099e-04\n",
      "Epoch 112/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 6.5694e-04 - val_loss: 6.9995e-04\n",
      "Epoch 113/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 6.5144e-04 - val_loss: 7.0568e-04\n",
      "Epoch 114/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 6.3924e-04 - val_loss: 7.0668e-04\n",
      "Epoch 115/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 6.5883e-04 - val_loss: 6.9701e-04\n",
      "Epoch 116/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 6.2414e-04 - val_loss: 7.2401e-04\n",
      "Epoch 117/1000\n",
      "349/349 [==============================] - 0s 956us/step - loss: 6.4378e-04 - val_loss: 6.8878e-04\n",
      "Epoch 118/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 6.2457e-04 - val_loss: 6.8865e-04\n",
      "Epoch 119/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 6.3290e-04 - val_loss: 6.7804e-04\n",
      "Epoch 120/1000\n",
      "349/349 [==============================] - 0s 899us/step - loss: 6.2409e-04 - val_loss: 6.7935e-04\n",
      "Epoch 121/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 6.0971e-04 - val_loss: 6.7352e-04\n",
      "Epoch 122/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 6.0038e-04 - val_loss: 6.7546e-04\n",
      "Epoch 123/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 6.0915e-04 - val_loss: 6.6761e-04\n",
      "Epoch 124/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 6.1034e-04 - val_loss: 6.9033e-04\n",
      "Epoch 125/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 6.0238e-04 - val_loss: 6.6335e-04\n",
      "Epoch 126/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 6.1885e-04 - val_loss: 6.6967e-04\n",
      "Epoch 127/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 6.0031e-04 - val_loss: 6.6135e-04\n",
      "Epoch 128/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 5.9355e-04 - val_loss: 6.5907e-04\n",
      "Epoch 129/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 6.0173e-04 - val_loss: 6.7706e-04\n",
      "Epoch 130/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 6.1602e-04 - val_loss: 6.5764e-04\n",
      "Epoch 131/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 6.0682e-04 - val_loss: 6.5182e-04\n",
      "Epoch 132/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 5.8828e-04 - val_loss: 6.5403e-04\n",
      "Epoch 133/1000\n",
      "349/349 [==============================] - 0s 940us/step - loss: 5.7840e-04 - val_loss: 6.5278e-04\n",
      "Epoch 134/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 5.8714e-04 - val_loss: 6.4741e-04\n",
      "Epoch 135/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 5.8164e-04 - val_loss: 6.4733e-04\n",
      "Epoch 136/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 5.7146e-04 - val_loss: 6.6166e-04\n",
      "Epoch 137/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 5.8776e-04 - val_loss: 6.4424e-04\n",
      "Epoch 138/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 5.7529e-04 - val_loss: 6.5827e-04\n",
      "Epoch 139/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 5.7399e-04 - val_loss: 6.4067e-04\n",
      "Epoch 140/1000\n",
      "349/349 [==============================] - 0s 962us/step - loss: 5.7447e-04 - val_loss: 6.2967e-04\n",
      "Epoch 141/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 5.6970e-04 - val_loss: 6.3463e-04\n",
      "Epoch 142/1000\n",
      "349/349 [==============================] - 0s 963us/step - loss: 5.7801e-04 - val_loss: 6.3119e-04\n",
      "Epoch 143/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 5.5751e-04 - val_loss: 6.3650e-04\n",
      "Epoch 144/1000\n",
      "349/349 [==============================] - 0s 899us/step - loss: 5.7579e-04 - val_loss: 6.2285e-04\n",
      "Epoch 145/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 5.5070e-04 - val_loss: 6.2338e-04\n",
      "Epoch 146/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 5.7454e-04 - val_loss: 6.1855e-04\n",
      "Epoch 147/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 5.5977e-04 - val_loss: 6.2201e-04\n",
      "Epoch 148/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 5.6663e-04 - val_loss: 6.3955e-04\n",
      "Epoch 149/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 5.3198e-04 - val_loss: 6.1508e-04\n",
      "Epoch 150/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 5.4249e-04 - val_loss: 6.3591e-04\n",
      "Epoch 151/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 5.9800e-04 - val_loss: 6.2195e-04\n",
      "Epoch 152/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 5.5621e-04 - val_loss: 6.1623e-04\n",
      "Epoch 153/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 5.5101e-04 - val_loss: 6.1397e-04\n",
      "Epoch 154/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 5.4492e-04 - val_loss: 6.2395e-04\n",
      "Epoch 155/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 5.5399e-04 - val_loss: 6.1081e-04\n",
      "Epoch 156/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 5.4816e-04 - val_loss: 6.1405e-04\n",
      "Epoch 157/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 5.4833e-04 - val_loss: 6.1256e-04\n",
      "Epoch 158/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 5.5257e-04 - val_loss: 6.0998e-04\n",
      "Epoch 159/1000\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5.3701e-04 - val_loss: 6.1543e-04\n",
      "Epoch 160/1000\n",
      "349/349 [==============================] - 0s 956us/step - loss: 5.3411e-04 - val_loss: 6.0337e-04\n",
      "Epoch 161/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 5.1781e-04 - val_loss: 6.1354e-04\n",
      "Epoch 162/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 5.4797e-04 - val_loss: 5.9839e-04\n",
      "Epoch 163/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 5.2970e-04 - val_loss: 6.0228e-04\n",
      "Epoch 164/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 5.2427e-04 - val_loss: 5.9682e-04\n",
      "Epoch 165/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 5.5098e-04 - val_loss: 6.0063e-04\n",
      "Epoch 166/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 5.2030e-04 - val_loss: 5.8935e-04\n",
      "Epoch 167/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 5.2221e-04 - val_loss: 5.9003e-04\n",
      "Epoch 168/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 5.1687e-04 - val_loss: 5.9186e-04\n",
      "Epoch 169/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 5.2080e-04 - val_loss: 5.9565e-04\n",
      "Epoch 170/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 5.1911e-04 - val_loss: 5.9149e-04\n",
      "Epoch 171/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 5.1144e-04 - val_loss: 5.8433e-04\n",
      "Epoch 172/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 5.1850e-04 - val_loss: 5.9211e-04\n",
      "Epoch 173/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 5.0447e-04 - val_loss: 6.0077e-04\n",
      "Epoch 174/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 5.1574e-04 - val_loss: 5.8542e-04\n",
      "Epoch 175/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 5.2020e-04 - val_loss: 5.8226e-04\n",
      "Epoch 176/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 5.1746e-04 - val_loss: 5.8420e-04\n",
      "Epoch 177/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 5.1070e-04 - val_loss: 5.7672e-04\n",
      "Epoch 178/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 5.0666e-04 - val_loss: 5.8573e-04\n",
      "Epoch 179/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 5.1373e-04 - val_loss: 5.9153e-04\n",
      "Epoch 180/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 5.1803e-04 - val_loss: 5.7133e-04\n",
      "Epoch 181/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 5.2304e-04 - val_loss: 5.8548e-04\n",
      "Epoch 182/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 5.3661e-04 - val_loss: 5.7875e-04\n",
      "Epoch 183/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 5.1690e-04 - val_loss: 5.7348e-04\n",
      "Epoch 184/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 4.9262e-04 - val_loss: 5.8027e-04\n",
      "Epoch 185/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 4.9483e-04 - val_loss: 5.7181e-04\n",
      "Epoch 186/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 4.8711e-04 - val_loss: 5.7157e-04\n",
      "Epoch 187/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.8293e-04 - val_loss: 5.7390e-04\n",
      "Epoch 188/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 4.7945e-04 - val_loss: 5.7799e-04\n",
      "Epoch 189/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 4.8820e-04 - val_loss: 5.7160e-04\n",
      "Epoch 190/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.8168e-04 - val_loss: 5.6650e-04\n",
      "Epoch 191/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 5.0699e-04 - val_loss: 5.6278e-04\n",
      "Epoch 192/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 4.8881e-04 - val_loss: 5.7251e-04\n",
      "Epoch 193/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 4.8435e-04 - val_loss: 5.6352e-04\n",
      "Epoch 194/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.8167e-04 - val_loss: 5.6279e-04\n",
      "Epoch 195/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 4.9721e-04 - val_loss: 5.6428e-04\n",
      "Epoch 196/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 4.8825e-04 - val_loss: 5.7326e-04\n",
      "Epoch 197/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 4.8021e-04 - val_loss: 5.5824e-04\n",
      "Epoch 198/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 5.0223e-04 - val_loss: 5.6797e-04\n",
      "Epoch 199/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 4.7507e-04 - val_loss: 5.6433e-04\n",
      "Epoch 200/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 4.6244e-04 - val_loss: 5.6797e-04\n",
      "Epoch 201/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 4.7264e-04 - val_loss: 5.6064e-04\n",
      "Epoch 202/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 4.8637e-04 - val_loss: 5.5241e-04\n",
      "Epoch 203/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 4.6629e-04 - val_loss: 5.5487e-04\n",
      "Epoch 204/1000\n",
      "349/349 [==============================] - 0s 899us/step - loss: 4.9071e-04 - val_loss: 6.0254e-04\n",
      "Epoch 205/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 4.8438e-04 - val_loss: 5.5167e-04\n",
      "Epoch 206/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 4.8083e-04 - val_loss: 5.4773e-04\n",
      "Epoch 207/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 4.7229e-04 - val_loss: 5.5151e-04\n",
      "Epoch 208/1000\n",
      "349/349 [==============================] - 0s 961us/step - loss: 4.7203e-04 - val_loss: 5.4719e-04\n",
      "Epoch 209/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.6215e-04 - val_loss: 5.5390e-04\n",
      "Epoch 210/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.6226e-04 - val_loss: 5.6179e-04\n",
      "Epoch 211/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 4.7617e-04 - val_loss: 5.5089e-04\n",
      "Epoch 212/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 4.8220e-04 - val_loss: 5.4973e-04\n",
      "Epoch 213/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 4.5254e-04 - val_loss: 5.4571e-04\n",
      "Epoch 214/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.7960e-04 - val_loss: 5.8567e-04\n",
      "Epoch 215/1000\n",
      "349/349 [==============================] - 0s 959us/step - loss: 5.0214e-04 - val_loss: 5.4673e-04\n",
      "Epoch 216/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 4.6633e-04 - val_loss: 5.4058e-04\n",
      "Epoch 217/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 4.6478e-04 - val_loss: 5.3810e-04\n",
      "Epoch 218/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 4.7030e-04 - val_loss: 5.3840e-04\n",
      "Epoch 219/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 4.4024e-04 - val_loss: 5.3977e-04\n",
      "Epoch 220/1000\n",
      "349/349 [==============================] - 0s 993us/step - loss: 4.5159e-04 - val_loss: 5.4776e-04\n",
      "Epoch 221/1000\n",
      "349/349 [==============================] - 0s 947us/step - loss: 4.4383e-04 - val_loss: 5.4163e-04\n",
      "Epoch 222/1000\n",
      "349/349 [==============================] - 0s 946us/step - loss: 4.6314e-04 - val_loss: 5.4139e-04\n",
      "Epoch 223/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 4.6948e-04 - val_loss: 5.3882e-04\n",
      "Epoch 224/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 4.4384e-04 - val_loss: 5.4040e-04\n",
      "Epoch 225/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 4.4770e-04 - val_loss: 5.3774e-04\n",
      "Epoch 226/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 4.4383e-04 - val_loss: 5.3617e-04\n",
      "Epoch 227/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 4.4156e-04 - val_loss: 5.4011e-04\n",
      "Epoch 228/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.5892e-04 - val_loss: 5.3553e-04\n",
      "Epoch 229/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 4.3249e-04 - val_loss: 5.3708e-04\n",
      "Epoch 230/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 4.4871e-04 - val_loss: 5.4140e-04\n",
      "Epoch 231/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 4.5704e-04 - val_loss: 5.7125e-04\n",
      "Epoch 232/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 4.6586e-04 - val_loss: 5.3169e-04\n",
      "Epoch 233/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 4.5803e-04 - val_loss: 5.3291e-04\n",
      "Epoch 234/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 4.5755e-04 - val_loss: 5.3750e-04\n",
      "Epoch 235/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 4.5566e-04 - val_loss: 5.4644e-04\n",
      "Epoch 236/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 4.9121e-04 - val_loss: 5.3388e-04\n",
      "Epoch 237/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 4.4859e-04 - val_loss: 5.2817e-04\n",
      "Epoch 238/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 4.3341e-04 - val_loss: 5.3959e-04\n",
      "Epoch 239/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.4146e-04 - val_loss: 5.2525e-04\n",
      "Epoch 240/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.3891e-04 - val_loss: 5.2862e-04\n",
      "Epoch 241/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.4978e-04 - val_loss: 5.2464e-04\n",
      "Epoch 242/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.3642e-04 - val_loss: 5.2820e-04\n",
      "Epoch 243/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 4.3368e-04 - val_loss: 5.2420e-04\n",
      "Epoch 244/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 4.2846e-04 - val_loss: 5.2361e-04\n",
      "Epoch 245/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 4.3336e-04 - val_loss: 5.2748e-04\n",
      "Epoch 246/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.4051e-04 - val_loss: 5.2690e-04\n",
      "Epoch 247/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 4.3036e-04 - val_loss: 5.1743e-04\n",
      "Epoch 248/1000\n",
      "349/349 [==============================] - 0s 953us/step - loss: 4.3569e-04 - val_loss: 5.4010e-04\n",
      "Epoch 249/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 4.4567e-04 - val_loss: 5.3614e-04\n",
      "Epoch 250/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 4.3711e-04 - val_loss: 5.1799e-04\n",
      "Epoch 251/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.3134e-04 - val_loss: 5.8499e-04\n",
      "Epoch 252/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 4.6065e-04 - val_loss: 5.2051e-04\n",
      "Epoch 253/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 4.4110e-04 - val_loss: 5.1590e-04\n",
      "Epoch 254/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 4.3023e-04 - val_loss: 5.1728e-04\n",
      "Epoch 255/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 4.2666e-04 - val_loss: 5.5975e-04\n",
      "Epoch 256/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 4.6691e-04 - val_loss: 5.1713e-04\n",
      "Epoch 257/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.3382e-04 - val_loss: 5.1390e-04\n",
      "Epoch 258/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 4.2430e-04 - val_loss: 5.2647e-04\n",
      "Epoch 259/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.3217e-04 - val_loss: 5.1105e-04\n",
      "Epoch 260/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 4.1404e-04 - val_loss: 5.0969e-04\n",
      "Epoch 261/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.3229e-04 - val_loss: 5.1578e-04\n",
      "Epoch 262/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 4.0806e-04 - val_loss: 5.4583e-04\n",
      "Epoch 263/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 4.3177e-04 - val_loss: 5.1025e-04\n",
      "Epoch 264/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 4.2823e-04 - val_loss: 5.4843e-04\n",
      "Epoch 265/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.6835e-04 - val_loss: 5.1017e-04\n",
      "Epoch 266/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 4.1020e-04 - val_loss: 5.1028e-04\n",
      "Epoch 267/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 4.0954e-04 - val_loss: 5.3014e-04\n",
      "Epoch 268/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 4.2546e-04 - val_loss: 5.2469e-04\n",
      "Epoch 269/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 4.1180e-04 - val_loss: 5.1655e-04\n",
      "Epoch 270/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 4.2083e-04 - val_loss: 5.0781e-04\n",
      "Epoch 271/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 4.2217e-04 - val_loss: 5.0575e-04\n",
      "Epoch 272/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 4.1306e-04 - val_loss: 5.2336e-04\n",
      "Epoch 273/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.1643e-04 - val_loss: 5.0935e-04\n",
      "Epoch 274/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 4.2619e-04 - val_loss: 5.2391e-04\n",
      "Epoch 275/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 4.1138e-04 - val_loss: 5.1016e-04\n",
      "Epoch 276/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 4.2141e-04 - val_loss: 5.1363e-04\n",
      "Epoch 277/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 4.2290e-04 - val_loss: 5.1470e-04\n",
      "Epoch 278/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 4.1720e-04 - val_loss: 5.0840e-04\n",
      "Epoch 279/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 4.0772e-04 - val_loss: 5.0107e-04\n",
      "Epoch 280/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 4.1645e-04 - val_loss: 5.0329e-04\n",
      "Epoch 281/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 4.1984e-04 - val_loss: 5.3069e-04\n",
      "Epoch 282/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.2488e-04 - val_loss: 4.9893e-04\n",
      "Epoch 283/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.1021e-04 - val_loss: 5.0567e-04\n",
      "Epoch 284/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 4.1097e-04 - val_loss: 5.2074e-04\n",
      "Epoch 285/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.9552e-04 - val_loss: 5.0175e-04\n",
      "Epoch 286/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 4.0013e-04 - val_loss: 5.0719e-04\n",
      "Epoch 287/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 4.0763e-04 - val_loss: 5.1580e-04\n",
      "Epoch 288/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 4.0411e-04 - val_loss: 4.9904e-04\n",
      "Epoch 289/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 4.0383e-04 - val_loss: 5.1038e-04\n",
      "Epoch 290/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 4.0537e-04 - val_loss: 5.0278e-04\n",
      "Epoch 291/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 4.0267e-04 - val_loss: 4.9584e-04\n",
      "Epoch 292/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.1718e-04 - val_loss: 5.0790e-04\n",
      "Epoch 293/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 4.0411e-04 - val_loss: 4.9408e-04\n",
      "Epoch 294/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 4.1074e-04 - val_loss: 4.9768e-04\n",
      "Epoch 295/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 4.0875e-04 - val_loss: 5.1442e-04\n",
      "Epoch 296/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 4.1074e-04 - val_loss: 4.9989e-04\n",
      "Epoch 297/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 3.9664e-04 - val_loss: 5.2737e-04\n",
      "Epoch 298/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 4.2126e-04 - val_loss: 5.3652e-04\n",
      "Epoch 299/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 4.2249e-04 - val_loss: 4.9313e-04\n",
      "Epoch 300/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 4.0113e-04 - val_loss: 4.9577e-04\n",
      "Epoch 301/1000\n",
      "349/349 [==============================] - 0s 953us/step - loss: 3.9719e-04 - val_loss: 5.0875e-04\n",
      "Epoch 302/1000\n",
      "349/349 [==============================] - 0s 947us/step - loss: 3.9973e-04 - val_loss: 4.9012e-04\n",
      "Epoch 303/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 3.9647e-04 - val_loss: 4.9790e-04\n",
      "Epoch 304/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.9368e-04 - val_loss: 4.9628e-04\n",
      "Epoch 305/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.8841e-04 - val_loss: 4.9385e-04\n",
      "Epoch 306/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 4.0042e-04 - val_loss: 5.0783e-04\n",
      "Epoch 307/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 4.1740e-04 - val_loss: 4.8887e-04\n",
      "Epoch 308/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.8526e-04 - val_loss: 4.9143e-04\n",
      "Epoch 309/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.8733e-04 - val_loss: 4.8918e-04\n",
      "Epoch 310/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 3.8212e-04 - val_loss: 5.0146e-04\n",
      "Epoch 311/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.9045e-04 - val_loss: 5.0347e-04\n",
      "Epoch 312/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 3.9175e-04 - val_loss: 4.8980e-04\n",
      "Epoch 313/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.8216e-04 - val_loss: 5.0155e-04\n",
      "Epoch 314/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.8923e-04 - val_loss: 4.9075e-04\n",
      "Epoch 315/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.8588e-04 - val_loss: 4.9070e-04\n",
      "Epoch 316/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 3.8378e-04 - val_loss: 4.8634e-04\n",
      "Epoch 317/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.8553e-04 - val_loss: 4.8789e-04\n",
      "Epoch 318/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.8487e-04 - val_loss: 4.8957e-04\n",
      "Epoch 319/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 3.9591e-04 - val_loss: 4.9667e-04\n",
      "Epoch 320/1000\n",
      "349/349 [==============================] - 0s 957us/step - loss: 3.9011e-04 - val_loss: 5.1424e-04\n",
      "Epoch 321/1000\n",
      "349/349 [==============================] - 0s 958us/step - loss: 3.9832e-04 - val_loss: 4.9340e-04\n",
      "Epoch 322/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 3.9842e-04 - val_loss: 4.9434e-04\n",
      "Epoch 323/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.9611e-04 - val_loss: 4.8927e-04\n",
      "Epoch 324/1000\n",
      "349/349 [==============================] - 0s 898us/step - loss: 3.9078e-04 - val_loss: 4.8338e-04\n",
      "Epoch 325/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.9965e-04 - val_loss: 4.9450e-04\n",
      "Epoch 326/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.9186e-04 - val_loss: 5.0566e-04\n",
      "Epoch 327/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.8157e-04 - val_loss: 4.8943e-04\n",
      "Epoch 328/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 3.7648e-04 - val_loss: 4.8431e-04\n",
      "Epoch 329/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.7946e-04 - val_loss: 4.8216e-04\n",
      "Epoch 330/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.8882e-04 - val_loss: 4.8844e-04\n",
      "Epoch 331/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.9638e-04 - val_loss: 4.8057e-04\n",
      "Epoch 332/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.8061e-04 - val_loss: 4.8582e-04\n",
      "Epoch 333/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.6890e-04 - val_loss: 4.8029e-04\n",
      "Epoch 334/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.8366e-04 - val_loss: 4.8160e-04\n",
      "Epoch 335/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 3.6249e-04 - val_loss: 4.8329e-04\n",
      "Epoch 336/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 3.6768e-04 - val_loss: 4.7845e-04\n",
      "Epoch 337/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.7052e-04 - val_loss: 4.7892e-04\n",
      "Epoch 338/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 3.7542e-04 - val_loss: 4.9628e-04\n",
      "Epoch 339/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 3.7575e-04 - val_loss: 4.8418e-04\n",
      "Epoch 340/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.8016e-04 - val_loss: 4.8414e-04\n",
      "Epoch 341/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.7069e-04 - val_loss: 4.9682e-04\n",
      "Epoch 342/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.8308e-04 - val_loss: 4.8404e-04\n",
      "Epoch 343/1000\n",
      "349/349 [==============================] - 0s 902us/step - loss: 3.9266e-04 - val_loss: 4.9133e-04\n",
      "Epoch 344/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.7466e-04 - val_loss: 4.8092e-04\n",
      "Epoch 345/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.7235e-04 - val_loss: 4.9166e-04\n",
      "Epoch 346/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.6545e-04 - val_loss: 4.7820e-04\n",
      "Epoch 347/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.7017e-04 - val_loss: 4.7893e-04\n",
      "Epoch 348/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.5885e-04 - val_loss: 4.8133e-04\n",
      "Epoch 349/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.6895e-04 - val_loss: 4.7548e-04\n",
      "Epoch 350/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.6548e-04 - val_loss: 4.7584e-04\n",
      "Epoch 351/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 3.7367e-04 - val_loss: 4.7788e-04\n",
      "Epoch 352/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 3.6706e-04 - val_loss: 4.7246e-04\n",
      "Epoch 353/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.7173e-04 - val_loss: 4.7218e-04\n",
      "Epoch 354/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 3.6413e-04 - val_loss: 4.7301e-04\n",
      "Epoch 355/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 3.7155e-04 - val_loss: 4.8758e-04\n",
      "Epoch 356/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 3.6464e-04 - val_loss: 4.7932e-04\n",
      "Epoch 357/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 3.6311e-04 - val_loss: 4.8119e-04\n",
      "Epoch 358/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 3.8901e-04 - val_loss: 4.7178e-04\n",
      "Epoch 359/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 3.7069e-04 - val_loss: 4.7878e-04\n",
      "Epoch 360/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.6266e-04 - val_loss: 4.7520e-04\n",
      "Epoch 361/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.6501e-04 - val_loss: 4.9136e-04\n",
      "Epoch 362/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.6158e-04 - val_loss: 4.8050e-04\n",
      "Epoch 363/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.7125e-04 - val_loss: 4.8299e-04\n",
      "Epoch 364/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.7094e-04 - val_loss: 4.7377e-04\n",
      "Epoch 365/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.6383e-04 - val_loss: 4.7173e-04\n",
      "Epoch 366/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.7361e-04 - val_loss: 4.7145e-04\n",
      "Epoch 367/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.6317e-04 - val_loss: 4.7513e-04\n",
      "Epoch 368/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.5163e-04 - val_loss: 4.6975e-04\n",
      "Epoch 369/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 3.5978e-04 - val_loss: 4.7664e-04\n",
      "Epoch 370/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 3.5244e-04 - val_loss: 4.7338e-04\n",
      "Epoch 371/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 3.6655e-04 - val_loss: 4.7420e-04\n",
      "Epoch 372/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 3.5703e-04 - val_loss: 4.6720e-04\n",
      "Epoch 373/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.5818e-04 - val_loss: 4.7250e-04\n",
      "Epoch 374/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.4821e-04 - val_loss: 4.6813e-04\n",
      "Epoch 375/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 3.4480e-04 - val_loss: 4.9236e-04\n",
      "Epoch 376/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 3.7339e-04 - val_loss: 4.8602e-04\n",
      "Epoch 377/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 3.4854e-04 - val_loss: 5.0313e-04\n",
      "Epoch 378/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 3.6290e-04 - val_loss: 4.8621e-04\n",
      "Epoch 379/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.5851e-04 - val_loss: 4.6901e-04\n",
      "Epoch 380/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 3.6026e-04 - val_loss: 4.6878e-04\n",
      "Epoch 381/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.6734e-04 - val_loss: 4.7051e-04\n",
      "Epoch 382/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 3.4369e-04 - val_loss: 4.7470e-04\n",
      "Epoch 383/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.5871e-04 - val_loss: 4.7850e-04\n",
      "Epoch 384/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.4517e-04 - val_loss: 5.0794e-04\n",
      "Epoch 385/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 3.9555e-04 - val_loss: 4.6812e-04\n",
      "Epoch 386/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 3.4907e-04 - val_loss: 4.7258e-04\n",
      "Epoch 387/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.5701e-04 - val_loss: 4.7385e-04\n",
      "Epoch 388/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 3.4859e-04 - val_loss: 4.6895e-04\n",
      "Epoch 389/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.6594e-04 - val_loss: 4.7577e-04\n",
      "Epoch 390/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.5043e-04 - val_loss: 4.6654e-04\n",
      "Epoch 391/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 3.4782e-04 - val_loss: 4.7234e-04\n",
      "Epoch 392/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 3.4666e-04 - val_loss: 4.6392e-04\n",
      "Epoch 393/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.3599e-04 - val_loss: 4.7633e-04\n",
      "Epoch 394/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 3.4491e-04 - val_loss: 4.6795e-04\n",
      "Epoch 395/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.5012e-04 - val_loss: 4.7930e-04\n",
      "Epoch 396/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.6148e-04 - val_loss: 4.6795e-04\n",
      "Epoch 397/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 3.5292e-04 - val_loss: 4.6115e-04\n",
      "Epoch 398/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.4212e-04 - val_loss: 4.7421e-04\n",
      "Epoch 399/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.5099e-04 - val_loss: 4.6022e-04\n",
      "Epoch 400/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.4545e-04 - val_loss: 4.6207e-04\n",
      "Epoch 401/1000\n",
      "349/349 [==============================] - 0s 946us/step - loss: 3.3431e-04 - val_loss: 4.8048e-04\n",
      "Epoch 402/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 3.5661e-04 - val_loss: 4.6363e-04\n",
      "Epoch 403/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 3.4197e-04 - val_loss: 4.6440e-04\n",
      "Epoch 404/1000\n",
      "349/349 [==============================] - 0s 898us/step - loss: 3.4164e-04 - val_loss: 4.5951e-04\n",
      "Epoch 405/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 3.4163e-04 - val_loss: 4.6485e-04\n",
      "Epoch 406/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 3.5684e-04 - val_loss: 4.6086e-04\n",
      "Epoch 407/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 3.4050e-04 - val_loss: 4.6636e-04\n",
      "Epoch 408/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.4860e-04 - val_loss: 4.5786e-04\n",
      "Epoch 409/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.5503e-04 - val_loss: 4.6210e-04\n",
      "Epoch 410/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.5938e-04 - val_loss: 4.7104e-04\n",
      "Epoch 411/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 3.4665e-04 - val_loss: 4.7343e-04\n",
      "Epoch 412/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.4787e-04 - val_loss: 4.5755e-04\n",
      "Epoch 413/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 3.6478e-04 - val_loss: 4.5611e-04\n",
      "Epoch 414/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.5856e-04 - val_loss: 4.6480e-04\n",
      "Epoch 415/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 3.4580e-04 - val_loss: 4.5818e-04\n",
      "Epoch 416/1000\n",
      "349/349 [==============================] - 0s 893us/step - loss: 3.4146e-04 - val_loss: 4.6507e-04\n",
      "Epoch 417/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 3.3487e-04 - val_loss: 4.5453e-04\n",
      "Epoch 418/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 3.3981e-04 - val_loss: 4.5640e-04\n",
      "Epoch 419/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.3712e-04 - val_loss: 4.5837e-04\n",
      "Epoch 420/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 3.2651e-04 - val_loss: 4.6886e-04\n",
      "Epoch 421/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.4145e-04 - val_loss: 4.6369e-04\n",
      "Epoch 422/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 3.4411e-04 - val_loss: 4.5894e-04\n",
      "Epoch 423/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 3.3309e-04 - val_loss: 4.5758e-04\n",
      "Epoch 424/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 3.4240e-04 - val_loss: 4.5862e-04\n",
      "Epoch 425/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.2698e-04 - val_loss: 4.7280e-04\n",
      "Epoch 426/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.3657e-04 - val_loss: 4.5927e-04\n",
      "Epoch 427/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.4138e-04 - val_loss: 4.6142e-04\n",
      "Epoch 428/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 3.3807e-04 - val_loss: 4.5823e-04\n",
      "Epoch 429/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.2887e-04 - val_loss: 4.5305e-04\n",
      "Epoch 430/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 3.3187e-04 - val_loss: 4.5762e-04\n",
      "Epoch 431/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 3.3119e-04 - val_loss: 4.5436e-04\n",
      "Epoch 432/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 3.3624e-04 - val_loss: 4.5338e-04\n",
      "Epoch 433/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 3.2777e-04 - val_loss: 4.6700e-04\n",
      "Epoch 434/1000\n",
      "349/349 [==============================] - 0s 957us/step - loss: 3.3518e-04 - val_loss: 4.5501e-04\n",
      "Epoch 435/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 3.3878e-04 - val_loss: 4.5424e-04\n",
      "Epoch 436/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 3.3465e-04 - val_loss: 4.6763e-04\n",
      "Epoch 437/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 3.3466e-04 - val_loss: 4.4952e-04\n",
      "Epoch 438/1000\n",
      "349/349 [==============================] - 0s 947us/step - loss: 3.3220e-04 - val_loss: 4.5372e-04\n",
      "Epoch 439/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 3.2549e-04 - val_loss: 4.6410e-04\n",
      "Epoch 440/1000\n",
      "349/349 [==============================] - 0s 952us/step - loss: 3.3252e-04 - val_loss: 4.6151e-04\n",
      "Epoch 441/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 3.2396e-04 - val_loss: 4.5983e-04\n",
      "Epoch 442/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 3.3156e-04 - val_loss: 4.4712e-04\n",
      "Epoch 443/1000\n",
      "349/349 [==============================] - 0s 980us/step - loss: 3.1282e-04 - val_loss: 4.4970e-04\n",
      "Epoch 444/1000\n",
      "349/349 [==============================] - 0s 970us/step - loss: 3.2123e-04 - val_loss: 4.5964e-04\n",
      "Epoch 445/1000\n",
      "349/349 [==============================] - 0s 970us/step - loss: 3.4016e-04 - val_loss: 4.4831e-04\n",
      "Epoch 446/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 3.3031e-04 - val_loss: 4.5515e-04\n",
      "Epoch 447/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 3.1287e-04 - val_loss: 4.5396e-04\n",
      "Epoch 448/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 3.3873e-04 - val_loss: 4.5833e-04\n",
      "Epoch 449/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 3.3140e-04 - val_loss: 5.0233e-04\n",
      "Epoch 450/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.5047e-04 - val_loss: 4.5984e-04\n",
      "Epoch 451/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 3.2594e-04 - val_loss: 4.5729e-04\n",
      "Epoch 452/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 3.2731e-04 - val_loss: 4.4801e-04\n",
      "Epoch 453/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 3.2623e-04 - val_loss: 4.5660e-04\n",
      "Epoch 454/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 3.2416e-04 - val_loss: 4.5551e-04\n",
      "Epoch 455/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 3.1936e-04 - val_loss: 4.4634e-04\n",
      "Epoch 456/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.3159e-04 - val_loss: 4.4862e-04\n",
      "Epoch 457/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 3.1520e-04 - val_loss: 4.4440e-04\n",
      "Epoch 458/1000\n",
      "349/349 [==============================] - 0s 943us/step - loss: 3.2712e-04 - val_loss: 4.4652e-04\n",
      "Epoch 459/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 3.2214e-04 - val_loss: 4.5075e-04\n",
      "Epoch 460/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.3082e-04 - val_loss: 4.4407e-04\n",
      "Epoch 461/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 3.1820e-04 - val_loss: 4.5022e-04\n",
      "Epoch 462/1000\n",
      "349/349 [==============================] - 0s 946us/step - loss: 3.2140e-04 - val_loss: 4.9472e-04\n",
      "Epoch 463/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 3.3256e-04 - val_loss: 4.4464e-04\n",
      "Epoch 464/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 3.2456e-04 - val_loss: 4.5555e-04\n",
      "Epoch 465/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.1592e-04 - val_loss: 4.4573e-04\n",
      "Epoch 466/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 3.1637e-04 - val_loss: 4.5481e-04\n",
      "Epoch 467/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.0966e-04 - val_loss: 4.4296e-04\n",
      "Epoch 468/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 3.1305e-04 - val_loss: 4.5328e-04\n",
      "Epoch 469/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 3.3233e-04 - val_loss: 4.6468e-04\n",
      "Epoch 470/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 3.1581e-04 - val_loss: 4.6277e-04\n",
      "Epoch 471/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 3.2776e-04 - val_loss: 4.6328e-04\n",
      "Epoch 472/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.2650e-04 - val_loss: 4.4206e-04\n",
      "Epoch 473/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 3.1478e-04 - val_loss: 4.5467e-04\n",
      "Epoch 474/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 3.2531e-04 - val_loss: 4.4278e-04\n",
      "Epoch 475/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.1198e-04 - val_loss: 4.6106e-04\n",
      "Epoch 476/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.2519e-04 - val_loss: 4.4197e-04\n",
      "Epoch 477/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.0837e-04 - val_loss: 4.4343e-04\n",
      "Epoch 478/1000\n",
      "349/349 [==============================] - 0s 971us/step - loss: 3.1519e-04 - val_loss: 4.5012e-04\n",
      "Epoch 479/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 3.2623e-04 - val_loss: 4.7741e-04\n",
      "Epoch 480/1000\n",
      "349/349 [==============================] - 0s 958us/step - loss: 3.1433e-04 - val_loss: 4.4090e-04\n",
      "Epoch 481/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 3.1232e-04 - val_loss: 4.5448e-04\n",
      "Epoch 482/1000\n",
      "349/349 [==============================] - 0s 965us/step - loss: 3.1360e-04 - val_loss: 4.4036e-04\n",
      "Epoch 483/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 3.0866e-04 - val_loss: 4.3955e-04\n",
      "Epoch 484/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 3.1270e-04 - val_loss: 4.4046e-04\n",
      "Epoch 485/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 3.1617e-04 - val_loss: 4.3971e-04\n",
      "Epoch 486/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.1153e-04 - val_loss: 4.4710e-04\n",
      "Epoch 487/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 3.2118e-04 - val_loss: 4.4000e-04\n",
      "Epoch 488/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 3.1573e-04 - val_loss: 4.4214e-04\n",
      "Epoch 489/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.1550e-04 - val_loss: 4.3858e-04\n",
      "Epoch 490/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.1099e-04 - val_loss: 4.3947e-04\n",
      "Epoch 491/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 3.2289e-04 - val_loss: 4.6492e-04\n",
      "Epoch 492/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 3.1893e-04 - val_loss: 4.4446e-04\n",
      "Epoch 493/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.9925e-04 - val_loss: 4.4643e-04\n",
      "Epoch 494/1000\n",
      "349/349 [==============================] - 0s 946us/step - loss: 3.1783e-04 - val_loss: 4.4462e-04\n",
      "Epoch 495/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 3.1082e-04 - val_loss: 4.3760e-04\n",
      "Epoch 496/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.0407e-04 - val_loss: 4.3810e-04\n",
      "Epoch 497/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 3.0898e-04 - val_loss: 4.4087e-04\n",
      "Epoch 498/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 3.0285e-04 - val_loss: 4.4398e-04\n",
      "Epoch 499/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 3.1006e-04 - val_loss: 4.3829e-04\n",
      "Epoch 500/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 3.1801e-04 - val_loss: 4.3446e-04\n",
      "Epoch 501/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.1039e-04 - val_loss: 4.4547e-04\n",
      "Epoch 502/1000\n",
      "349/349 [==============================] - 0s 893us/step - loss: 3.1568e-04 - val_loss: 4.3695e-04\n",
      "Epoch 503/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 3.0101e-04 - val_loss: 4.3809e-04\n",
      "Epoch 504/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 3.0228e-04 - val_loss: 4.3977e-04\n",
      "Epoch 505/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.0228e-04 - val_loss: 4.3523e-04\n",
      "Epoch 506/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 3.0718e-04 - val_loss: 4.3696e-04\n",
      "Epoch 507/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.9526e-04 - val_loss: 4.4102e-04\n",
      "Epoch 508/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 3.0351e-04 - val_loss: 4.3380e-04\n",
      "Epoch 509/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.0434e-04 - val_loss: 4.3934e-04\n",
      "Epoch 510/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.9662e-04 - val_loss: 4.4144e-04\n",
      "Epoch 511/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.1061e-04 - val_loss: 4.3792e-04\n",
      "Epoch 512/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.0869e-04 - val_loss: 4.4208e-04\n",
      "Epoch 513/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 3.0631e-04 - val_loss: 4.3717e-04\n",
      "Epoch 514/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.9659e-04 - val_loss: 4.3873e-04\n",
      "Epoch 515/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 3.0553e-04 - val_loss: 4.4187e-04\n",
      "Epoch 516/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 3.1003e-04 - val_loss: 4.4839e-04\n",
      "Epoch 517/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 2.9591e-04 - val_loss: 4.3563e-04\n",
      "Epoch 518/1000\n",
      "349/349 [==============================] - 0s 956us/step - loss: 2.9539e-04 - val_loss: 4.3679e-04\n",
      "Epoch 519/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 3.0255e-04 - val_loss: 4.5076e-04\n",
      "Epoch 520/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 2.9942e-04 - val_loss: 4.3715e-04\n",
      "Epoch 521/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 3.0138e-04 - val_loss: 4.4224e-04\n",
      "Epoch 522/1000\n",
      "349/349 [==============================] - 0s 945us/step - loss: 3.0230e-04 - val_loss: 4.3316e-04\n",
      "Epoch 523/1000\n",
      "349/349 [==============================] - 0s 943us/step - loss: 2.9858e-04 - val_loss: 4.5318e-04\n",
      "Epoch 524/1000\n",
      "349/349 [==============================] - 0s 947us/step - loss: 2.9563e-04 - val_loss: 4.2993e-04\n",
      "Epoch 525/1000\n",
      "349/349 [==============================] - 0s 953us/step - loss: 2.9745e-04 - val_loss: 4.3749e-04\n",
      "Epoch 526/1000\n",
      "349/349 [==============================] - 0s 900us/step - loss: 2.9037e-04 - val_loss: 4.4571e-04\n",
      "Epoch 527/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.9887e-04 - val_loss: 4.2844e-04\n",
      "Epoch 528/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.9875e-04 - val_loss: 4.3292e-04\n",
      "Epoch 529/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.9581e-04 - val_loss: 4.3978e-04\n",
      "Epoch 530/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.8402e-04 - val_loss: 4.4164e-04\n",
      "Epoch 531/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 3.0169e-04 - val_loss: 4.3800e-04\n",
      "Epoch 532/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 3.0747e-04 - val_loss: 4.5385e-04\n",
      "Epoch 533/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 3.0083e-04 - val_loss: 4.3368e-04\n",
      "Epoch 534/1000\n",
      "349/349 [==============================] - 0s 967us/step - loss: 2.9376e-04 - val_loss: 4.4078e-04\n",
      "Epoch 535/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 2.9159e-04 - val_loss: 4.2880e-04\n",
      "Epoch 536/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.8931e-04 - val_loss: 4.4399e-04\n",
      "Epoch 537/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.8932e-04 - val_loss: 4.3121e-04\n",
      "Epoch 538/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.8528e-04 - val_loss: 4.3443e-04\n",
      "Epoch 539/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.9128e-04 - val_loss: 4.7761e-04\n",
      "Epoch 540/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 3.0551e-04 - val_loss: 4.3502e-04\n",
      "Epoch 541/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.9699e-04 - val_loss: 4.3012e-04\n",
      "Epoch 542/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 2.8889e-04 - val_loss: 4.3562e-04\n",
      "Epoch 543/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 3.0374e-04 - val_loss: 4.3370e-04\n",
      "Epoch 544/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.9512e-04 - val_loss: 4.3158e-04\n",
      "Epoch 545/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.9658e-04 - val_loss: 4.3678e-04\n",
      "Epoch 546/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 3.0085e-04 - val_loss: 4.4525e-04\n",
      "Epoch 547/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.8432e-04 - val_loss: 4.2795e-04\n",
      "Epoch 548/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 2.8153e-04 - val_loss: 4.3069e-04\n",
      "Epoch 549/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.7907e-04 - val_loss: 4.3277e-04\n",
      "Epoch 550/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.0275e-04 - val_loss: 4.4030e-04\n",
      "Epoch 551/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 2.8296e-04 - val_loss: 4.2568e-04\n",
      "Epoch 552/1000\n",
      "349/349 [==============================] - 0s 956us/step - loss: 2.8816e-04 - val_loss: 4.2862e-04\n",
      "Epoch 553/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 3.0807e-04 - val_loss: 4.2877e-04\n",
      "Epoch 554/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.9637e-04 - val_loss: 4.3456e-04\n",
      "Epoch 555/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.8451e-04 - val_loss: 4.3849e-04\n",
      "Epoch 556/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.8422e-04 - val_loss: 4.2999e-04\n",
      "Epoch 557/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.8767e-04 - val_loss: 4.2623e-04\n",
      "Epoch 558/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.8892e-04 - val_loss: 4.2799e-04\n",
      "Epoch 559/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.8374e-04 - val_loss: 4.4582e-04\n",
      "Epoch 560/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.8637e-04 - val_loss: 4.2395e-04\n",
      "Epoch 561/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.8082e-04 - val_loss: 4.8602e-04\n",
      "Epoch 562/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.5024e-04 - val_loss: 4.3226e-04\n",
      "Epoch 563/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.9297e-04 - val_loss: 4.2853e-04\n",
      "Epoch 564/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.8335e-04 - val_loss: 4.3786e-04\n",
      "Epoch 565/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.9483e-04 - val_loss: 4.2670e-04\n",
      "Epoch 566/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.7871e-04 - val_loss: 4.2779e-04\n",
      "Epoch 567/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.9072e-04 - val_loss: 4.2329e-04\n",
      "Epoch 568/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.7396e-04 - val_loss: 4.4946e-04\n",
      "Epoch 569/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 3.2772e-04 - val_loss: 4.2360e-04\n",
      "Epoch 570/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.7959e-04 - val_loss: 4.2699e-04\n",
      "Epoch 571/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 2.8806e-04 - val_loss: 4.2452e-04\n",
      "Epoch 572/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.9134e-04 - val_loss: 4.2297e-04\n",
      "Epoch 573/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.8023e-04 - val_loss: 4.2377e-04\n",
      "Epoch 574/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 2.9170e-04 - val_loss: 4.3152e-04\n",
      "Epoch 575/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.7941e-04 - val_loss: 4.2533e-04\n",
      "Epoch 576/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.8736e-04 - val_loss: 4.3214e-04\n",
      "Epoch 577/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.8303e-04 - val_loss: 4.3721e-04\n",
      "Epoch 578/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 3.0886e-04 - val_loss: 4.2398e-04\n",
      "Epoch 579/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.8034e-04 - val_loss: 4.6753e-04\n",
      "Epoch 580/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.9558e-04 - val_loss: 4.2355e-04\n",
      "Epoch 581/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 2.8498e-04 - val_loss: 4.2157e-04\n",
      "Epoch 582/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.8633e-04 - val_loss: 4.4769e-04\n",
      "Epoch 583/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 2.8591e-04 - val_loss: 4.3287e-04\n",
      "Epoch 584/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 2.8474e-04 - val_loss: 4.2396e-04\n",
      "Epoch 585/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.8109e-04 - val_loss: 4.2662e-04\n",
      "Epoch 586/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.7179e-04 - val_loss: 4.2068e-04\n",
      "Epoch 587/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.8760e-04 - val_loss: 4.3681e-04\n",
      "Epoch 588/1000\n",
      "349/349 [==============================] - 0s 952us/step - loss: 2.7775e-04 - val_loss: 4.2783e-04\n",
      "Epoch 589/1000\n",
      "349/349 [==============================] - 0s 972us/step - loss: 2.7026e-04 - val_loss: 4.2273e-04\n",
      "Epoch 590/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.8064e-04 - val_loss: 4.2164e-04\n",
      "Epoch 591/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.8140e-04 - val_loss: 4.2149e-04\n",
      "Epoch 592/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 2.9866e-04 - val_loss: 4.3077e-04\n",
      "Epoch 593/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.7717e-04 - val_loss: 4.2631e-04\n",
      "Epoch 594/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 2.8189e-04 - val_loss: 4.2127e-04\n",
      "Epoch 595/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 2.6614e-04 - val_loss: 4.2229e-04\n",
      "Epoch 596/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.7941e-04 - val_loss: 4.2347e-04\n",
      "Epoch 597/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.8190e-04 - val_loss: 4.6249e-04\n",
      "Epoch 598/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.8748e-04 - val_loss: 4.1958e-04\n",
      "Epoch 599/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 2.8531e-04 - val_loss: 4.2853e-04\n",
      "Epoch 600/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.7916e-04 - val_loss: 4.2563e-04\n",
      "Epoch 601/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.7490e-04 - val_loss: 4.1991e-04\n",
      "Epoch 602/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.7565e-04 - val_loss: 4.2058e-04\n",
      "Epoch 603/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.7749e-04 - val_loss: 4.1880e-04\n",
      "Epoch 604/1000\n",
      "349/349 [==============================] - 0s 972us/step - loss: 2.7297e-04 - val_loss: 4.1777e-04\n",
      "Epoch 605/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.7175e-04 - val_loss: 4.3136e-04\n",
      "Epoch 606/1000\n",
      "349/349 [==============================] - 0s 960us/step - loss: 2.8913e-04 - val_loss: 4.2344e-04\n",
      "Epoch 607/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 2.7895e-04 - val_loss: 4.2883e-04\n",
      "Epoch 608/1000\n",
      "349/349 [==============================] - 0s 962us/step - loss: 2.7255e-04 - val_loss: 4.2348e-04\n",
      "Epoch 609/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.7039e-04 - val_loss: 4.3205e-04\n",
      "Epoch 610/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 2.9720e-04 - val_loss: 4.2263e-04\n",
      "Epoch 611/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.6645e-04 - val_loss: 4.3178e-04\n",
      "Epoch 612/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.7223e-04 - val_loss: 4.2260e-04\n",
      "Epoch 613/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.6767e-04 - val_loss: 4.2529e-04\n",
      "Epoch 614/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.7413e-04 - val_loss: 4.3180e-04\n",
      "Epoch 615/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.7389e-04 - val_loss: 4.2378e-04\n",
      "Epoch 616/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.6508e-04 - val_loss: 4.1754e-04\n",
      "Epoch 617/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.6496e-04 - val_loss: 4.3774e-04\n",
      "Epoch 618/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.8125e-04 - val_loss: 4.2469e-04\n",
      "Epoch 619/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.6324e-04 - val_loss: 4.4167e-04\n",
      "Epoch 620/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.6028e-04 - val_loss: 4.2813e-04\n",
      "Epoch 621/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.8051e-04 - val_loss: 4.2849e-04\n",
      "Epoch 622/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.6119e-04 - val_loss: 4.2140e-04\n",
      "Epoch 623/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.5869e-04 - val_loss: 4.2260e-04\n",
      "Epoch 624/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.7205e-04 - val_loss: 4.1623e-04\n",
      "Epoch 625/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.6689e-04 - val_loss: 4.3108e-04\n",
      "Epoch 626/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.7414e-04 - val_loss: 4.1972e-04\n",
      "Epoch 627/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.6936e-04 - val_loss: 4.2268e-04\n",
      "Epoch 628/1000\n",
      "349/349 [==============================] - 0s 897us/step - loss: 2.7637e-04 - val_loss: 4.2276e-04\n",
      "Epoch 629/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.6584e-04 - val_loss: 4.2830e-04\n",
      "Epoch 630/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 2.6057e-04 - val_loss: 4.2292e-04\n",
      "Epoch 631/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.6901e-04 - val_loss: 4.1663e-04\n",
      "Epoch 632/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.6067e-04 - val_loss: 4.1923e-04\n",
      "Epoch 633/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 2.5891e-04 - val_loss: 4.1388e-04\n",
      "Epoch 634/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.6476e-04 - val_loss: 4.2110e-04\n",
      "Epoch 635/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.7172e-04 - val_loss: 4.3058e-04\n",
      "Epoch 636/1000\n",
      "349/349 [==============================] - 0s 900us/step - loss: 2.7239e-04 - val_loss: 4.1898e-04\n",
      "Epoch 637/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.7330e-04 - val_loss: 4.2326e-04\n",
      "Epoch 638/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.6977e-04 - val_loss: 4.1557e-04\n",
      "Epoch 639/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.6602e-04 - val_loss: 4.3501e-04\n",
      "Epoch 640/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.7500e-04 - val_loss: 4.2015e-04\n",
      "Epoch 641/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 2.6511e-04 - val_loss: 4.1816e-04\n",
      "Epoch 642/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 2.6015e-04 - val_loss: 4.4333e-04\n",
      "Epoch 643/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.7829e-04 - val_loss: 4.1423e-04\n",
      "Epoch 644/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.6141e-04 - val_loss: 4.2269e-04\n",
      "Epoch 645/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.8751e-04 - val_loss: 4.4017e-04\n",
      "Epoch 646/1000\n",
      "349/349 [==============================] - 0s 955us/step - loss: 2.7730e-04 - val_loss: 4.1771e-04\n",
      "Epoch 647/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.6070e-04 - val_loss: 4.2211e-04\n",
      "Epoch 648/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.5809e-04 - val_loss: 4.4555e-04\n",
      "Epoch 649/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.7836e-04 - val_loss: 4.1425e-04\n",
      "Epoch 650/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.6288e-04 - val_loss: 4.1699e-04\n",
      "Epoch 651/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.5015e-04 - val_loss: 4.1467e-04\n",
      "Epoch 652/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 2.5387e-04 - val_loss: 4.1424e-04\n",
      "Epoch 653/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.6512e-04 - val_loss: 4.1947e-04\n",
      "Epoch 654/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 2.5948e-04 - val_loss: 4.1943e-04\n",
      "Epoch 655/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.5674e-04 - val_loss: 4.1348e-04\n",
      "Epoch 656/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.5291e-04 - val_loss: 4.1853e-04\n",
      "Epoch 657/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.5576e-04 - val_loss: 4.1100e-04\n",
      "Epoch 658/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.6095e-04 - val_loss: 4.1037e-04\n",
      "Epoch 659/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.6409e-04 - val_loss: 4.1534e-04\n",
      "Epoch 660/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.4869e-04 - val_loss: 4.1304e-04\n",
      "Epoch 661/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.5813e-04 - val_loss: 4.1351e-04\n",
      "Epoch 662/1000\n",
      "349/349 [==============================] - 0s 896us/step - loss: 2.6702e-04 - val_loss: 4.1429e-04\n",
      "Epoch 663/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.5591e-04 - val_loss: 4.1045e-04\n",
      "Epoch 664/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.5740e-04 - val_loss: 4.5773e-04\n",
      "Epoch 665/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.5992e-04 - val_loss: 4.2908e-04\n",
      "Epoch 666/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.5325e-04 - val_loss: 4.1104e-04\n",
      "Epoch 667/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.5707e-04 - val_loss: 4.2245e-04\n",
      "Epoch 668/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.5670e-04 - val_loss: 4.1500e-04\n",
      "Epoch 669/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.6168e-04 - val_loss: 4.1426e-04\n",
      "Epoch 670/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 2.5637e-04 - val_loss: 4.1116e-04\n",
      "Epoch 671/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.5940e-04 - val_loss: 4.1988e-04\n",
      "Epoch 672/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.5022e-04 - val_loss: 4.1619e-04\n",
      "Epoch 673/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.4546e-04 - val_loss: 4.2777e-04\n",
      "Epoch 674/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.6108e-04 - val_loss: 4.1473e-04\n",
      "Epoch 675/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 2.6229e-04 - val_loss: 4.0823e-04\n",
      "Epoch 676/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.5058e-04 - val_loss: 4.2328e-04\n",
      "Epoch 677/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.5608e-04 - val_loss: 4.1989e-04\n",
      "Epoch 678/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.4832e-04 - val_loss: 4.1688e-04\n",
      "Epoch 679/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.6273e-04 - val_loss: 4.1764e-04\n",
      "Epoch 680/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.5917e-04 - val_loss: 4.1004e-04\n",
      "Epoch 681/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.4906e-04 - val_loss: 4.1063e-04\n",
      "Epoch 682/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.5844e-04 - val_loss: 4.1107e-04\n",
      "Epoch 683/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.4622e-04 - val_loss: 4.1565e-04\n",
      "Epoch 684/1000\n",
      "349/349 [==============================] - 0s 900us/step - loss: 2.5244e-04 - val_loss: 4.1467e-04\n",
      "Epoch 685/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.5415e-04 - val_loss: 4.1085e-04\n",
      "Epoch 686/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.4597e-04 - val_loss: 4.2889e-04\n",
      "Epoch 687/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.6083e-04 - val_loss: 4.0776e-04\n",
      "Epoch 688/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.5671e-04 - val_loss: 4.0859e-04\n",
      "Epoch 689/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.4857e-04 - val_loss: 4.2480e-04\n",
      "Epoch 690/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.4863e-04 - val_loss: 4.1394e-04\n",
      "Epoch 691/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.5785e-04 - val_loss: 4.0996e-04\n",
      "Epoch 692/1000\n",
      "349/349 [==============================] - 0s 940us/step - loss: 2.3916e-04 - val_loss: 4.1919e-04\n",
      "Epoch 693/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.5760e-04 - val_loss: 4.1022e-04\n",
      "Epoch 694/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.4284e-04 - val_loss: 4.0823e-04\n",
      "Epoch 695/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.4757e-04 - val_loss: 4.1201e-04\n",
      "Epoch 696/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.5285e-04 - val_loss: 4.1091e-04\n",
      "Epoch 697/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.5423e-04 - val_loss: 4.2426e-04\n",
      "Epoch 698/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.5346e-04 - val_loss: 4.0813e-04\n",
      "Epoch 699/1000\n",
      "349/349 [==============================] - 0s 943us/step - loss: 2.4856e-04 - val_loss: 4.1254e-04\n",
      "Epoch 700/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 2.4443e-04 - val_loss: 4.1127e-04\n",
      "Epoch 701/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 2.4969e-04 - val_loss: 4.1322e-04\n",
      "Epoch 702/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.5099e-04 - val_loss: 4.3590e-04\n",
      "Epoch 703/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.6821e-04 - val_loss: 4.0739e-04\n",
      "Epoch 704/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.4713e-04 - val_loss: 4.1376e-04\n",
      "Epoch 705/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.5107e-04 - val_loss: 4.0567e-04\n",
      "Epoch 706/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.4824e-04 - val_loss: 4.1285e-04\n",
      "Epoch 707/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.4908e-04 - val_loss: 4.1778e-04\n",
      "Epoch 708/1000\n",
      "349/349 [==============================] - 0s 892us/step - loss: 2.4787e-04 - val_loss: 4.1779e-04\n",
      "Epoch 709/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 2.4955e-04 - val_loss: 4.0875e-04\n",
      "Epoch 710/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.3759e-04 - val_loss: 4.1569e-04\n",
      "Epoch 711/1000\n",
      "349/349 [==============================] - 0s 940us/step - loss: 2.5272e-04 - val_loss: 4.0514e-04\n",
      "Epoch 712/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.4302e-04 - val_loss: 4.1211e-04\n",
      "Epoch 713/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.4988e-04 - val_loss: 4.0858e-04\n",
      "Epoch 714/1000\n",
      "349/349 [==============================] - 0s 940us/step - loss: 2.3992e-04 - val_loss: 4.0845e-04\n",
      "Epoch 715/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.4835e-04 - val_loss: 4.2349e-04\n",
      "Epoch 716/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.5097e-04 - val_loss: 4.1294e-04\n",
      "Epoch 717/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.4701e-04 - val_loss: 4.2549e-04\n",
      "Epoch 718/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.5000e-04 - val_loss: 4.1107e-04\n",
      "Epoch 719/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.4829e-04 - val_loss: 4.1474e-04\n",
      "Epoch 720/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.4640e-04 - val_loss: 4.0938e-04\n",
      "Epoch 721/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.5407e-04 - val_loss: 4.0400e-04\n",
      "Epoch 722/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 2.3950e-04 - val_loss: 4.1298e-04\n",
      "Epoch 723/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.4263e-04 - val_loss: 4.1180e-04\n",
      "Epoch 724/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.4714e-04 - val_loss: 4.1156e-04\n",
      "Epoch 725/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.4125e-04 - val_loss: 4.2784e-04\n",
      "Epoch 726/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.3734e-04 - val_loss: 4.0611e-04\n",
      "Epoch 727/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.4345e-04 - val_loss: 4.1638e-04\n",
      "Epoch 728/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.4728e-04 - val_loss: 4.1017e-04\n",
      "Epoch 729/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.5504e-04 - val_loss: 4.0954e-04\n",
      "Epoch 730/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 2.4374e-04 - val_loss: 4.0542e-04\n",
      "Epoch 731/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 2.3615e-04 - val_loss: 4.0648e-04\n",
      "Epoch 732/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.4641e-04 - val_loss: 4.0319e-04\n",
      "Epoch 733/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.4140e-04 - val_loss: 4.0933e-04\n",
      "Epoch 734/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.3636e-04 - val_loss: 4.0590e-04\n",
      "Epoch 735/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.3476e-04 - val_loss: 4.0652e-04\n",
      "Epoch 736/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.3768e-04 - val_loss: 4.4382e-04\n",
      "Epoch 737/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.9610e-04 - val_loss: 4.0288e-04\n",
      "Epoch 738/1000\n",
      "349/349 [==============================] - 0s 956us/step - loss: 2.3906e-04 - val_loss: 4.0641e-04\n",
      "Epoch 739/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.3823e-04 - val_loss: 4.0876e-04\n",
      "Epoch 740/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.3642e-04 - val_loss: 4.1000e-04\n",
      "Epoch 741/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 2.4665e-04 - val_loss: 4.1183e-04\n",
      "Epoch 742/1000\n",
      "349/349 [==============================] - 0s 900us/step - loss: 2.3534e-04 - val_loss: 4.0564e-04\n",
      "Epoch 743/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.3684e-04 - val_loss: 4.1313e-04\n",
      "Epoch 744/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.3938e-04 - val_loss: 4.1681e-04\n",
      "Epoch 745/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.5510e-04 - val_loss: 4.0874e-04\n",
      "Epoch 746/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.3601e-04 - val_loss: 4.0798e-04\n",
      "Epoch 747/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 2.4233e-04 - val_loss: 4.1066e-04\n",
      "Epoch 748/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.3265e-04 - val_loss: 4.1095e-04\n",
      "Epoch 749/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.3675e-04 - val_loss: 4.1050e-04\n",
      "Epoch 750/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.2980e-04 - val_loss: 4.0167e-04\n",
      "Epoch 751/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.3055e-04 - val_loss: 4.0568e-04\n",
      "Epoch 752/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.4445e-04 - val_loss: 4.0424e-04\n",
      "Epoch 753/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.3105e-04 - val_loss: 4.0311e-04\n",
      "Epoch 754/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.3775e-04 - val_loss: 4.0220e-04\n",
      "Epoch 755/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 2.4326e-04 - val_loss: 4.0890e-04\n",
      "Epoch 756/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.3516e-04 - val_loss: 4.1081e-04\n",
      "Epoch 757/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.3128e-04 - val_loss: 4.0335e-04\n",
      "Epoch 758/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.3081e-04 - val_loss: 4.1754e-04\n",
      "Epoch 759/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 2.3311e-04 - val_loss: 4.1802e-04\n",
      "Epoch 760/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.4494e-04 - val_loss: 4.0628e-04\n",
      "Epoch 761/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.3129e-04 - val_loss: 4.0147e-04\n",
      "Epoch 762/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 2.2511e-04 - val_loss: 4.0270e-04\n",
      "Epoch 763/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.3848e-04 - val_loss: 4.2462e-04\n",
      "Epoch 764/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.6182e-04 - val_loss: 4.1343e-04\n",
      "Epoch 765/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.4264e-04 - val_loss: 4.0086e-04\n",
      "Epoch 766/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.3014e-04 - val_loss: 4.1392e-04\n",
      "Epoch 767/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.3847e-04 - val_loss: 4.0003e-04\n",
      "Epoch 768/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.2865e-04 - val_loss: 4.0014e-04\n",
      "Epoch 769/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 2.3309e-04 - val_loss: 3.9924e-04\n",
      "Epoch 770/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.3196e-04 - val_loss: 4.0628e-04\n",
      "Epoch 771/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 2.3030e-04 - val_loss: 4.0151e-04\n",
      "Epoch 772/1000\n",
      "349/349 [==============================] - 0s 902us/step - loss: 2.2214e-04 - val_loss: 4.1709e-04\n",
      "Epoch 773/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.3711e-04 - val_loss: 4.0839e-04\n",
      "Epoch 774/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.3505e-04 - val_loss: 4.0230e-04\n",
      "Epoch 775/1000\n",
      "349/349 [==============================] - 0s 903us/step - loss: 2.3627e-04 - val_loss: 3.9832e-04\n",
      "Epoch 776/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.3004e-04 - val_loss: 4.0117e-04\n",
      "Epoch 777/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.2826e-04 - val_loss: 3.9851e-04\n",
      "Epoch 778/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.3557e-04 - val_loss: 4.1161e-04\n",
      "Epoch 779/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.2644e-04 - val_loss: 4.0762e-04\n",
      "Epoch 780/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.3370e-04 - val_loss: 4.0415e-04\n",
      "Epoch 781/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.3582e-04 - val_loss: 4.0526e-04\n",
      "Epoch 782/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.2130e-04 - val_loss: 4.1579e-04\n",
      "Epoch 783/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.3429e-04 - val_loss: 4.0593e-04\n",
      "Epoch 784/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.3165e-04 - val_loss: 4.0214e-04\n",
      "Epoch 785/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 2.2804e-04 - val_loss: 4.0330e-04\n",
      "Epoch 786/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.2913e-04 - val_loss: 4.2324e-04\n",
      "Epoch 787/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.5016e-04 - val_loss: 4.2100e-04\n",
      "Epoch 788/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.4058e-04 - val_loss: 3.9955e-04\n",
      "Epoch 789/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.2991e-04 - val_loss: 3.9945e-04\n",
      "Epoch 790/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 2.2154e-04 - val_loss: 3.9853e-04\n",
      "Epoch 791/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 2.3406e-04 - val_loss: 3.9729e-04\n",
      "Epoch 792/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 2.2187e-04 - val_loss: 4.1343e-04\n",
      "Epoch 793/1000\n",
      "349/349 [==============================] - 0s 898us/step - loss: 2.3625e-04 - val_loss: 4.0223e-04\n",
      "Epoch 794/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.2928e-04 - val_loss: 4.0394e-04\n",
      "Epoch 795/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 2.2854e-04 - val_loss: 4.0256e-04\n",
      "Epoch 796/1000\n",
      "349/349 [==============================] - 0s 934us/step - loss: 2.3293e-04 - val_loss: 4.4033e-04\n",
      "Epoch 797/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 2.9417e-04 - val_loss: 3.9700e-04\n",
      "Epoch 798/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.2817e-04 - val_loss: 3.9648e-04\n",
      "Epoch 799/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2651e-04 - val_loss: 3.9994e-04\n",
      "Epoch 800/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.2408e-04 - val_loss: 4.0165e-04\n",
      "Epoch 801/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.2692e-04 - val_loss: 4.0955e-04\n",
      "Epoch 802/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2810e-04 - val_loss: 4.0504e-04\n",
      "Epoch 803/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.1631e-04 - val_loss: 4.0022e-04\n",
      "Epoch 804/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 2.2408e-04 - val_loss: 3.9848e-04\n",
      "Epoch 805/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.1505e-04 - val_loss: 4.0289e-04\n",
      "Epoch 806/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 2.2544e-04 - val_loss: 4.0215e-04\n",
      "Epoch 807/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.2825e-04 - val_loss: 3.9842e-04\n",
      "Epoch 808/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.2496e-04 - val_loss: 3.9828e-04\n",
      "Epoch 809/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.3897e-04 - val_loss: 4.0141e-04\n",
      "Epoch 810/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.1819e-04 - val_loss: 4.0265e-04\n",
      "Epoch 811/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 2.1418e-04 - val_loss: 4.0294e-04\n",
      "Epoch 812/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.1854e-04 - val_loss: 3.9778e-04\n",
      "Epoch 813/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.2816e-04 - val_loss: 4.0487e-04\n",
      "Epoch 814/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.3003e-04 - val_loss: 4.0377e-04\n",
      "Epoch 815/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.2935e-04 - val_loss: 3.9969e-04\n",
      "Epoch 816/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.2412e-04 - val_loss: 3.9819e-04\n",
      "Epoch 817/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.2011e-04 - val_loss: 4.0573e-04\n",
      "Epoch 818/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.2473e-04 - val_loss: 3.9551e-04\n",
      "Epoch 819/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.1713e-04 - val_loss: 4.1805e-04\n",
      "Epoch 820/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.2452e-04 - val_loss: 4.0611e-04\n",
      "Epoch 821/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2414e-04 - val_loss: 3.9651e-04\n",
      "Epoch 822/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.2316e-04 - val_loss: 3.9654e-04\n",
      "Epoch 823/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.2984e-04 - val_loss: 3.9888e-04\n",
      "Epoch 824/1000\n",
      "349/349 [==============================] - 0s 897us/step - loss: 2.2124e-04 - val_loss: 3.9548e-04\n",
      "Epoch 825/1000\n",
      "349/349 [==============================] - 0s 968us/step - loss: 2.1056e-04 - val_loss: 4.0283e-04\n",
      "Epoch 826/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.2023e-04 - val_loss: 4.0032e-04\n",
      "Epoch 827/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.1763e-04 - val_loss: 3.9749e-04\n",
      "Epoch 828/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.1791e-04 - val_loss: 3.9875e-04\n",
      "Epoch 829/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.2304e-04 - val_loss: 4.0224e-04\n",
      "Epoch 830/1000\n",
      "349/349 [==============================] - 0s 941us/step - loss: 2.1893e-04 - val_loss: 4.0260e-04\n",
      "Epoch 831/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.2120e-04 - val_loss: 4.0014e-04\n",
      "Epoch 832/1000\n",
      "349/349 [==============================] - 0s 944us/step - loss: 2.2548e-04 - val_loss: 3.9534e-04\n",
      "Epoch 833/1000\n",
      "349/349 [==============================] - 0s 936us/step - loss: 2.1832e-04 - val_loss: 3.9952e-04\n",
      "Epoch 834/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2422e-04 - val_loss: 3.9815e-04\n",
      "Epoch 835/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.1565e-04 - val_loss: 4.0321e-04\n",
      "Epoch 836/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 2.2040e-04 - val_loss: 3.9512e-04\n",
      "Epoch 837/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 2.1957e-04 - val_loss: 3.9800e-04\n",
      "Epoch 838/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 2.1780e-04 - val_loss: 4.0354e-04\n",
      "Epoch 839/1000\n",
      "349/349 [==============================] - 0s 968us/step - loss: 2.1865e-04 - val_loss: 3.9546e-04\n",
      "Epoch 840/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 2.1286e-04 - val_loss: 3.9386e-04\n",
      "Epoch 841/1000\n",
      "349/349 [==============================] - 0s 945us/step - loss: 2.1620e-04 - val_loss: 3.9867e-04\n",
      "Epoch 842/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.2239e-04 - val_loss: 3.9552e-04\n",
      "Epoch 843/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 2.2451e-04 - val_loss: 4.0262e-04\n",
      "Epoch 844/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.2029e-04 - val_loss: 3.9614e-04\n",
      "Epoch 845/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.1903e-04 - val_loss: 4.0478e-04\n",
      "Epoch 846/1000\n",
      "349/349 [==============================] - 0s 952us/step - loss: 2.1511e-04 - val_loss: 4.1143e-04\n",
      "Epoch 847/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.2236e-04 - val_loss: 3.9683e-04\n",
      "Epoch 848/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.1897e-04 - val_loss: 4.2391e-04\n",
      "Epoch 849/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.8968e-04 - val_loss: 3.9848e-04\n",
      "Epoch 850/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.1266e-04 - val_loss: 4.0173e-04\n",
      "Epoch 851/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.1790e-04 - val_loss: 4.1268e-04\n",
      "Epoch 852/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.2135e-04 - val_loss: 3.9575e-04\n",
      "Epoch 853/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 2.1600e-04 - val_loss: 3.9426e-04\n",
      "Epoch 854/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.1004e-04 - val_loss: 4.0346e-04\n",
      "Epoch 855/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 2.1887e-04 - val_loss: 3.9971e-04\n",
      "Epoch 856/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 2.1708e-04 - val_loss: 4.0390e-04\n",
      "Epoch 857/1000\n",
      "349/349 [==============================] - 0s 955us/step - loss: 2.1497e-04 - val_loss: 4.0463e-04\n",
      "Epoch 858/1000\n",
      "349/349 [==============================] - 0s 990us/step - loss: 2.1658e-04 - val_loss: 3.9594e-04\n",
      "Epoch 859/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 2.1080e-04 - val_loss: 3.9986e-04\n",
      "Epoch 860/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.1815e-04 - val_loss: 3.9366e-04\n",
      "Epoch 861/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.1413e-04 - val_loss: 3.9371e-04\n",
      "Epoch 862/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.0503e-04 - val_loss: 3.9740e-04\n",
      "Epoch 863/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.1446e-04 - val_loss: 4.0262e-04\n",
      "Epoch 864/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.1700e-04 - val_loss: 3.9854e-04\n",
      "Epoch 865/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.1425e-04 - val_loss: 3.9719e-04\n",
      "Epoch 866/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.0748e-04 - val_loss: 3.9396e-04\n",
      "Epoch 867/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 2.1893e-04 - val_loss: 4.0147e-04\n",
      "Epoch 868/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 2.1782e-04 - val_loss: 4.0275e-04\n",
      "Epoch 869/1000\n",
      "349/349 [==============================] - 0s 945us/step - loss: 2.2232e-04 - val_loss: 3.9307e-04\n",
      "Epoch 870/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.1061e-04 - val_loss: 3.9307e-04\n",
      "Epoch 871/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2242e-04 - val_loss: 3.9266e-04\n",
      "Epoch 872/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.1208e-04 - val_loss: 4.0717e-04\n",
      "Epoch 873/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.0803e-04 - val_loss: 3.9363e-04\n",
      "Epoch 874/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.2430e-04 - val_loss: 3.9371e-04\n",
      "Epoch 875/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.1217e-04 - val_loss: 3.9619e-04\n",
      "Epoch 876/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.0971e-04 - val_loss: 4.2933e-04\n",
      "Epoch 877/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.2326e-04 - val_loss: 3.9364e-04\n",
      "Epoch 878/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 2.1075e-04 - val_loss: 3.9757e-04\n",
      "Epoch 879/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.1529e-04 - val_loss: 3.9250e-04\n",
      "Epoch 880/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.1090e-04 - val_loss: 4.0002e-04\n",
      "Epoch 881/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.1689e-04 - val_loss: 3.9514e-04\n",
      "Epoch 882/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.0461e-04 - val_loss: 3.9325e-04\n",
      "Epoch 883/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 2.1110e-04 - val_loss: 3.9959e-04\n",
      "Epoch 884/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 2.0727e-04 - val_loss: 3.9391e-04\n",
      "Epoch 885/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.0826e-04 - val_loss: 3.9203e-04\n",
      "Epoch 886/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.1682e-04 - val_loss: 4.0295e-04\n",
      "Epoch 887/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.0684e-04 - val_loss: 3.9098e-04\n",
      "Epoch 888/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 2.0757e-04 - val_loss: 3.9224e-04\n",
      "Epoch 889/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 2.0746e-04 - val_loss: 3.9324e-04\n",
      "Epoch 890/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.0919e-04 - val_loss: 3.9323e-04\n",
      "Epoch 891/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 2.0547e-04 - val_loss: 3.9078e-04\n",
      "Epoch 892/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.0432e-04 - val_loss: 3.9671e-04\n",
      "Epoch 893/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 2.0652e-04 - val_loss: 3.9162e-04\n",
      "Epoch 894/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.0369e-04 - val_loss: 3.9382e-04\n",
      "Epoch 895/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.0540e-04 - val_loss: 3.9835e-04\n",
      "Epoch 896/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.1017e-04 - val_loss: 3.9596e-04\n",
      "Epoch 897/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 2.0347e-04 - val_loss: 3.9398e-04\n",
      "Epoch 898/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 2.0835e-04 - val_loss: 4.0069e-04\n",
      "Epoch 899/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.0404e-04 - val_loss: 4.2105e-04\n",
      "Epoch 900/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 2.1098e-04 - val_loss: 4.1442e-04\n",
      "Epoch 901/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.0286e-04 - val_loss: 3.8965e-04\n",
      "Epoch 902/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.0241e-04 - val_loss: 3.8879e-04\n",
      "Epoch 903/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 2.0451e-04 - val_loss: 3.9076e-04\n",
      "Epoch 904/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 2.0294e-04 - val_loss: 4.0127e-04\n",
      "Epoch 905/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.0460e-04 - val_loss: 3.9273e-04\n",
      "Epoch 906/1000\n",
      "349/349 [==============================] - 0s 901us/step - loss: 2.0792e-04 - val_loss: 3.9589e-04\n",
      "Epoch 907/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.0919e-04 - val_loss: 3.9341e-04\n",
      "Epoch 908/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.1153e-04 - val_loss: 3.9573e-04\n",
      "Epoch 909/1000\n",
      "349/349 [==============================] - 0s 923us/step - loss: 2.0773e-04 - val_loss: 3.9100e-04\n",
      "Epoch 910/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.0370e-04 - val_loss: 3.9290e-04\n",
      "Epoch 911/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 2.0410e-04 - val_loss: 3.9733e-04\n",
      "Epoch 912/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.0872e-04 - val_loss: 3.9477e-04\n",
      "Epoch 913/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.0080e-04 - val_loss: 3.9244e-04\n",
      "Epoch 914/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 1.9725e-04 - val_loss: 3.9596e-04\n",
      "Epoch 915/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 2.1217e-04 - val_loss: 3.9180e-04\n",
      "Epoch 916/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 2.0183e-04 - val_loss: 3.9310e-04\n",
      "Epoch 917/1000\n",
      "349/349 [==============================] - 0s 915us/step - loss: 2.0040e-04 - val_loss: 4.1562e-04\n",
      "Epoch 918/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 2.1036e-04 - val_loss: 3.9069e-04\n",
      "Epoch 919/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 2.0427e-04 - val_loss: 3.9369e-04\n",
      "Epoch 920/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 2.0909e-04 - val_loss: 3.9561e-04\n",
      "Epoch 921/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 1.9860e-04 - val_loss: 4.0749e-04\n",
      "Epoch 922/1000\n",
      "349/349 [==============================] - 0s 950us/step - loss: 2.1743e-04 - val_loss: 3.9344e-04\n",
      "Epoch 923/1000\n",
      "349/349 [==============================] - 0s 961us/step - loss: 2.0417e-04 - val_loss: 4.0058e-04\n",
      "Epoch 924/1000\n",
      "349/349 [==============================] - 0s 935us/step - loss: 2.0265e-04 - val_loss: 3.9488e-04\n",
      "Epoch 925/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.0150e-04 - val_loss: 3.9043e-04\n",
      "Epoch 926/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 2.0737e-04 - val_loss: 3.9217e-04\n",
      "Epoch 927/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 2.0411e-04 - val_loss: 4.0393e-04\n",
      "Epoch 928/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 2.0941e-04 - val_loss: 3.8990e-04\n",
      "Epoch 929/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 2.0349e-04 - val_loss: 3.9512e-04\n",
      "Epoch 930/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.1046e-04 - val_loss: 3.9053e-04\n",
      "Epoch 931/1000\n",
      "349/349 [==============================] - 0s 904us/step - loss: 2.0080e-04 - val_loss: 3.9103e-04\n",
      "Epoch 932/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 1.9915e-04 - val_loss: 3.9642e-04\n",
      "Epoch 933/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 2.0354e-04 - val_loss: 3.9642e-04\n",
      "Epoch 934/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 1.9910e-04 - val_loss: 4.0065e-04\n",
      "Epoch 935/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 1.9459e-04 - val_loss: 3.8849e-04\n",
      "Epoch 936/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 2.0361e-04 - val_loss: 3.9542e-04\n",
      "Epoch 937/1000\n",
      "349/349 [==============================] - 0s 910us/step - loss: 2.0704e-04 - val_loss: 3.8989e-04\n",
      "Epoch 938/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 1.9378e-04 - val_loss: 3.9975e-04\n",
      "Epoch 939/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 2.0163e-04 - val_loss: 3.9920e-04\n",
      "Epoch 940/1000\n",
      "349/349 [==============================] - 0s 948us/step - loss: 2.0214e-04 - val_loss: 4.0791e-04\n",
      "Epoch 941/1000\n",
      "349/349 [==============================] - 0s 945us/step - loss: 2.0533e-04 - val_loss: 3.9853e-04\n",
      "Epoch 942/1000\n",
      "349/349 [==============================] - 0s 949us/step - loss: 2.0220e-04 - val_loss: 3.8949e-04\n",
      "Epoch 943/1000\n",
      "349/349 [==============================] - 0s 932us/step - loss: 1.9249e-04 - val_loss: 3.9578e-04\n",
      "Epoch 944/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 1.9372e-04 - val_loss: 4.0655e-04\n",
      "Epoch 945/1000\n",
      "349/349 [==============================] - 0s 894us/step - loss: 2.0652e-04 - val_loss: 3.9331e-04\n",
      "Epoch 946/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 2.0802e-04 - val_loss: 3.8937e-04\n",
      "Epoch 947/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 1.9535e-04 - val_loss: 4.0298e-04\n",
      "Epoch 948/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 2.0586e-04 - val_loss: 3.9439e-04\n",
      "Epoch 949/1000\n",
      "349/349 [==============================] - 0s 943us/step - loss: 1.9534e-04 - val_loss: 3.8975e-04\n",
      "Epoch 950/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 1.9928e-04 - val_loss: 3.8734e-04\n",
      "Epoch 951/1000\n",
      "349/349 [==============================] - 0s 921us/step - loss: 1.9885e-04 - val_loss: 3.8932e-04\n",
      "Epoch 952/1000\n",
      "349/349 [==============================] - 0s 918us/step - loss: 1.9634e-04 - val_loss: 3.8726e-04\n",
      "Epoch 953/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 1.9933e-04 - val_loss: 3.8869e-04\n",
      "Epoch 954/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 1.9749e-04 - val_loss: 4.3584e-04\n",
      "Epoch 955/1000\n",
      "349/349 [==============================] - 0s 909us/step - loss: 2.1743e-04 - val_loss: 3.9619e-04\n",
      "Epoch 956/1000\n",
      "349/349 [==============================] - 0s 920us/step - loss: 1.9799e-04 - val_loss: 3.8768e-04\n",
      "Epoch 957/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 1.9585e-04 - val_loss: 3.8852e-04\n",
      "Epoch 958/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 1.9594e-04 - val_loss: 3.8663e-04\n",
      "Epoch 959/1000\n",
      "349/349 [==============================] - 0s 911us/step - loss: 1.9645e-04 - val_loss: 3.9169e-04\n",
      "Epoch 960/1000\n",
      "349/349 [==============================] - 0s 908us/step - loss: 1.9227e-04 - val_loss: 4.0202e-04\n",
      "Epoch 961/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 1.9819e-04 - val_loss: 3.8942e-04\n",
      "Epoch 962/1000\n",
      "349/349 [==============================] - 0s 907us/step - loss: 1.9692e-04 - val_loss: 3.8783e-04\n",
      "Epoch 963/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 1.9697e-04 - val_loss: 3.8747e-04\n",
      "Epoch 964/1000\n",
      "349/349 [==============================] - 0s 928us/step - loss: 1.9833e-04 - val_loss: 3.9300e-04\n",
      "Epoch 965/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 1.9311e-04 - val_loss: 3.9547e-04\n",
      "Epoch 966/1000\n",
      "349/349 [==============================] - 0s 942us/step - loss: 1.9880e-04 - val_loss: 4.3026e-04\n",
      "Epoch 967/1000\n",
      "349/349 [==============================] - 0s 931us/step - loss: 2.2795e-04 - val_loss: 3.8581e-04\n",
      "Epoch 968/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 1.9381e-04 - val_loss: 3.9413e-04\n",
      "Epoch 969/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 1.9164e-04 - val_loss: 3.9724e-04\n",
      "Epoch 970/1000\n",
      "349/349 [==============================] - 0s 938us/step - loss: 1.9300e-04 - val_loss: 3.8898e-04\n",
      "Epoch 971/1000\n",
      "349/349 [==============================] - 0s 933us/step - loss: 1.9992e-04 - val_loss: 3.8915e-04\n",
      "Epoch 972/1000\n",
      "349/349 [==============================] - 0s 917us/step - loss: 1.9756e-04 - val_loss: 3.9244e-04\n",
      "Epoch 973/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 1.9633e-04 - val_loss: 3.8946e-04\n",
      "Epoch 974/1000\n",
      "349/349 [==============================] - 0s 929us/step - loss: 2.0042e-04 - val_loss: 3.9552e-04\n",
      "Epoch 975/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 1.9394e-04 - val_loss: 3.9170e-04\n",
      "Epoch 976/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 1.9111e-04 - val_loss: 3.9091e-04\n",
      "Epoch 977/1000\n",
      "349/349 [==============================] - 0s 939us/step - loss: 1.9475e-04 - val_loss: 3.9035e-04\n",
      "Epoch 978/1000\n",
      "349/349 [==============================] - 0s 906us/step - loss: 1.9032e-04 - val_loss: 3.8971e-04\n",
      "Epoch 979/1000\n",
      "349/349 [==============================] - 0s 913us/step - loss: 1.9051e-04 - val_loss: 3.8842e-04\n",
      "Epoch 980/1000\n",
      "349/349 [==============================] - 0s 916us/step - loss: 1.8563e-04 - val_loss: 3.9186e-04\n",
      "Epoch 981/1000\n",
      "349/349 [==============================] - 0s 912us/step - loss: 1.9921e-04 - val_loss: 3.9619e-04\n",
      "Epoch 982/1000\n",
      "349/349 [==============================] - 0s 926us/step - loss: 1.9156e-04 - val_loss: 4.0395e-04\n",
      "Epoch 983/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 1.9626e-04 - val_loss: 3.8779e-04\n",
      "Epoch 984/1000\n",
      "349/349 [==============================] - 0s 922us/step - loss: 1.9013e-04 - val_loss: 3.9264e-04\n",
      "Epoch 985/1000\n",
      "349/349 [==============================] - 0s 930us/step - loss: 1.9997e-04 - val_loss: 3.9636e-04\n",
      "Epoch 986/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 1.9139e-04 - val_loss: 3.8980e-04\n",
      "Epoch 987/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 1.9165e-04 - val_loss: 3.9497e-04\n",
      "Epoch 988/1000\n",
      "349/349 [==============================] - 0s 919us/step - loss: 1.9309e-04 - val_loss: 3.9350e-04\n",
      "Epoch 989/1000\n",
      "349/349 [==============================] - 0s 925us/step - loss: 1.9234e-04 - val_loss: 4.0870e-04\n",
      "Epoch 990/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 2.0025e-04 - val_loss: 3.8420e-04\n",
      "Epoch 991/1000\n",
      "349/349 [==============================] - 0s 924us/step - loss: 1.8894e-04 - val_loss: 3.8818e-04\n",
      "Epoch 992/1000\n",
      "349/349 [==============================] - 0s 927us/step - loss: 1.9283e-04 - val_loss: 3.8885e-04\n",
      "Epoch 993/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 1.9319e-04 - val_loss: 3.8562e-04\n",
      "Epoch 994/1000\n",
      "349/349 [==============================] - 0s 954us/step - loss: 1.9448e-04 - val_loss: 3.9000e-04\n",
      "Epoch 995/1000\n",
      "349/349 [==============================] - 0s 937us/step - loss: 1.9373e-04 - val_loss: 3.9323e-04\n",
      "Epoch 996/1000\n",
      "349/349 [==============================] - 0s 983us/step - loss: 1.9774e-04 - val_loss: 3.8643e-04\n",
      "Epoch 997/1000\n",
      "349/349 [==============================] - 0s 951us/step - loss: 1.8772e-04 - val_loss: 3.8566e-04\n",
      "Epoch 998/1000\n",
      "349/349 [==============================] - 0s 974us/step - loss: 1.9101e-04 - val_loss: 3.8457e-04\n",
      "Epoch 999/1000\n",
      "349/349 [==============================] - 0s 905us/step - loss: 1.9211e-04 - val_loss: 4.0043e-04\n",
      "Epoch 1000/1000\n",
      "349/349 [==============================] - 0s 914us/step - loss: 1.9587e-04 - val_loss: 3.9317e-04\n",
      "y_preds_dnn_reg: (7425, 1)\n",
      "CPU times: user 12min 28s, sys: 1min 47s, total: 14min 16s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dnn_reg_combined = DnnReg(n_units=n_units, n_features=input_shape)\n",
    "\n",
    "y_preds_dnn_reg_combined = train_eval_dnn_reg(dnn_reg=dnn_reg_combined,\n",
    "                                          x_train=x_r_train_combined,\n",
    "                                          y_train=y_train_combined, \n",
    "                                          x_val=x_r_val_combined, \n",
    "                                          y_val=y_val_combined,\n",
    "                                          x_test=x_r_test_combined,\n",
    "                                          y_test=y_test_combined,\n",
    "                                          name='combined',\n",
    "                                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.0237572</td>\n",
       "      <td>0.0517857</td>\n",
       "      <td>0.703024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              MAE       MRAE       RMSE R^2-Score\n",
       "RF            NaN        NaN        NaN       NaN\n",
       "GBR-Ls        NaN        NaN        NaN       NaN\n",
       "DNN-Reg  0.040592  0.0237572  0.0517857  0.703024"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_reg_combined = add_to_regression_comparison(df_reg_combined,\n",
    "                                           y_preds=y_preds_dnn_reg_combined,\n",
    "                                           y_trues=y_test_combined, \n",
    "                                           name='DNN-Reg',\n",
    "                                           data_name='combined')\n",
    "df_reg_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  20 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 50s, sys: 0 ns, total: 14min 50s\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.0133423</td>\n",
       "      <td>0.00782976</td>\n",
       "      <td>0.0202903</td>\n",
       "      <td>0.715944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.0237572</td>\n",
       "      <td>0.0517857</td>\n",
       "      <td>0.703024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF       0.0133423  0.00782976  0.0202903  0.715944\n",
       "GBR-Ls         NaN         NaN        NaN       NaN\n",
       "DNN-Reg   0.040592   0.0237572  0.0517857  0.703024"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_preds_rf_combined = train_eval_rf(x_train=x_r_train_combined,\n",
    "                                y_train=y_train_combined, \n",
    "                                x_test=x_r_test_combined,\n",
    "                                y_test=y_test_combined,\n",
    "                                name='combined'\n",
    "                               )\n",
    "\n",
    "\n",
    "df_reg_combined = add_to_regression_comparison(df_reg_combined,\n",
    "                                           y_preds=y_preds_rf_combined,\n",
    "                                           y_trues=y_test_combined, \n",
    "                                           name='RF',\n",
    "                                           data_name='combined'\n",
    "                                          )\n",
    "df_reg_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0013            2.84m\n",
      "         2           0.0012            2.83m\n",
      "         3           0.0011            2.81m\n",
      "         4           0.0011            2.80m\n",
      "         5           0.0010            2.78m\n",
      "         6           0.0010            2.74m\n",
      "         7           0.0009            2.71m\n",
      "         8           0.0009            2.68m\n",
      "         9           0.0009            2.65m\n",
      "        10           0.0008            2.62m\n",
      "        20           0.0007            2.32m\n",
      "        30           0.0007            2.03m\n",
      "        40           0.0006            1.75m\n",
      "        50           0.0006            1.46m\n",
      "        60           0.0006            1.17m\n",
      "        70           0.0006           52.87s\n",
      "        80           0.0005           35.31s\n",
      "        90           0.0005           17.70s\n",
      "       100           0.0005            0.00s\n",
      "CPU times: user 2min 57s, sys: 0 ns, total: 2min 57s\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MRAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R^2-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.0133423</td>\n",
       "      <td>0.00782976</td>\n",
       "      <td>0.0202903</td>\n",
       "      <td>0.715944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR-Ls</th>\n",
       "      <td>0.0169401</td>\n",
       "      <td>0.00993664</td>\n",
       "      <td>0.0242529</td>\n",
       "      <td>0.594159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN-Reg</th>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.0237572</td>\n",
       "      <td>0.0517857</td>\n",
       "      <td>0.703024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE        MRAE       RMSE R^2-Score\n",
       "RF       0.0133423  0.00782976  0.0202903  0.715944\n",
       "GBR-Ls   0.0169401  0.00993664  0.0242529  0.594159\n",
       "DNN-Reg   0.040592   0.0237572  0.0517857  0.703024"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_preds_gbr_combined = train_eval_gbr(x_train=x_r_train_combined,\n",
    "                              y_train=y_train_combined, \n",
    "                              x_test=x_r_test_combined,\n",
    "                              y_test=y_test_combined,\n",
    "                              name='combined',\n",
    "                             )\n",
    "\n",
    "\n",
    "df_reg_combined = add_to_regression_comparison(df_reg_combined,\n",
    "                                           y_preds=y_preds_gbr_combined,\n",
    "                                           y_trues=y_test_combined, \n",
    "                                           name='GBR-Ls',\n",
    "                                           data_name='combined'\n",
    "                                          )\n",
    "df_reg_combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion over synthetic-only data:\n",
    "\n",
    "- All three algorithms obtained acceptable results w.r.t MAE, MRAE, RMSE.\n",
    "\n",
    "- Although all of these three also obtain acceptable r^2 score. Although RF is the winner, but DNN-Reg is a closer follower here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusion:\n",
    "\n",
    "\n",
    "This study trained three regressors over a) real-data; b) synthetically generated data; c) their combination.\n",
    "\n",
    "We used four metrics to evaluate and compare the obtained results.\n",
    "\n",
    "- W.r.t MAE, MRAE, RMSE, all three algorithms, obtained excellent results over all three types of data sets.\n",
    "\n",
    "- W.r.t R^2 score, DNN-Reg obtained outstanding results over synthetic only data. It is also a close follower of the combined data set winner, which is RF. \n",
    "\n",
    "- RF wins the combined and real-only data, with relatively acceptable results.\n",
    "\n",
    "\n",
    "\n",
    "Future work: \n",
    "\n",
    "- I am going to re-train DNN-Reg with more epochs and smaller batch-size to improve its performance (hopefully). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfGvenv",
   "language": "python",
   "name": "tfgvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
